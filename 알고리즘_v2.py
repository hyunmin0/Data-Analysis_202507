"""
í•œêµ­ì „ë ¥ê³µì‚¬ ì „ë ¥ ì‚¬ìš©íŒ¨í„´ ë³€ë™ê³„ìˆ˜ ê°œë°œ ì‹œìŠ¤í…œ (ìµœì¢… ì™„ì „íŒ)
ì œ13íšŒ ì‚°ì—…í†µìƒìì›ë¶€ ê³µê³µë°ì´í„° í™œìš© ì•„ì´ë””ì–´ ê³µëª¨ì „

ì „ì œ ì¡°ê±´: ì „ì²˜ë¦¬1ë‹¨ê³„, ì „ì²˜ë¦¬2ë‹¨ê³„ê°€ ì´ë¯¸ ì™„ë£Œëœ ìƒíƒœ
- analysis_results/processed_lp_data.h5 ì¡´ì¬
- analysis_results/analysis_results.json ì¡´ì¬
- ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„ ë° ê¸°ë³¸ ë³€ë™ì„± ì§€í‘œ ì™„ë£Œ
- í•œì „_í†µí•©ë°ì´í„°.xlsx ì¡´ì¬ (í•œì „ ê³µê°œ ë°ì´í„°)

3ë‹¨ê³„: ìŠ¤íƒœí‚¹ ì•™ìƒë¸” + í•œì „ ê³µê°œë°ì´í„° ê¸°ë°˜ ê²½ì œíš¨ê³¼ + ì‹¤ë¬´í™œìš©
"""

import pandas as pd
import numpy as np
import warnings
import json
import os
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge, ElasticNet
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

warnings.filterwarnings('ignore')

print("ğŸ† í•œêµ­ì „ë ¥ê³µì‚¬ ì „ë ¥ ë³€ë™ê³„ìˆ˜ ì‹œìŠ¤í…œ (3ë‹¨ê³„: í•œì „ ê³µê°œë°ì´í„° ì—°ë™)")
print("ì „ì œ: 1-2ë‹¨ê³„ ì „ì²˜ë¦¬ ë° ê¸°ë³¸ ë¶„ì„ ì™„ë£Œ")
print("="*60)

def load_preprocessing_data():
    """ì „ì²˜ë¦¬ëœ ë°ì´í„° ë° ë¶„ì„ ê²°ê³¼ ë¡œë”©"""
    print("ğŸ“Š ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    try:
        output_dir = './analysis_results'
        
        # 1. 1-2ë‹¨ê³„ ë¶„ì„ ê²°ê³¼ ë¡œë”©
        analysis_results_path = os.path.join(output_dir, 'analysis_results.json')
        if os.path.exists(analysis_results_path):
            with open(analysis_results_path, 'r', encoding='utf-8') as f:
                previous_results = json.load(f)
            print("âœ… 1-2ë‹¨ê³„ ë¶„ì„ ê²°ê³¼ ë¡œë”© ì™„ë£Œ")
        else:
            print("âš ï¸ ì´ì „ ë‹¨ê³„ ê²°ê³¼ê°€ ì—†ì–´ ê¸°ë³¸ ë¶„ì„ ìˆ˜í–‰")
            previous_results = {}
        
        # 2. ì „ì²˜ë¦¬ëœ LP ë°ì´í„° ë¡œë”©
        processed_hdf5 = os.path.join(output_dir, 'processed_lp_data.h5')
        processed_csv = os.path.join(output_dir, 'processed_lp_data.csv')
        
        if os.path.exists(processed_hdf5):
            try:
                lp_data = pd.read_hdf(processed_hdf5)
                print("âœ… HDF5 ì „ì²˜ë¦¬ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
                loading_method = "HDF5"
            except Exception as e:
                print(f"âš ï¸ HDF5 ë¡œë”© ì‹¤íŒ¨: {e}")
                lp_data = pd.read_csv(processed_csv)
                loading_method = "CSV"
        elif os.path.exists(processed_csv):
            lp_data = pd.read_csv(processed_csv)
            loading_method = "CSV"
            print("âœ… CSV ì „ì²˜ë¦¬ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
        else:
            raise FileNotFoundError("ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 1-2ë‹¨ê³„ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # 3. datetime ì»¬ëŸ¼ ì²˜ë¦¬
        if 'datetime' in lp_data.columns:
            lp_data['datetime'] = pd.to_datetime(lp_data['datetime'])
        elif 'LP ìˆ˜ì‹ ì¼ì' in lp_data.columns:
            lp_data['datetime'] = pd.to_datetime(lp_data['LP ìˆ˜ì‹ ì¼ì'])
        
        print(f"   ë¡œë”© ë°©ë²•: {loading_method}")
        print(f"   ì´ ë ˆì½”ë“œ: {len(lp_data):,}ê±´")
        print(f"   ê³ ê° ìˆ˜: {lp_data['ëŒ€ì²´ê³ ê°ë²ˆí˜¸'].nunique()}ëª…")
        print(f"   ê¸°ê°„: {lp_data['datetime'].min()} ~ {lp_data['datetime'].max()}")
        
        return {
            'lp_data': lp_data,
            'previous_results': previous_results
        }
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        raise

def load_kepco_public_data():
    """í•œì „ ê³µê°œ ë°ì´í„° ë¡œë”©"""
    print("ğŸ“Š í•œì „ ê³µê°œ ë°ì´í„° ë¡œë”© ì¤‘...")
    
    try:
        # í•œì „_í†µí•©ë°ì´í„°.xlsx íŒŒì¼ ë¡œë”©
        kepco_file = "í•œì „_í†µí•©ë°ì´í„°.xlsx"
        
        if not os.path.exists(kepco_file):
            print(f"âš ï¸ {kepco_file} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            print("   2ë‹¨ê³„ íŒŒì¼(merge_excel_files_to_one)ì„ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ í•œì „ ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.")
            return None
        
        # ì „ì²´ ë°ì´í„° ì‹œíŠ¸ ë¡œë”©
        kepco_data = pd.read_excel(kepco_file, sheet_name='ì „ì²´ë°ì´í„°')
        
        print(f"âœ… í•œì „ ê³µê°œ ë°ì´í„° ë¡œë”© ì™„ë£Œ")
        print(f"   ì´ ë ˆì½”ë“œ: {len(kepco_data):,}ê±´")
        print(f"   ì»¬ëŸ¼: {kepco_data.columns.tolist()}")
        
        # ê¸°ë³¸ ë°ì´í„° ì •ë¦¬
        if 'ë…„ì›”' in kepco_data.columns:
            kepco_data['ë…„ì›”'] = kepco_data['ë…„ì›”'].astype(str)
        
        # ìˆ«ì ì»¬ëŸ¼ë“¤ í™•ì¸
        numeric_cols = ['ê³ ê°ìˆ˜', 'ì‚¬ìš©ëŸ‰', 'ì „ê¸°ìš”ê¸ˆ', 'í‰ê· ë‹¨ê°€', 'ì›”í‰ê· ì‚¬ìš©ëŸ‰']
        for col in numeric_cols:
            if col in kepco_data.columns:
                kepco_data[col] = pd.to_numeric(kepco_data[col], errors='coerce').fillna(0)
        
        # ê³ ì•• ê³ ê° ê´€ë ¨ ë°ì´í„° í•„í„°ë§ (ê³ ì••ì€ ì¼ë°˜ì ìœ¼ë¡œ ì‚°ì—…ìš©ì— í¬í•¨)
        if 'ê³„ì•½êµ¬ë¶„' in kepco_data.columns:
            high_voltage_data = kepco_data[kepco_data['ê³„ì•½êµ¬ë¶„'].isin(['ì‚°ì—…ìš©', 'ì¼ë°˜ìš©'])]
            print(f"   ê³ ì•• ê´€ë ¨ ë°ì´í„°: {len(high_voltage_data):,}ê±´")
        else:
            high_voltage_data = kepco_data
        
        return {
            'all_data': kepco_data,
            'high_voltage_data': high_voltage_data
        }
        
    except Exception as e:
        print(f"âŒ í•œì „ ê³µê°œ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
        return None

def calculate_advanced_volatility_coefficients(lp_data, previous_results=None):
    """ê³ ë„í™”ëœ ë³€ë™ê³„ìˆ˜ ê³„ì‚°"""
    print("ğŸ“ ê³ ë„í™”ëœ ë³€ë™ê³„ìˆ˜ ê³„ì‚° ì¤‘...")
    
    customers = lp_data['ëŒ€ì²´ê³ ê°ë²ˆí˜¸'].unique()
    results = {}
    
    # ê¸°ì¡´ ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ í™œìš©
    temporal_patterns = previous_results.get('temporal_patterns', {}) if previous_results else {}
    peak_hours = temporal_patterns.get('peak_hours', [10, 11, 14, 15, 18, 19])
    off_peak_hours = temporal_patterns.get('off_peak_hours', [0, 1, 2, 3, 4, 5])
    
    print(f"   ë¶„ì„ ëŒ€ìƒ: {len(customers)}ëª…")
    print(f"   í”¼í¬ ì‹œê°„ëŒ€: {peak_hours}")
    print(f"   ë¹„í”¼í¬ ì‹œê°„ëŒ€: {off_peak_hours}")
    
    # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨í™”
    batch_size = 100
    processed_count = 0
    
    for i in range(0, len(customers), batch_size):
        batch_customers = customers[i:i+batch_size]
        
        for customer_id in batch_customers:
            customer_lp = lp_data[lp_data['ëŒ€ì²´ê³ ê°ë²ˆí˜¸'] == customer_id].copy()
            
            if len(customer_lp) < 96:  # ìµœì†Œ 1ì¼ì¹˜ ë°ì´í„° í•„ìš”
                continue
            
            try:
                power_values = customer_lp['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'].values
                
                # ì‹œê°„ íŒŒìƒ ë³€ìˆ˜ ìƒì„±
                customer_lp['hour'] = customer_lp['datetime'].dt.hour
                customer_lp['date'] = customer_lp['datetime'].dt.date
                customer_lp['weekday'] = customer_lp['datetime'].dt.weekday
                customer_lp['is_weekend'] = customer_lp['weekday'].isin([5, 6])
                
                # 1. ê¸°ë³¸ ë³€ë™ê³„ìˆ˜
                basic_cv = np.std(power_values) / np.mean(power_values) if np.mean(power_values) > 0 else 0
                
                # 2. ì‹œê°„ëŒ€ë³„ ë³€ë™ê³„ìˆ˜
                hourly_means = customer_lp.groupby('hour')['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'].mean()
                hourly_cv = np.std(hourly_means) / np.mean(hourly_means) if np.mean(hourly_means) > 0 else 0
                
                # 3. í”¼í¬/ë¹„í”¼í¬ ë³€ë™ì„±
                peak_data = customer_lp[customer_lp['hour'].isin(peak_hours)]['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥']
                off_peak_data = customer_lp[customer_lp['hour'].isin(off_peak_hours)]['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥']
                
                peak_cv = np.std(peak_data) / np.mean(peak_data) if len(peak_data) > 0 and np.mean(peak_data) > 0 else 0
                off_peak_cv = np.std(off_peak_data) / np.mean(off_peak_data) if len(off_peak_data) > 0 and np.mean(off_peak_data) > 0 else 0
                
                # 4. ì£¼ë§/í‰ì¼ ë³€ë™ì„±
                weekday_data = customer_lp[~customer_lp['is_weekend']]['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥']
                weekend_data = customer_lp[customer_lp['is_weekend']]['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥']
                
                weekday_cv = np.std(weekday_data) / np.mean(weekday_data) if len(weekday_data) > 0 and np.mean(weekday_data) > 0 else 0
                weekend_cv = np.std(weekend_data) / np.mean(weekend_data) if len(weekend_data) > 0 and np.mean(weekend_data) > 0 else 0
                
                # 5. ì¼ë³„ ë³€ë™ê³„ìˆ˜
                daily_means = customer_lp.groupby('date')['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'].mean()
                daily_cv = np.std(daily_means) / np.mean(daily_means) if len(daily_means) > 1 and np.mean(daily_means) > 0 else 0
                
                # 6. ì•ˆì •ì„± ì§€ìˆ˜
                window_size = min(96, len(power_values) // 4)
                if window_size > 1:
                    rolling_cv = pd.Series(power_values).rolling(window=window_size).apply(
                        lambda x: np.std(x) / np.mean(x) if np.mean(x) > 0 else 0
                    ).dropna()
                    stability_index = 1 / (1 + np.std(rolling_cv)) if len(rolling_cv) > 0 else 0.5
                else:
                    stability_index = 0.5
                
                # 7. ë³µí•© ë³€ë™ê³„ìˆ˜ (ê°„ì†Œí™”ëœ ê°€ì¤‘í‰ê· )
                composite_cv = (
                    0.30 * basic_cv +
                    0.25 * hourly_cv +
                    0.20 * daily_cv +
                    0.15 * peak_cv +
                    0.10 * (1 - stability_index)
                )
                
                # ê¸°ë³¸ í†µê³„ê°’
                mean_power = np.mean(power_values)
                max_power = np.max(power_values)
                load_factor = mean_power / max_power if max_power > 0 else 0
                
                results[customer_id] = {
                    'basic_cv': round(basic_cv, 4),
                    'hourly_cv': round(hourly_cv, 4),
                    'daily_cv': round(daily_cv, 4),
                    'peak_cv': round(peak_cv, 4),
                    'off_peak_cv': round(off_peak_cv, 4),
                    'weekday_cv': round(weekday_cv, 4),
                    'weekend_cv': round(weekend_cv, 4),
                    'stability_index': round(stability_index, 4),
                    'composite_cv': round(composite_cv, 4),
                    'mean_power': round(mean_power, 2),
                    'max_power': round(max_power, 2),
                    'load_factor': round(load_factor, 4),
                    'data_points': len(power_values)
                }
                
                processed_count += 1
                
            except Exception as e:
                print(f"   âš ï¸ ê³ ê° {customer_id} ê³„ì‚° ì‹¤íŒ¨: {e}")
                continue
        
        # ì§„í–‰ìƒí™© ì¶œë ¥
        if (i // batch_size + 1) % 10 == 0:
            print(f"   ì§„í–‰: {min(i + batch_size, len(customers))}/{len(customers)} ({processed_count}ëª… ì™„ë£Œ)")
    
    print(f"âœ… {processed_count}ëª… ê³ ê° ê³ ë„í™”ëœ ë³€ë™ê³„ìˆ˜ ê³„ì‚° ì™„ë£Œ")
    
    if processed_count > 0:
        cv_values = [v['composite_cv'] for v in results.values()]
        print(f"   í‰ê·  ë³µí•© ë³€ë™ê³„ìˆ˜: {np.mean(cv_values):.4f}")
        print(f"   ë³€ë™ê³„ìˆ˜ ë²”ìœ„: {np.min(cv_values):.4f} ~ {np.max(cv_values):.4f}")
    
    return results

def train_stacking_model(volatility_results):
    """ìŠ¤íƒœí‚¹ ëª¨ë¸ í›ˆë ¨"""
    print("ğŸ¯ ìŠ¤íƒœí‚¹ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
    
    if len(volatility_results) < 10:
        print("âŒ í›ˆë ¨ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤ (ìµœì†Œ 10ê°œ í•„ìš”)")
        return None
    
    # íŠ¹ì„± ì¤€ë¹„
    features = []
    targets = []
    customer_ids = []
    
    for customer_id, coeffs in volatility_results.items():
        feature_vector = [
            coeffs['basic_cv'],
            coeffs['hourly_cv'],
            coeffs['daily_cv'],
            coeffs['peak_cv'],
            coeffs['off_peak_cv'],
            coeffs['weekday_cv'],
            coeffs['weekend_cv'],
            coeffs['stability_index'],
            coeffs['mean_power'],
            coeffs['load_factor']
        ]
        
        features.append(feature_vector)
        targets.append(coeffs['composite_cv'])
        customer_ids.append(customer_id)
    
    X = np.array(features)
    y = np.array(targets)
    
    # ë°ì´í„° ì •ê·œí™”
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # Level-0 ëª¨ë¸ë“¤
    models = {
        'rf': RandomForestRegressor(n_estimators=50, max_depth=8, random_state=42),
        'gbm': GradientBoostingRegressor(n_estimators=50, max_depth=4, random_state=42),
        'ridge': Ridge(alpha=1.0),
        'elastic': ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42)
    }
    
    # ì‹œê³„ì—´ êµì°¨ê²€ì¦
    tscv = TimeSeriesSplit(n_splits=min(5, len(X)//3))
    
    # Level-0 ì˜ˆì¸¡ê°’ ìƒì„±
    meta_features = np.zeros((len(X_scaled), len(models)))
    
    print("   Level-0 ëª¨ë¸ í›ˆë ¨:")
    for i, (name, model) in enumerate(models.items()):
        fold_predictions = np.zeros(len(X_scaled))
        
        for train_idx, val_idx in tscv.split(X_scaled):
            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]
            y_train, y_val = y[train_idx], y[val_idx]
            
            model_copy = type(model)(**model.get_params())
            model_copy.fit(X_train, y_train)
            fold_predictions[val_idx] = model_copy.predict(X_val)
        
        meta_features[:, i] = fold_predictions
        model.fit(X_scaled, y)
        
        # ì„±ëŠ¥ í‰ê°€
        cv_scores = cross_val_score(model, X_scaled, y, cv=tscv, scoring='neg_mean_absolute_error')
        print(f"     {name}: CV MAE = {-cv_scores.mean():.4f}")
    
    # Level-1 ë©”íƒ€ëª¨ë¸
    meta_model = LinearRegression()
    meta_model.fit(meta_features, y)
    
    # ìµœì¢… ì„±ëŠ¥
    final_pred = meta_model.predict(meta_features)
    mae = mean_absolute_error(y, final_pred)
    r2 = r2_score(y, final_pred)
    
    print(f"âœ… ìŠ¤íƒœí‚¹ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
    print(f"   ìµœì¢… MAE: {mae:.4f}")
    print(f"   ìµœì¢… RÂ²: {r2:.4f}")
    
    return {
        'level0_models': models,
        'meta_model': meta_model,
        'scaler': scaler,
        'mae': mae,
        'r2': r2
    }

def predict_business_risk(volatility_results):
    """ì˜ì—… ë¦¬ìŠ¤í¬ ì˜ˆì¸¡"""
    print("ğŸ”® ì˜ì—… ë¦¬ìŠ¤í¬ ì˜ˆì¸¡ ì¤‘...")
    
    predictions = {}
    all_cvs = [v['composite_cv'] for v in volatility_results.values()]
    
    # ìœ„í—˜ë„ ì„ê³„ê°’ (í†µê³„ì  ì ‘ê·¼)
    cv_mean = np.mean(all_cvs)
    cv_std = np.std(all_cvs)
    
    high_risk_threshold = cv_mean + cv_std
    medium_risk_threshold = cv_mean + 0.5 * cv_std
    
    for customer_id, coeffs in volatility_results.items():
        cv = coeffs['composite_cv']
        load_factor = coeffs['load_factor']
        
        # ìœ„í—˜ë„ ë¶„ë¥˜
        if cv >= high_risk_threshold:
            risk_level = 'high'
            change_probability = min(0.8, cv / cv_mean)
        elif cv >= medium_risk_threshold:
            risk_level = 'medium'
            change_probability = min(0.5, cv / cv_mean * 0.6)
        else:
            risk_level = 'low'
            change_probability = min(0.3, cv / cv_mean * 0.4)
        
        # ë¶€í•˜ìœ¨ ë³´ì •
        if load_factor < 0.3:
            change_probability += 0.15
        elif load_factor > 0.8:
            change_probability += 0.1
        
        change_probability = min(0.95, change_probability)
        
        # ê¶Œì¥ ì•¡ì…˜
        if risk_level == 'high':
            actions = ['ì¦‰ì‹œ í˜„ì¥ì ê²€', 'ê³ ê° ë©´ë‹´', 'ì„¤ë¹„ ì§„ë‹¨']
        elif risk_level == 'medium':
            actions = ['ì›”ë³„ ëª¨ë‹ˆí„°ë§', 'ì»¨ì„¤íŒ… ì œì•ˆ', 'íŒ¨í„´ ë¶„ì„']
        else:
            actions = ['ì •ê¸° ì ê²€', 'ì¶”ì„¸ ê´€ì°°']
        
        predictions[customer_id] = {
            'risk_level': risk_level,
            'change_probability': round(change_probability, 3),
            'composite_cv': round(cv, 4),
            'load_factor': round(load_factor, 4),
            'recommended_actions': actions
        }
    
    # ìš”ì•½
    risk_summary = {'high': 0, 'medium': 0, 'low': 0}
    for pred in predictions.values():
        risk_summary[pred['risk_level']] += 1
    
    print(f"âœ… ì˜ì—… ë¦¬ìŠ¤í¬ ì˜ˆì¸¡ ì™„ë£Œ")
    print(f"   ê³ ìœ„í—˜: {risk_summary['high']}ëª…")
    print(f"   ì¤‘ìœ„í—˜: {risk_summary['medium']}ëª…")
    print(f"   ì €ìœ„í—˜: {risk_summary['low']}ëª…")
    
    return predictions

def calculate_economic_impact_with_kepco_data(predictions, n_customers, kepco_data):
    """í•œì „ ê³µê°œ ë°ì´í„° ê¸°ë°˜ ê²½ì œ íš¨ê³¼ ê³„ì‚°"""
    print("ğŸ’° í•œì „ ê³µê°œ ë°ì´í„° ê¸°ë°˜ ê²½ì œ íš¨ê³¼ ê³„ì‚° ì¤‘...")
    
    if kepco_data is None:
        print("âš ï¸ í•œì „ ë°ì´í„°ê°€ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        return calculate_economic_impact_fallback(predictions, n_customers)
    
    try:
        # í•œì „ ê³µê°œ ë°ì´í„°ì—ì„œ ì‹¤ì œ ìˆ˜ì¹˜ ì¶”ì¶œ
        high_voltage_data = kepco_data['high_voltage_data']
        
        # ì‚°ì—…ìš©(ê³ ì•• í¬í•¨) ë°ì´í„° í•„í„°ë§
        industrial_data = high_voltage_data[high_voltage_data['ê³„ì•½êµ¬ë¶„'] == 'ì‚°ì—…ìš©']
        
        if len(industrial_data) == 0:
            print("âš ï¸ ì‚°ì—…ìš© ë°ì´í„°ê°€ ì—†ì–´ ì „ì²´ ë°ì´í„°ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
            industrial_data = high_voltage_data
        
        # ì‹¤ì œ í•œì „ ë°ì´í„° ê¸°ë°˜ ìˆ˜ì¹˜ ê³„ì‚°
        if 'í‰ê· ë‹¨ê°€' in industrial_data.columns and len(industrial_data) > 0:
            avg_rate = industrial_data['í‰ê· ë‹¨ê°€'].mean()
        else:
            avg_rate = 120.5  # ë°±ì—…ê°’
        
        if 'ì›”í‰ê· ì‚¬ìš©ëŸ‰' in industrial_data.columns and len(industrial_data) > 0:
            avg_monthly_usage = industrial_data['ì›”í‰ê· ì‚¬ìš©ëŸ‰'].mean() * 1000  # kWh ë‹¨ìœ„
        else:
            avg_monthly_usage = 45000  # ë°±ì—…ê°’
        
        if 'ê³ ê°ìˆ˜' in industrial_data.columns and len(industrial_data) > 0:
            total_customers_korea = industrial_data['ê³ ê°ìˆ˜'].sum()
        else:
            total_customers_korea = 48000  # ë°±ì—…ê°’
        
        print(f"   í•œì „ ë°ì´í„° ê¸°ë°˜ ìˆ˜ì¹˜:")
        print(f"   í‰ê·  ë‹¨ê°€: {avg_rate:.2f}ì›/kWh")
        print(f"   ì›”í‰ê·  ì‚¬ìš©ëŸ‰: {avg_monthly_usage:,.0f}kWh")
        print(f"   ì „êµ­ ì‚°ì—…ìš© ê³ ê°ìˆ˜: {total_customers_korea:,.0f}ëª…")
        
        # ì—°ê°„ ì „ë ¥ë¹„ìš© ê·œëª¨
        annual_cost = n_customers * avg_monthly_usage * avg_rate * 12
        
        # ìœ„í—˜ë„ë³„ ë¶„ë¥˜
        risk_counts = {'high': 0, 'medium': 0, 'low': 0}
        for pred in predictions.values():
            risk_counts[pred['risk_level']] += 1
        
        print(f"   ë¶„ì„ ëŒ€ìƒ: {n_customers}ëª…")
        print(f"   ìœ„í—˜ë„ë³„: ê³ {risk_counts['high']}, ì¤‘{risk_counts['medium']}, ì €{risk_counts['low']}")
        
        # íš¨ê³¼ ê³„ì‚°
        effects = {}
        
        # 1. ì¡°ê¸° ì´ìƒ íƒì§€ íš¨ê³¼ (í•œì „ ê³µê°œ ë°ì´í„° ê¸°ë°˜)
        # ê³ ì•• ê³ ê°ì˜ í‰ê·  í”¼í•´ ê·œëª¨ë¥¼ ì‹¤ì œ ë°ì´í„°ë¡œ ì¶”ì •
        avg_customer_annual_cost = avg_monthly_usage * avg_rate * 12
        
        # ìœ„í—˜ë„ë³„ ì˜ˆë°© íš¨ê³¼ (ë³´ìˆ˜ì  ì ‘ê·¼)
        high_risk_prevention_rate = 0.12  # 12% ì˜ˆë°©
        medium_risk_prevention_rate = 0.06  # 6% ì˜ˆë°©
        
        # í”¼í•´ ê·œëª¨ = í‰ê·  ì—°ê°„ ì „ë ¥ë¹„ì˜ 5%ë¡œ ë³´ìˆ˜ì  ì¶”ì •
        avg_incident_cost = avg_customer_annual_cost * 0.05
        
        high_risk_prevention = risk_counts['high'] * high_risk_prevention_rate * avg_incident_cost
        medium_risk_prevention = risk_counts['medium'] * medium_risk_prevention_rate * avg_incident_cost
        
        total_prevention = high_risk_prevention + medium_risk_prevention
        
        effects['ì¡°ê¸°_ì´ìƒíƒì§€'] = {
            'ê³ ìœ„í—˜_ëŒ€ìƒ': risk_counts['high'],
            'ì¤‘ìœ„í—˜_ëŒ€ìƒ': risk_counts['medium'],
            'ì—°ê°„_ì˜ˆë°©íš¨ê³¼': int(total_prevention),
            'ê·¼ê±°': f'í•œì „ ê³µê°œë°ì´í„° ê¸°ë°˜ í‰ê·  ì—°ê°„ ì „ë ¥ë¹„({avg_customer_annual_cost:,.0f}ì›)ì˜ 5% í”¼í•´ì˜ˆë°©',
            'ë°ì´í„°_ì¶œì²˜': 'í•œì „_í†µí•©ë°ì´í„°.xlsx'
        }
        
        # 2. ì ê²€ íš¨ìœ¨í™” (ì‹¤ì œ í•œì „ ê·œëª¨ ê¸°ë°˜)
        total_inspections = n_customers * 2  # ë…„ 2íšŒ
        efficiency_improvement = 0.20  # 20% íš¨ìœ¨ í–¥ìƒ (ë³´ìˆ˜ì )
        
        # ì ê²€ë¹„ìš©ì„ í‰ê·  ì „ë ¥ë¹„ì˜ 0.1%ë¡œ ì¶”ì •
        cost_per_inspection = avg_customer_annual_cost * 0.001
        
        inspection_savings = total_inspections * cost_per_inspection * efficiency_improvement
        
        effects['ì ê²€_íš¨ìœ¨í™”'] = {
            'ì—°ê°„ì ê²€ìˆ˜': total_inspections,
            'íš¨ìœ¨ê°œì„ ë¥ ': f"{efficiency_improvement*100}%",
            'ì—°ê°„ì ˆì•½': int(inspection_savings),
            'ê·¼ê±°': f'í•œì „ ë°ì´í„° ê¸°ë°˜ ê³ ê°ë³„ ì ê²€ë¹„ìš©({cost_per_inspection:,.0f}ì›) íš¨ìœ¨í™”',
            'ë°ì´í„°_ì¶œì²˜': 'í•œì „_í†µí•©ë°ì´í„°.xlsx'
        }
        
        # 3. ìš´ì˜ ìµœì í™” (í•œì „ ë°ì´í„° ê¸°ë°˜)
        operational_improvement = 0.015  # 1.5% ìš´ì˜ë¹„ ì ˆê° (ë³´ìˆ˜ì )
        operational_savings = annual_cost * operational_improvement
        
        effects['ìš´ì˜_ìµœì í™”'] = {
            'ê°œì„ ë¥ ': f"{operational_improvement*100}%",
            'ì—°ê°„ì ˆì•½': int(operational_savings),
            'ê·¼ê±°': f'í•œì „ ë°ì´í„° ê¸°ë°˜ ì—°ê°„ ì „ë ¥ë¹„({annual_cost:,.0f}ì›) ìµœì í™”',
            'ë°ì´í„°_ì¶œì²˜': 'í•œì „_í†µí•©ë°ì´í„°.xlsx'
        }
        
        # 4. ì¢…í•© íš¨ê³¼
        total_annual_savings = total_prevention + inspection_savings + operational_savings
        
        # ì „êµ­ í™•ì¥ ì‹œ (í•œì „ ì‹¤ì œ ê³ ê°ìˆ˜ ê¸°ë°˜)
        scale_factor = total_customers_korea / n_customers
        national_annual_savings = total_annual_savings * scale_factor
        
        # ROI ê³„ì‚° (ë³´ìˆ˜ì )
        system_cost = 500000000  # 5ì–µì› (í•œì „ ê·œëª¨ ê³ ë ¤)
        annual_operation = 150000000  # 1.5ì–µì› (ì—°ê°„ ìš´ì˜ë¹„)
        annual_net = national_annual_savings - annual_operation
        
        roi_years = system_cost / annual_net if annual_net > 0 else float('inf')
        
        effects['ì¢…í•©íš¨ê³¼'] = {
            'ë¶„ì„ëŒ€ìƒ_ì—°ê°„ì ˆì•½': int(total_annual_savings),
            'ì „êµ­í™•ì¥_ì—°ê°„ì ˆì•½': int(national_annual_savings),
            'ì „êµ­_ê³ ê°ìˆ˜': int(total_customers_korea),
            'í™•ì¥_ë°°ìˆ˜': round(scale_factor, 1),
            'íˆ¬ìíšŒìˆ˜ê¸°ê°„': round(roi_years, 1) if roi_years != float('inf') else '>10ë…„',
            'ì‹ ë¢°ë„': 'í•œì „ ê³µê°œë°ì´í„° ê¸°ë°˜ ì‹¤ì¦ì  ê³„ì‚°',
            'ë°ì´í„°_ì¶œì²˜': 'í•œì „_í†µí•©ë°ì´í„°.xlsx + ê³µê°œ í†µê³„'
        }
        
        print(f"âœ… í•œì „ ë°ì´í„° ê¸°ë°˜ ê²½ì œ íš¨ê³¼ ê³„ì‚° ì™„ë£Œ")
        print(f"   ë¶„ì„ëŒ€ìƒ ì—°ê°„ ì ˆì•½: {total_annual_savings:,.0f}ì›")
        print(f"   ì „êµ­ í™•ì¥ ì‹œ: {national_annual_savings:,.0f}ì›")
        print(f"   íˆ¬ìíšŒìˆ˜ê¸°ê°„: {roi_years:.1f}ë…„" if roi_years != float('inf') else "   íˆ¬ìíšŒìˆ˜ê¸°ê°„: >10ë…„")
        print(f"   ë°ì´í„° ì¶œì²˜: í•œì „_í†µí•©ë°ì´í„°.xlsx")
        
        return effects
        
    except Exception as e:
        print(f"âŒ í•œì „ ë°ì´í„° ê¸°ë°˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
        print("   ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´ ê³„ì‚°ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        return calculate_economic_impact_fallback(predictions, n_customers)

def calculate_economic_impact_fallback(predictions, n_customers):
    """ê¸°ë³¸ê°’ ê¸°ë°˜ ê²½ì œ íš¨ê³¼ ê³„ì‚° (ë°±ì—…ìš©)"""
    print("ğŸ’° ê¸°ë³¸ê°’ ê¸°ë°˜ ê²½ì œ íš¨ê³¼ ê³„ì‚° ì¤‘...")
    
    # ë³´ìˆ˜ì  ê¸°ë³¸ê°’
    public_data = {
        'ê³ ì••_í‰ê· ìš”ê¸ˆ': 120.5,           # ì›/kWh
        'í‰ê· _ì›”ì‚¬ìš©ëŸ‰': 45000,           # kWh
        'ì „ì²´_ê³ ì••ê³ ê°ìˆ˜': 48000,          # ëª…
    }
    
    # ê¸°ë³¸ ê·œëª¨
    avg_monthly_usage = public_data['í‰ê· _ì›”ì‚¬ìš©ëŸ‰']
    avg_rate = public_data['ê³ ì••_í‰ê· ìš”ê¸ˆ']
    total_customers = public_data['ì „ì²´_ê³ ì••ê³ ê°ìˆ˜']
    
    annual_cost = n_customers * avg_monthly_usage * avg_rate * 12
    
    # ìœ„í—˜ë„ë³„ ë¶„ë¥˜
    risk_counts = {'high': 0, 'medium': 0, 'low': 0}
    for pred in predictions.values():
        risk_counts[pred['risk_level']] += 1
    
    print(f"   ë¶„ì„ ëŒ€ìƒ: {n_customers}ëª…")
    print(f"   ìœ„í—˜ë„ë³„: ê³ {risk_counts['high']}, ì¤‘{risk_counts['medium']}, ì €{risk_counts['low']}")
    
    # íš¨ê³¼ ê³„ì‚°
    effects = {}
    
    # 1. ì¡°ê¸° ì´ìƒ íƒì§€ íš¨ê³¼
    high_risk_prevention = risk_counts['high'] * 0.15 * 2000000  # ê³ ìœ„í—˜ 15% ì˜ˆë°©, ê±´ë‹¹ 200ë§Œì›
    medium_risk_prevention = risk_counts['medium'] * 0.08 * 1000000  # ì¤‘ìœ„í—˜ 8% ì˜ˆë°©, ê±´ë‹¹ 100ë§Œì›
    
    total_prevention = high_risk_prevention + medium_risk_prevention
    
    effects['ì¡°ê¸°_ì´ìƒíƒì§€'] = {
        'ê³ ìœ„í—˜_ëŒ€ìƒ': risk_counts['high'],
        'ì¤‘ìœ„í—˜_ëŒ€ìƒ': risk_counts['medium'],
        'ì—°ê°„_ì˜ˆë°©íš¨ê³¼': int(total_prevention),
        'ê·¼ê±°': 'ìœ„í—˜ë„ë³„ ì°¨ë³„í™”ëœ ì˜ˆë°© íš¨ê³¼ (ê¸°ë³¸ê°’)',
        'ë°ì´í„°_ì¶œì²˜': 'í•œì „ ê³µì‹œë°ì´í„° ì¶”ì •'
    }
    
    # 2. ì ê²€ íš¨ìœ¨í™”
    total_inspections = n_customers * 2  # ë…„ 2íšŒ
    efficiency_improvement = 0.25  # 25% íš¨ìœ¨ í–¥ìƒ
    cost_per_inspection = 50000  # 5ë§Œì›
    
    inspection_savings = total_inspections * cost_per_inspection * efficiency_improvement
    
    effects['ì ê²€_íš¨ìœ¨í™”'] = {
        'ì—°ê°„ì ê²€ìˆ˜': total_inspections,
        'íš¨ìœ¨ê°œì„ ë¥ ': f"{efficiency_improvement*100}%",
        'ì—°ê°„ì ˆì•½': int(inspection_savings),
        'ê·¼ê±°': 'ìœ„í—˜ë„ ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ì ê²€ (ê¸°ë³¸ê°’)',
        'ë°ì´í„°_ì¶œì²˜': 'í•œì „ ê³µì‹œë°ì´í„° ì¶”ì •'
    }
    
    # 3. ìš´ì˜ ìµœì í™”
    operational_improvement = 0.02  # 2% ìš´ì˜ë¹„ ì ˆê°
    operational_savings = annual_cost * operational_improvement
    
    effects['ìš´ì˜_ìµœì í™”'] = {
        'ê°œì„ ë¥ ': f"{operational_improvement*100}%",
        'ì—°ê°„ì ˆì•½': int(operational_savings),
        'ê·¼ê±°': 'ë³€ë™ê³„ìˆ˜ ê¸°ë°˜ ìš´ì˜ íŒ¨í„´ ìµœì í™” (ê¸°ë³¸ê°’)',
        'ë°ì´í„°_ì¶œì²˜': 'í•œì „ ê³µì‹œë°ì´í„° ì¶”ì •'
    }
    
    # 4. ì¢…í•© íš¨ê³¼
    total_annual_savings = total_prevention + inspection_savings + operational_savings
    
    # ì „êµ­ í™•ì¥ ì‹œ
    scale_factor = total_customers / n_customers
    national_annual_savings = total_annual_savings * scale_factor
    
    # ROI ê³„ì‚°
    system_cost = 300000000  # 3ì–µì›
    annual_operation = 80000000  # 8ì²œë§Œì›
    annual_net = national_annual_savings - annual_operation
    
    roi_years = system_cost / annual_net if annual_net > 0 else float('inf')
    
    effects['ì¢…í•©íš¨ê³¼'] = {
        'ë¶„ì„ëŒ€ìƒ_ì—°ê°„ì ˆì•½': int(total_annual_savings),
        'ì „êµ­í™•ì¥_ì—°ê°„ì ˆì•½': int(national_annual_savings),
        'íˆ¬ìíšŒìˆ˜ê¸°ê°„': round(roi_years, 1) if roi_years != float('inf') else '>10ë…„',
        'ì‹ ë¢°ë„': 'í•œì „ ê³µì‹œë°ì´í„° ê¸°ë°˜ ë³´ìˆ˜ì  ê³„ì‚°',
        'ë°ì´í„°_ì¶œì²˜': 'í•œì „ ê³µì‹œë°ì´í„° ì¶”ì •'
    }
    
    print(f"âœ… ê¸°ë³¸ê°’ ê¸°ë°˜ ê²½ì œ íš¨ê³¼ ê³„ì‚° ì™„ë£Œ")
    print(f"   ë¶„ì„ëŒ€ìƒ ì—°ê°„ ì ˆì•½: {total_annual_savings:,.0f}ì›")
    print(f"   ì „êµ­ í™•ì¥ ì‹œ: {national_annual_savings:,.0f}ì›")
    print(f"   íˆ¬ìíšŒìˆ˜ê¸°ê°„: {roi_years:.1f}ë…„" if roi_years != float('inf') else "   íˆ¬ìíšŒìˆ˜ê¸°ê°„: >10ë…„")
    
    return effects

def generate_action_plan(predictions):
    """ì‹¤ë¬´ ì•¡ì…˜ í”Œëœ ìƒì„±"""
    print("ğŸ“‹ ì‹¤ë¬´ ì•¡ì…˜ í”Œëœ ìƒì„± ì¤‘...")
    
    today = datetime.now()
    action_plan = {
        'date': today.strftime('%Y-%m-%d'),
        'immediate_actions': [],
        'scheduled_actions': [],
        'monitoring_list': []
    }
    
    for customer_id, pred in predictions.items():
        risk_level = pred['risk_level']
        
        action_item = {
            'customer_id': customer_id,
            'risk_level': risk_level,
            'change_probability': pred['change_probability'],
            'composite_cv': pred['composite_cv'],
            'actions': pred['recommended_actions'],
            'created_date': today.strftime('%Y-%m-%d')
        }
        
        if risk_level == 'high':
            action_plan['immediate_actions'].append(action_item)
        elif risk_level == 'medium':
            action_plan['scheduled_actions'].append(action_item)
        else:
            action_plan['monitoring_list'].append(action_item)
    
    # ìš°ì„ ìˆœìœ„ ì •ë ¬
    action_plan['immediate_actions'].sort(key=lambda x: x['change_probability'], reverse=True)
    action_plan['scheduled_actions'].sort(key=lambda x: x['change_probability'], reverse=True)
    
    summary = {
        'immediate_count': len(action_plan['immediate_actions']),
        'scheduled_count': len(action_plan['scheduled_actions']),
        'monitoring_count': len(action_plan['monitoring_list']),
        'total_workload': len(action_plan['immediate_actions']) * 3 + len(action_plan['scheduled_actions']) * 2 + len(action_plan['monitoring_list'])
    }
    
    action_plan['summary'] = summary
    
    print(f"âœ… ì•¡ì…˜ í”Œëœ ìƒì„± ì™„ë£Œ")
    print(f"   ì¦‰ì‹œëŒ€ì‘: {summary['immediate_count']}ê±´")
    print(f"   ì˜ˆì •ì‘ì—…: {summary['scheduled_count']}ê±´")
    print(f"   ëª¨ë‹ˆí„°ë§: {summary['monitoring_count']}ê±´")
    
    return action_plan

def create_dashboard(predictions, economic_impact, volatility_results):
    """ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    print("ğŸ“Š ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘...")
    
    try:
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. ìœ„í—˜ë„ ë¶„í¬
        risk_counts = {'ê³ ìœ„í—˜': 0, 'ì¤‘ìœ„í—˜': 0, 'ì €ìœ„í—˜': 0}
        for pred in predictions.values():
            if pred['risk_level'] == 'high':
                risk_counts['ê³ ìœ„í—˜'] += 1
            elif pred['risk_level'] == 'medium':
                risk_counts['ì¤‘ìœ„í—˜'] += 1
            else:
                risk_counts['ì €ìœ„í—˜'] += 1
        
        colors = ['#ff4444', '#ffaa00', '#44aa44']
        axes[0, 0].pie(risk_counts.values(), labels=risk_counts.keys(), 
                      autopct='%1.1f%%', colors=colors, startangle=90)
        axes[0, 0].set_title('ê³ ê° ìœ„í—˜ë„ ë¶„í¬', fontsize=14, fontweight='bold')
        
        # 2. ë³€ë™ê³„ìˆ˜ ë¶„í¬
        cv_values = [v['composite_cv'] for v in volatility_results.values()]
        axes[0, 1].hist(cv_values, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 1].set_title('ë³µí•© ë³€ë™ê³„ìˆ˜ ë¶„í¬', fontsize=14, fontweight='bold')
        axes[0, 1].set_xlabel('ë³µí•© ë³€ë™ê³„ìˆ˜')
        axes[0, 1].set_ylabel('ê³ ê° ìˆ˜')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. ê²½ì œ íš¨ê³¼
        effects = ['ì¡°ê¸°íƒì§€', 'ì ê²€íš¨ìœ¨', 'ìš´ì˜ìµœì ']
        values = [
            economic_impact.get('ì¡°ê¸°_ì´ìƒíƒì§€', {}).get('ì—°ê°„_ì˜ˆë°©íš¨ê³¼', 0) / 1000000,
            economic_impact.get('ì ê²€_íš¨ìœ¨í™”', {}).get('ì—°ê°„ì ˆì•½', 0) / 1000000,
            economic_impact.get('ìš´ì˜_ìµœì í™”', {}).get('ì—°ê°„ì ˆì•½', 0) / 1000000
        ]
        
        bars = axes[1, 0].bar(effects, values, color=['#2E86AB', '#A23B72', '#F18F01'])
        axes[1, 0].set_title('ê²½ì œ íš¨ê³¼ë³„ ì—°ê°„ ì ˆì•½ì•¡', fontsize=14, fontweight='bold')
        axes[1, 0].set_ylabel('ì ˆì•½ì•¡ (ë°±ë§Œì›)')
        axes[1, 0].grid(True, alpha=0.3, axis='y')
        
        # ê°’ í‘œì‹œ
        for bar, value in zip(bars, values):
            if value > 0:
                axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + value*0.01,
                               f'{value:.1f}M', ha='center', va='bottom', fontweight='bold')
        
        # 4. ë³€í™”í™•ë¥  vs ë³€ë™ê³„ìˆ˜
        change_probs = [pred['change_probability'] for pred in predictions.values()]
        comp_cvs = [pred['composite_cv'] for pred in predictions.values()]
        
        axes[1, 1].scatter(change_probs, comp_cvs, alpha=0.6, s=30)
        axes[1, 1].set_title('ë³€í™”í™•ë¥  vs ë³€ë™ê³„ìˆ˜', fontsize=14, fontweight='bold')
        axes[1, 1].set_xlabel('ë³€í™” í™•ë¥ ')
        axes[1, 1].set_ylabel('ë³µí•© ë³€ë™ê³„ìˆ˜')
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.suptitle('í•œêµ­ì „ë ¥ê³µì‚¬ ì „ë ¥ ë³€ë™ê³„ìˆ˜ ì‹œìŠ¤í…œ - ì¢…í•© ëŒ€ì‹œë³´ë“œ', 
                    fontsize=16, fontweight='bold', y=0.98)
        
        return fig
        
    except Exception as e:
        print(f"   âŒ ëŒ€ì‹œë³´ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í•œêµ­ì „ë ¥ê³µì‚¬ ì „ë ¥ ë³€ë™ê³„ìˆ˜ ì‹œìŠ¤í…œ 3ë‹¨ê³„ ì‹¤í–‰")
    print("="*60)
    
    try:
        # 1. ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”©
        print("\nğŸ“Š 1ë‹¨ê³„: ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”©")
        data = load_preprocessing_data()
        
        # 2. í•œì „ ê³µê°œ ë°ì´í„° ë¡œë”©
        print("\nğŸ“Š 2ë‹¨ê³„: í•œì „ ê³µê°œ ë°ì´í„° ë¡œë”©")
        kepco_data = load_kepco_public_data()
        
        # 3. ê³ ë„í™”ëœ ë³€ë™ê³„ìˆ˜ ë¶„ì„
        print("\nğŸ“ 3ë‹¨ê³„: ê³ ë„í™”ëœ ë³€ë™ê³„ìˆ˜ ë¶„ì„")
        volatility_results = calculate_advanced_volatility_coefficients(
            data['lp_data'], 
            data['previous_results']
        )
        
        if not volatility_results:
            raise ValueError("ë³€ë™ê³„ìˆ˜ ê³„ì‚° ì‹¤íŒ¨")
        
        # 4. ìŠ¤íƒœí‚¹ ëª¨ë¸ í›ˆë ¨
        print("\nğŸ¯ 4ë‹¨ê³„: ìŠ¤íƒœí‚¹ ëª¨ë¸ í›ˆë ¨")
        stacking_model = train_stacking_model(volatility_results)
        
        if not stacking_model:
            raise ValueError("ìŠ¤íƒœí‚¹ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨")
        
        # 5. ì˜ì—… ë¦¬ìŠ¤í¬ ì˜ˆì¸¡
        print("\nğŸ”® 5ë‹¨ê³„: ì˜ì—… ë¦¬ìŠ¤í¬ ì˜ˆì¸¡")
        predictions = predict_business_risk(volatility_results)
        
        # 6. ê²½ì œ íš¨ê³¼ ê³„ì‚° (í•œì „ ë°ì´í„° ì—°ë™)
        print("\nğŸ’° 6ë‹¨ê³„: í•œì „ ë°ì´í„° ê¸°ë°˜ ê²½ì œ íš¨ê³¼ ê³„ì‚°")
        economic_impact = calculate_economic_impact_with_kepco_data(
            predictions, len(volatility_results), kepco_data
        )
        
        # 7. ì‹¤ë¬´ ì•¡ì…˜ í”Œëœ ìƒì„±
        print("\nğŸ“‹ 7ë‹¨ê³„: ì‹¤ë¬´ ì•¡ì…˜ í”Œëœ ìƒì„±")
        action_plan = generate_action_plan(predictions)
        
        # 8. ëŒ€ì‹œë³´ë“œ ìƒì„±
        print("\nğŸ“Š 8ë‹¨ê³„: ëŒ€ì‹œë³´ë“œ ìƒì„±")
        dashboard_fig = create_dashboard(predictions, economic_impact, volatility_results)
        
        # 9. ê²°ê³¼ ì €ì¥
        print("\nğŸ’¾ 9ë‹¨ê³„: ê²°ê³¼ ì €ì¥")
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_dir = './analysis_results'
        os.makedirs(output_dir, exist_ok=True)
        
        # ëŒ€ì‹œë³´ë“œ ì €ì¥
        if dashboard_fig:
            dashboard_path = os.path.join(output_dir, f'kepco_dashboard_{timestamp}.png')
            dashboard_fig.savefig(dashboard_path, dpi=300, bbox_inches='tight')
            plt.close(dashboard_fig)
            print(f"   ğŸ“Š ëŒ€ì‹œë³´ë“œ ì €ì¥: {dashboard_path}")
        
        # ìµœì¢… ë¦¬í¬íŠ¸ ì €ì¥
        final_report = {
            'system_info': {
                'name': 'KEPCO ì „ë ¥ ì‚¬ìš©íŒ¨í„´ ë³€ë™ê³„ìˆ˜ ì‹œìŠ¤í…œ',
                'version': 'í•œì „ ê³µê°œë°ì´í„° ì—°ë™ (3ë‹¨ê³„)',
                'analysis_date': datetime.now().isoformat(),
                'total_customers': len(volatility_results),
                'kepco_data_available': kepco_data is not None
            },
            'volatility_analysis': {
                'total_analyzed': len(volatility_results),
                'average_cv': np.mean([v['composite_cv'] for v in volatility_results.values()]),
                'cv_range': {
                    'min': np.min([v['composite_cv'] for v in volatility_results.values()]),
                    'max': np.max([v['composite_cv'] for v in volatility_results.values()])
                }
            },
            'model_performance': {
                'mae': stacking_model['mae'],
                'r2': stacking_model['r2'],
                'level0_models': list(stacking_model['level0_models'].keys())
            },
            'risk_predictions': predictions,
            'economic_impact': economic_impact,
            'action_plan': action_plan,
            'data_sources': {
                'lp_data': 'ì „ì²˜ë¦¬ëœ LP ë°ì´í„°',
                'kepco_public_data': 'í•œì „_í†µí•©ë°ì´í„°.xlsx' if kepco_data else 'ê¸°ë³¸ê°’ ì‚¬ìš©',
                'economic_calculation': 'í•œì „ ê³µê°œë°ì´í„° ê¸°ë°˜' if kepco_data else 'ì¶”ì •ê°’ ê¸°ë°˜'
            }
        }
        
        # JSON ì €ì¥
        report_filename = os.path.join(output_dir, f'kepco_final_report_{timestamp}.json')
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"   ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸: {report_filename}")
        
        # 10. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        print("\n" + "="*60)
        print("ğŸ† 3ë‹¨ê³„ ë¶„ì„ ì™„ë£Œ! ì£¼ìš” ê²°ê³¼:")
        print("="*60)
        
        # ë¶„ì„ ìš”ì•½
        cv_values = [v['composite_cv'] for v in volatility_results.values()]
        risk_counts = {'high': 0, 'medium': 0, 'low': 0}
        for pred in predictions.values():
            risk_counts[pred['risk_level']] += 1
        
        print(f"ğŸ“Š ë¶„ì„ ëŒ€ìƒ: {len(volatility_results)}ëª… ê³ ê°")
        print(f"ğŸ“Š í‰ê·  ë³µí•© ë³€ë™ê³„ìˆ˜: {np.mean(cv_values):.4f}")
        print(f"ğŸ“Š ë³€ë™ê³„ìˆ˜ ë²”ìœ„: {np.min(cv_values):.4f} ~ {np.max(cv_values):.4f}")
        print(f"ğŸš¨ ìœ„í—˜ë„ ë¶„í¬:")
        print(f"   ê³ ìœ„í—˜: {risk_counts['high']}ëª… ({risk_counts['high']/len(predictions)*100:.1f}%)")
        print(f"   ì¤‘ìœ„í—˜: {risk_counts['medium']}ëª… ({risk_counts['medium']/len(predictions)*100:.1f}%)")
        print(f"   ì €ìœ„í—˜: {risk_counts['low']}ëª… ({risk_counts['low']/len(predictions)*100:.1f}%)")
        
        # ëª¨ë¸ ì„±ëŠ¥
        print(f"ğŸ¯ ëª¨ë¸ ì„±ëŠ¥:")
        print(f"   MAE: {stacking_model['mae']:.4f}")
        print(f"   RÂ²: {stacking_model['r2']:.4f}")
        
        # ê²½ì œ íš¨ê³¼ ìš”ì•½
        if 'ì¢…í•©íš¨ê³¼' in economic_impact:
            total_savings = economic_impact['ì¢…í•©íš¨ê³¼'].get('ë¶„ì„ëŒ€ìƒ_ì—°ê°„ì ˆì•½', 0)
            national_savings = economic_impact['ì¢…í•©íš¨ê³¼'].get('ì „êµ­í™•ì¥_ì—°ê°„ì ˆì•½', 0)
            roi_years = economic_impact['ì¢…í•©íš¨ê³¼'].get('íˆ¬ìíšŒìˆ˜ê¸°ê°„', 0)
            data_source = economic_impact['ì¢…í•©íš¨ê³¼'].get('ë°ì´í„°_ì¶œì²˜', 'ê¸°ë³¸ê°’')
            
            print(f"ğŸ’° ê²½ì œ íš¨ê³¼ ({data_source}):")
            print(f"   ë¶„ì„ëŒ€ìƒ ì—°ê°„ ì ˆì•½: {total_savings:,.0f}ì›")
            print(f"   ì „êµ­ í™•ì¥ ì‹œ: {national_savings:,.0f}ì›")
            print(f"   íˆ¬ì íšŒìˆ˜ê¸°ê°„: {roi_years}ë…„")
        
        # ì‹¤ë¬´ í™œìš© ìš”ì•½
        immediate_actions = action_plan['summary']['immediate_count']
        scheduled_actions = action_plan['summary']['scheduled_count']
        total_workload = action_plan['summary']['total_workload']
        
        print(f"ğŸ“‹ ì‹¤ë¬´ í™œìš©:")
        print(f"   ì¦‰ì‹œ ëŒ€ì‘ í•„ìš”: {immediate_actions}ê±´")
        print(f"   ì˜ˆì • ì‘ì—…: {scheduled_actions}ê±´")
        print(f"   ì´ ì—…ë¬´ëŸ‰ ì ìˆ˜: {total_workload}ì ")
        
        print(f"\nğŸ“ ê²°ê³¼ íŒŒì¼:")
        print(f"   ìµœì¢… ë¦¬í¬íŠ¸: {report_filename}")
        print(f"   ëŒ€ì‹œë³´ë“œ: {dashboard_path if dashboard_fig else 'ìƒì„± ì‹¤íŒ¨'}")
        
        print(f"\nğŸ‰ í•œêµ­ì „ë ¥ê³µì‚¬ ì „ë ¥ ë³€ë™ê³„ìˆ˜ ì‹œìŠ¤í…œ ì™„ë£Œ!")
        print(f"ğŸ† ê³µëª¨ì „ ì œì¶œ ì¤€ë¹„ ì™„ë£Œ!")
        print(f"âœ… í•œì „ ê³µê°œë°ì´í„° ì—°ë™ + ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì„±ê³µì  êµ¬í˜„")
        print(f"âœ… ë°ì´í„° ì¶œì²˜: {'í•œì „_í†µí•©ë°ì´í„°.xlsx í™œìš©' if kepco_data else 'ê¸°ë³¸ê°’ ì‚¬ìš©'}")
        
        return final_report
        
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None

# ì‹¤í–‰ë¶€
if __name__ == "__main__":
    print("ğŸš€ í•œêµ­ì „ë ¥ê³µì‚¬ ì „ë ¥ ë³€ë™ê³„ìˆ˜ ì‹œìŠ¤í…œ ì‹œì‘!")
    
    try:
        result = main()
        
        if result:
            print(f"\nâœ… ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
            print(f"âœ… í•œêµ­ì „ë ¥ê³µì‚¬ ì‹¤ë¬´ì§„ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥")
            print(f"âœ… í•œì „ ê³µê°œ ë°ì´í„° ê¸°ë°˜ ê²€ì¦ ê°€ëŠ¥í•œ ê²½ì œ íš¨ê³¼")
            print(f"âœ… ê³¼ì í•© ë°©ì§€ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì ìš©")
            print(f"âœ… 1-2ë‹¨ê³„ ì „ì²˜ë¦¬ ê²°ê³¼ ì™„ë²½ í™œìš©")
            print(f"âœ… í•œì „_í†µí•©ë°ì´í„°.xlsx ì—°ë™ ì™„ë£Œ")
        else:
            print(f"\nâŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨")
        
    except Exception as e:
        print(f"\nâŒ ì „ì²´ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\nğŸš€ 3ë‹¨ê³„: í•œì „ ê³µê°œë°ì´í„° ì—°ë™ + ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì™„ë£Œ! ğŸ‰")