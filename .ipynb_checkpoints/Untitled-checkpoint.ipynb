{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c60571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 실제 환경에서 사용 방법 (3000호):\n",
      "\n",
      "    # 실제 LP 데이터만 로딩하면 끝!\n",
      "    lp_files = ['LP데이터1.csv', 'LP데이터2.csv']\n",
      "    analyzer.load_real_lp_data(lp_files)\n",
      "    \n",
      "    # 실제 데이터로 패턴 분석\n",
      "    enhanced_summary = analyzer.generate_enhanced_pattern_summary()\n",
      "    \n",
      "\n",
      "==================================================\n",
      "🧪 현재는 테스트용 샘플 데이터로 시연\n",
      "==================================================\n",
      "=== 테스트용 샘플 데이터 생성 ===\n",
      "⚠️  주의: 실제 환경에서는 load_real_lp_data() 사용\n",
      "✅ 테스트 데이터 생성 완료: 29,760레코드\n",
      "기간: 2024-03-01 00:00:00 ~ 2024-03-31 23:45:00\n",
      "고객 수: 10명\n",
      "\n",
      "============================================================\n",
      "📊 시계열 패턴 분석 종합 요약\n",
      "============================================================\n",
      "\n",
      "=== 시간대별 전력 사용 패턴 분석 ===\n",
      "📊 시간대별 평균 전력 사용량 (kW):\n",
      "시간\t평균\t표준편차\t최소\t최대\n",
      "00시\t58.3\t23.8\t7.4\t122.1\n",
      "01시\t66.2\t27.4\t8.6\t133.2\n",
      "02시\t73.7\t30.4\t10.1\t159.4\n",
      "03시\t79.8\t32.5\t9.8\t159.2\n",
      "04시\t84.9\t34.9\t11.7\t170.7\n",
      "05시\t88.1\t36.3\t10.6\t180.2\n",
      "06시\t92.8\t37.2\t12.3\t190.1\n",
      "07시\t104.0\t56.2\t16.1\t287.0\n",
      "08시\t111.3\t54.2\t15.5\t262.6\n",
      "09시\t107.8\t51.5\t15.4\t255.9\n",
      "10시\t93.6\t38.3\t10.3\t183.9\n",
      "11시\t79.8\t34.9\t8.2\t152.7\n",
      "12시\t68.0\t34.5\t11.3\t180.6\n",
      "13시\t62.8\t31.1\t9.4\t154.7\n",
      "14시\t55.2\t26.5\t8.1\t135.4\n",
      "15시\t45.7\t18.5\t4.7\t91.4\n",
      "16시\t35.0\t14.1\t4.3\t77.3\n",
      "17시\t32.9\t14.9\t5.4\t90.5\n",
      "18시\t32.4\t15.9\t4.8\t89.6\n",
      "19시\t37.7\t19.1\t5.4\t83.4\n",
      "20시\t38.2\t19.0\t3.9\t87.0\n",
      "21시\t42.4\t21.2\t5.4\t98.7\n",
      "22시\t44.0\t17.7\t6.0\t85.8\n",
      "23시\t50.3\t20.8\t6.2\t110.5\n",
      "\n",
      "⚡ 피크 시간대 (상위 20%): [6, 7, 8, 9, 10]시\n",
      "💤 비피크 시간대 (하위 30%): [16, 17, 18, 19, 20, 21, 22]시\n",
      "\n",
      "=== 일별/요일별 패턴 분석 ===\n",
      "📅 요일별 평균 일간 사용량 (kWh):\n",
      "월요일: 7,064.2 ± 2006.4\n",
      "화요일: 7,066.2 ± 1988.1\n",
      "수요일: 7,073.5 ± 2008.9\n",
      "목요일: 7,075.3 ± 2010.7\n",
      "금요일: 7,076.1 ± 2001.6\n",
      "토요일: 4,802.9 ± 2989.1\n",
      "일요일: 4,799.4 ± 2982.6\n",
      "\n",
      "📊 평일 vs 주말 비교:\n",
      "평일 평균: 7,071.3 kWh\n",
      "주말 평균: 4,801.1 kWh\n",
      "주말/평일 비율: 0.68\n",
      "\n",
      "=== 고객별 사용량 프로파일 분석 ===\n",
      "👥 고객별 기본 통계 (kW):\n",
      "고객번호\t평균\t표준편차\t변동계수\t최소\t최대\n",
      "A1001\t85.2\t36.3\t0.426\t23.6\t216.2\n",
      "A1002\t45.7\t29.6\t0.648\t5.5\t143.5\n",
      "A1003\t78.9\t28.9\t0.366\t23.9\t183.9\n",
      "A1004\t81.1\t63.8\t0.787\t3.9\t287.0\n",
      "A1005\t66.0\t24.4\t0.37\t23.5\t131.3\n",
      "A1006\t57.9\t26.3\t0.454\t18.6\t156.4\n",
      "A1007\t59.7\t41.3\t0.692\t4.8\t203.4\n",
      "A1008\t95.3\t44.5\t0.467\t28.4\t246.4\n",
      "A1009\t36.7\t19.7\t0.537\t7.6\t107.7\n",
      "A1010\t53.9\t26.0\t0.482\t11.4\t148.7\n",
      "\n",
      "📈 대용량 사용자 (상위 20%): ['A1001', 'A1008']\n",
      "📉 소용량 사용자 (하위 20%): ['A1002', 'A1009']\n",
      "\n",
      "🌊 고변동성 고객: ['A1004', 'A1007']\n",
      "📊 저변동성 고객: ['A1003', 'A1005']\n",
      "\n",
      "=== 부하율 및 효율성 지표 계산 ===\n",
      "⚡ 고객별 부하율 및 피크 집중도:\n",
      "고객번호\t부하율\t피크집중도\t평균부하\t최대부하\n",
      "A1001\t0.394\t1.041\t85.2\t216.2\n",
      "A1002\t0.319\t1.064\t45.7\t143.5\n",
      "A1003\t0.429\t0.923\t78.9\t183.9\n",
      "A1004\t0.283\t1.103\t81.1\t287.0\n",
      "A1005\t0.502\t0.851\t66.0\t131.3\n",
      "A1006\t0.37\t0.803\t57.9\t156.4\n",
      "A1007\t0.294\t1.072\t59.7\t203.4\n",
      "A1008\t0.387\t0.958\t95.3\t246.4\n",
      "A1009\t0.34\t0.967\t36.7\t107.7\n",
      "A1010\t0.362\t1.081\t53.9\t148.7\n",
      "\n",
      "📊 전체 부하율 분포:\n",
      "평균 부하율: 0.368\n",
      "부하율 범위: 0.283 ~ 0.502\n",
      "\n",
      "=== 사용량 이상 패턴 탐지 ===\n",
      "🚨 이상 패턴 탐지 결과:\n",
      "고객번호\t급격변화\t장기0값\t통계이상치\n",
      "A1001\t0\t0\t7\n",
      "A1002\t4\t0\t6\n",
      "A1003\t0\t0\t4\n",
      "A1004\t4\t0\t3\n",
      "A1006\t0\t0\t35\n",
      "A1007\t4\t0\t1\n",
      "A1008\t0\t0\t9\n",
      "A1009\t0\t0\t17\n",
      "A1010\t0\t0\t7\n",
      "\n",
      "🔍 주요 발견사항:\n",
      "  • 주요 피크 시간: [6, 7, 8, 9, 10]시\n",
      "  • 주말/평일 사용량 비율: 0.68\n",
      "  • 고객별 변동계수 범위: 0.366 ~ 0.787\n",
      "  • 평균 부하율: 0.368\n",
      "  • 이상 패턴 고객: 9명\n",
      "\n",
      "💡 변동계수 설계를 위한 인사이트:\n",
      "  1. 시간대별 가중치 필요 (피크/비피크 구분)\n",
      "  2. 요일별 보정 계수 고려\n",
      "  3. 고객별 기준 변동성 설정\n",
      "  4. 부하율과 변동성의 상관관계 분석\n",
      "  5. 다차원 변동성 지표 조합 검토\n",
      "\n",
      "💡 핵심 포인트:\n",
      "  ✅ 실제 환경: 실제 LP 데이터 그대로 분석\n",
      "  ✅ 테스트용: 샘플 데이터로 알고리즘 검증\n",
      "  ✅ 3000호: 실제 데이터 있으니 프로파일 생성 불필요\n",
      "  ✅ 패턴 분석: 실제 사용량에서 변동성 지표 계산\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class KEPCOTimeSeriesAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.lp_data = None\n",
    "        self.weather_data = None\n",
    "        self.calendar_data = None\n",
    "        \n",
    "    def load_sample_data(self, customer_df=None):\n",
    "        \"\"\"테스트용 샘플 LP 데이터 생성 (실제 환경에서는 사용 안함)\"\"\"\n",
    "        print(\"=== 테스트용 샘플 데이터 생성 ===\")\n",
    "        print(\"⚠️  주의: 실제 환경에서는 load_real_lp_data() 사용\")\n",
    "        \n",
    "        # 테스트용 샘플 데이터 생성\n",
    "        self.lp_data = self._create_comprehensive_sample_data(customer_df)\n",
    "        \n",
    "        # 날짜/시간 전처리\n",
    "        self.lp_data['datetime'] = pd.to_datetime(self.lp_data['LP수신일자'], format='%Y-%m-%d-%H:%M')\n",
    "        self.lp_data['date'] = self.lp_data['datetime'].dt.date\n",
    "        self.lp_data['hour'] = self.lp_data['datetime'].dt.hour\n",
    "        self.lp_data['minute'] = self.lp_data['datetime'].dt.minute\n",
    "        self.lp_data['weekday'] = self.lp_data['datetime'].dt.weekday  # 0=월요일\n",
    "        self.lp_data['is_weekend'] = self.lp_data['weekday'].isin([5, 6])\n",
    "        \n",
    "        print(f\"✅ 테스트 데이터 생성 완료: {len(self.lp_data):,}레코드\")\n",
    "        print(f\"기간: {self.lp_data['datetime'].min()} ~ {self.lp_data['datetime'].max()}\")\n",
    "        print(f\"고객 수: {self.lp_data['대체고객번호'].nunique()}명\")\n",
    "        \n",
    "        return self.lp_data\n",
    "    \n",
    "    def load_real_lp_data(self, lp_files):\n",
    "        \"\"\"실제 LP 데이터 로딩 (실제 환경에서 사용)\"\"\"\n",
    "        print(\"=== 실제 LP 데이터 로딩 ===\")\n",
    "        \n",
    "        lp_data_list = []\n",
    "        \n",
    "        for file_path in lp_files:\n",
    "            print(f\"📂 로딩 중: {file_path}\")\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                lp_data_list.append(df)\n",
    "                print(f\"   ✅ 완료: {len(df):,}레코드\")\n",
    "            except Exception as e:\n",
    "                print(f\"   ❌ 실패: {e}\")\n",
    "        \n",
    "        if lp_data_list:\n",
    "            self.lp_data = pd.concat(lp_data_list, ignore_index=True)\n",
    "            \n",
    "            # 날짜/시간 전처리\n",
    "            self.lp_data['datetime'] = pd.to_datetime(self.lp_data['LP수신일자'], format='%Y-%m-%d-%H:%M')\n",
    "            self.lp_data['date'] = self.lp_data['datetime'].dt.date\n",
    "            self.lp_data['hour'] = self.lp_data['datetime'].dt.hour\n",
    "            self.lp_data['minute'] = self.lp_data['datetime'].dt.minute\n",
    "            self.lp_data['weekday'] = self.lp_data['datetime'].dt.weekday\n",
    "            self.lp_data['is_weekend'] = self.lp_data['weekday'].isin([5, 6])\n",
    "            \n",
    "            print(f\"✅ 전체 데이터 결합 완료: {len(self.lp_data):,}레코드\")\n",
    "            print(f\"기간: {self.lp_data['datetime'].min()} ~ {self.lp_data['datetime'].max()}\")\n",
    "            print(f\"고객 수: {self.lp_data['대체고객번호'].nunique()}명\")\n",
    "        \n",
    "        return self.lp_data\n",
    "    \n",
    "    def load_external_data(self):\n",
    "        \"\"\"기상 및 달력 데이터 로딩\"\"\"\n",
    "        print(\"\\n=== 외부 데이터 로딩 ===\")\n",
    "        \n",
    "        try:\n",
    "            # 기상 데이터 로딩\n",
    "            print(\"📊 기상 데이터 로딩 중...\")\n",
    "            self.weather_data = pd.read_csv('weather_daily_processed.csv')\n",
    "            \n",
    "            # 날짜 컬럼 전처리\n",
    "            self.weather_data['date'] = pd.to_datetime(self.weather_data['날짜'])\n",
    "            \n",
    "            print(f\"✅ 기상 데이터 로딩 완료: {len(self.weather_data):,}일\")\n",
    "            print(f\"   기간: {self.weather_data['date'].min().date()} ~ {self.weather_data['date'].max().date()}\")\n",
    "            print(f\"   컬럼: {len(self.weather_data.columns)}개 - {list(self.weather_data.columns[:5])}...\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(\"⚠️  기상 데이터 파일을 찾을 수 없음 (weather_daily_processed.csv)\")\n",
    "            self.weather_data = None\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 기상 데이터 로딩 실패: {e}\")\n",
    "            self.weather_data = None\n",
    "        \n",
    "        try:\n",
    "            # 달력 데이터 로딩\n",
    "            print(\"\\n📅 달력 데이터 로딩 중...\")\n",
    "            self.calendar_data = pd.read_csv('power_analysis_calendar_2022_2025.csv')\n",
    "            \n",
    "            # 날짜 컬럼 전처리\n",
    "            self.calendar_data['date'] = pd.to_datetime(self.calendar_data['date'])\n",
    "            \n",
    "            print(f\"✅ 달력 데이터 로딩 완료: {len(self.calendar_data):,}일\")\n",
    "            print(f\"   기간: {self.calendar_data['date'].min().date()} ~ {self.calendar_data['date'].max().date()}\")\n",
    "            print(f\"   컬럼: {len(self.calendar_data.columns)}개 - {list(self.calendar_data.columns[:5])}...\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(\"⚠️  달력 데이터 파일을 찾을 수 없음 (power_analysis_calendar_2022_2025.csv)\")\n",
    "            self.calendar_data = None\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 달력 데이터 로딩 실패: {e}\")\n",
    "            self.calendar_data = None\n",
    "    \n",
    "    def _create_customer_profiles_from_data(self, customer_df=None):\n",
    "        \"\"\"실제 고객 정보를 기반으로 고객 프로파일 생성\"\"\"\n",
    "        profiles = {}\n",
    "        \n",
    "        if customer_df is not None:\n",
    "            # 실제 고객 데이터가 있는 경우\n",
    "            for _, customer in customer_df.iterrows():\n",
    "                customer_id = customer['고객번호']\n",
    "                \n",
    "                # 계약전력에서 base_power 추정\n",
    "                contract_power = customer['계약전력']\n",
    "                if '100~199' in str(contract_power):\n",
    "                    base_power = np.random.uniform(80, 120)\n",
    "                elif '200~299' in str(contract_power):\n",
    "                    base_power = np.random.uniform(120, 180)\n",
    "                elif '400~499' in str(contract_power):\n",
    "                    base_power = np.random.uniform(200, 280)\n",
    "                elif '500~599' in str(contract_power):\n",
    "                    base_power = np.random.uniform(280, 360)\n",
    "                elif '700~799' in str(contract_power):\n",
    "                    base_power = np.random.uniform(400, 500)\n",
    "                elif '800~899' in str(contract_power):\n",
    "                    base_power = np.random.uniform(500, 650)\n",
    "                else:\n",
    "                    base_power = np.random.uniform(100, 200)\n",
    "                \n",
    "                # 사용용도별 패턴 정의\n",
    "                usage_type = customer['사용용도']\n",
    "                if '상업용' in str(usage_type):\n",
    "                    peak_hours = [9, 14, 19]  # 상업용: 오전, 오후, 저녁 피크\n",
    "                    weekend_factor = np.random.uniform(0.7, 1.3)  # 상업용은 주말 변동 큼\n",
    "                else:  # 광공업용\n",
    "                    peak_hours = [8, 13, 18]  # 산업용: 작업시간 피크\n",
    "                    weekend_factor = np.random.uniform(0.1, 0.4)  # 산업용은 주말 낮음\n",
    "                \n",
    "                # 계약종별 세부 조정\n",
    "                contract_type = customer['계약종별']\n",
    "                if '일반용' in str(contract_type):\n",
    "                    # 일반용은 더 불규칙한 패턴\n",
    "                    weekend_factor *= np.random.uniform(0.8, 1.5)\n",
    "                \n",
    "                # 산업분류별 특성 반영 (있는 경우)\n",
    "                industry = customer.get('산업분류(소)', '')\n",
    "                if '제조' in str(industry) or '생산' in str(industry):\n",
    "                    # 제조업은 더 일정한 패턴\n",
    "                    weekend_factor *= 0.3\n",
    "                    peak_hours = [8, 13, 18, 22]  # 교대근무 고려\n",
    "                \n",
    "                profiles[customer_id] = {\n",
    "                    'type': self._classify_business_type(customer),\n",
    "                    'base_power': round(base_power, 1),\n",
    "                    'peak_hours': peak_hours,\n",
    "                    'weekend_factor': round(weekend_factor, 2),\n",
    "                    'contract_power': contract_power,\n",
    "                    'usage_type': usage_type\n",
    "                }\n",
    "        else:\n",
    "            # 샘플 데이터용 기본 프로파일\n",
    "            profiles = self._get_default_sample_profiles()\n",
    "        \n",
    "        return profiles\n",
    "    \n",
    "    def _classify_business_type(self, customer):\n",
    "        \"\"\"고객 정보를 바탕으로 업종 분류\"\"\"\n",
    "        usage_type = str(customer['사용용도'])\n",
    "        contract_type = str(customer['계약종별'])\n",
    "        industry = str(customer.get('산업분류(소)', ''))\n",
    "        product = str(customer.get('주생산품', ''))\n",
    "        \n",
    "        # 사용용도 기반 1차 분류\n",
    "        if '상업용' in usage_type:\n",
    "            if '일반용' in contract_type:\n",
    "                return 'commercial'  # 상가, 사무소 등\n",
    "            else:\n",
    "                return 'service'     # 대형 서비스업\n",
    "        else:  # 광공업용\n",
    "            if any(keyword in industry.lower() for keyword in ['제조', '생산', '공장']):\n",
    "                return 'manufacturing'\n",
    "            else:\n",
    "                return 'industrial'\n",
    "        \n",
    "    def _get_default_sample_profiles(self):\n",
    "        \"\"\"샘플 데이터용 기본 프로파일\"\"\"\n",
    "        return {\n",
    "            'A1001': {'type': 'hospital', 'base_power': 120, 'peak_hours': [9, 14, 20], 'weekend_factor': 0.8},\n",
    "            'A1002': {'type': 'office', 'base_power': 80, 'peak_hours': [9, 14], 'weekend_factor': 0.3},\n",
    "            'A1003': {'type': 'retail', 'base_power': 100, 'peak_hours': [11, 15, 19], 'weekend_factor': 1.2},\n",
    "            'A1004': {'type': 'factory', 'base_power': 150, 'peak_hours': [8, 13, 18], 'weekend_factor': 0.1},\n",
    "            'A1005': {'type': 'restaurant', 'base_power': 90, 'peak_hours': [12, 18], 'weekend_factor': 1.1},\n",
    "            'A1006': {'type': 'gym', 'base_power': 70, 'peak_hours': [7, 18, 21], 'weekend_factor': 1.3},\n",
    "            'A1007': {'type': 'school', 'base_power': 110, 'peak_hours': [10, 14], 'weekend_factor': 0.2},\n",
    "            'A1008': {'type': 'hotel', 'base_power': 130, 'peak_hours': [8, 20], 'weekend_factor': 1.0},\n",
    "            'A1009': {'type': 'warehouse', 'base_power': 60, 'peak_hours': [9, 16], 'weekend_factor': 0.5},\n",
    "            'A1010': {'type': 'clinic', 'base_power': 85, 'peak_hours': [10, 15], 'weekend_factor': 0.6}\n",
    "        }\n",
    "\n",
    "    def _create_comprehensive_sample_data(self, customer_df=None):\n",
    "        \"\"\"포괄적인 테스트용 샘플 데이터 생성\"\"\"\n",
    "        data = []\n",
    "        customers = [f'A{1001+i}' for i in range(10)]  # A1001~A1010\n",
    "        start_date = datetime(2024, 3, 1)\n",
    "        days = 31  # 3월 전체\n",
    "        \n",
    "        # 동적 고객 프로파일 생성\n",
    "        customer_profiles = self._create_customer_profiles_from_data(customer_df)\n",
    "        \n",
    "        for customer in customers:\n",
    "            profile = customer_profiles[customer]\n",
    "            \n",
    "            for day in range(days):\n",
    "                current_date = start_date + timedelta(days=day)\n",
    "                is_weekend = current_date.weekday() >= 5\n",
    "                \n",
    "                for hour in range(24):\n",
    "                    for minute in [0, 15, 30, 45]:\n",
    "                        timestamp = current_date.replace(hour=hour, minute=minute)\n",
    "                        \n",
    "                        # 기본 전력 계산\n",
    "                        base_power = profile['base_power']\n",
    "                        \n",
    "                        # 시간대별 패턴 (사인파 기반)\n",
    "                        time_factor = 0.3 + 0.7 * (np.sin(2 * np.pi * hour / 24) + 1) / 2\n",
    "                        \n",
    "                        # 피크 시간 보정\n",
    "                        peak_factor = 1.0\n",
    "                        for peak_hour in profile['peak_hours']:\n",
    "                            if abs(hour - peak_hour) <= 1:\n",
    "                                peak_factor = 1.5\n",
    "                        \n",
    "                        # 주말 보정\n",
    "                        weekend_factor = profile['weekend_factor'] if is_weekend else 1.0\n",
    "                        \n",
    "                        # 최종 전력 계산\n",
    "                        power = base_power * time_factor * peak_factor * weekend_factor\n",
    "                        power += np.random.normal(0, power * 0.1)  # 10% 노이즈\n",
    "                        power = max(0, power)\n",
    "                        \n",
    "                        # 무효전력 계산\n",
    "                        reactive_lag = power * np.random.uniform(0.1, 0.3)\n",
    "                        reactive_lead = power * np.random.uniform(0.05, 0.15)\n",
    "                        apparent_power = np.sqrt(power**2 + (reactive_lag - reactive_lead)**2)\n",
    "                        \n",
    "                        data.append({\n",
    "                            '대체고객번호': customer,\n",
    "                            'LP수신일자': timestamp.strftime('%Y-%m-%d-%H:%M'),\n",
    "                            '순방향유효전력': round(power, 1),\n",
    "                            '지상무효': round(reactive_lag, 1),\n",
    "                            '진상무효': round(reactive_lead, 1),\n",
    "                            '피상전력': round(apparent_power, 1)\n",
    "                        })\n",
    "        \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def merge_with_external_data(self):\n",
    "        \"\"\"LP 데이터와 외부 데이터 결합\"\"\"\n",
    "        if self.lp_data is None:\n",
    "            print(\"❌ LP 데이터가 로딩되지 않음\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n=== 외부 데이터와 결합 ===\")\n",
    "        \n",
    "        # 일별 LP 데이터 집계\n",
    "        daily_lp = self.lp_data.groupby(['대체고객번호', 'date'])['순방향유효전력'].agg(['sum', 'mean', 'std', 'min', 'max']).reset_index()\n",
    "        daily_lp.columns = ['대체고객번호', 'date', 'daily_sum', 'daily_mean', 'daily_std', 'daily_min', 'daily_max']\n",
    "        daily_lp['date'] = pd.to_datetime(daily_lp['date'])\n",
    "        \n",
    "        # 기상 데이터와 결합\n",
    "        if self.weather_data is not None:\n",
    "            print(\"🌤️  기상 데이터 결합 중...\")\n",
    "            merged_data = daily_lp.merge(\n",
    "                self.weather_data[['date', '평균기온', '최고기온', '최저기온', '평균습도', '총강수량', '불쾌지수', '냉방필요도', '난방필요도']],\n",
    "                on='date',\n",
    "                how='left'\n",
    "            )\n",
    "            print(f\"   ✅ 기상 데이터 결합 완료: {merged_data['평균기온'].notna().sum():,}일 매칭\")\n",
    "        else:\n",
    "            merged_data = daily_lp.copy()\n",
    "        \n",
    "        # 달력 데이터와 결합\n",
    "        if self.calendar_data is not None:\n",
    "            print(\"📅 달력 데이터 결합 중...\")\n",
    "            merged_data = merged_data.merge(\n",
    "                self.calendar_data[['date', 'is_workday', 'is_weekend', 'is_holiday', 'is_consecutive_holiday', 'day_type']],\n",
    "                on='date',\n",
    "                how='left'\n",
    "            )\n",
    "            print(f\"   ✅ 달력 데이터 결합 완료: {merged_data['is_workday'].notna().sum():,}일 매칭\")\n",
    "        \n",
    "        # 결합된 데이터 저장\n",
    "        self.merged_daily_data = merged_data\n",
    "        \n",
    "        print(f\"\\n📊 결합된 데이터 요약:\")\n",
    "        print(f\"   총 레코드: {len(merged_data):,}개\")\n",
    "        print(f\"   고객 수: {merged_data['대체고객번호'].nunique():,}명\")\n",
    "        print(f\"   기간: {merged_data['date'].min().date()} ~ {merged_data['date'].max().date()}\")\n",
    "        print(f\"   컬럼 수: {len(merged_data.columns)}개\")\n",
    "        \n",
    "        return merged_data\n",
    "    \n",
    "    def analyze_weather_impact(self):\n",
    "        \"\"\"기상 요인이 전력 사용량에 미치는 영향 분석\"\"\"\n",
    "        if not hasattr(self, 'merged_daily_data') or self.weather_data is None:\n",
    "            print(\"⚠️  기상 데이터가 없어 기상 영향 분석을 건너뜁니다.\")\n",
    "            return None\n",
    "        \n",
    "        print(\"\\n=== 기상 요인 영향 분석 ===\")\n",
    "        \n",
    "        # 기상 변수별 상관관계 분석\n",
    "        weather_cols = ['평균기온', '최고기온', '최저기온', '평균습도', '총강수량', '불쾌지수', '냉방필요도', '난방필요도']\n",
    "        power_cols = ['daily_sum', 'daily_mean']\n",
    "        \n",
    "        correlations = {}\n",
    "        for weather_col in weather_cols:\n",
    "            if weather_col in self.merged_daily_data.columns:\n",
    "                corr_sum = self.merged_daily_data[weather_col].corr(self.merged_daily_data['daily_sum'])\n",
    "                corr_mean = self.merged_daily_data[weather_col].corr(self.merged_daily_data['daily_mean'])\n",
    "                correlations[weather_col] = {'sum': corr_sum, 'mean': corr_mean}\n",
    "        \n",
    "        print(\"🌡️  기상 요인별 상관관계 (전력사용량):\")\n",
    "        print(\"기상요인\\t\\t일총사용량\\t일평균사용량\")\n",
    "        for weather_factor, corrs in correlations.items():\n",
    "            print(f\"{weather_factor}\\t{corrs['sum']:.3f}\\t\\t{corrs['mean']:.3f}\")\n",
    "        \n",
    "        # 온도별 전력 사용 패턴\n",
    "        temp_bins = [-10, 0, 10, 20, 25, 30, 35, 50]\n",
    "        temp_labels = ['극한저온', '저온', '서늘', '적정', '따뜻', '더움', '고온']\n",
    "        \n",
    "        if '평균기온' in self.merged_daily_data.columns:\n",
    "            self.merged_daily_data['temp_category'] = pd.cut(\n",
    "                self.merged_daily_data['평균기온'], \n",
    "                bins=temp_bins, \n",
    "                labels=temp_labels, \n",
    "                include_lowest=True\n",
    "            )\n",
    "            \n",
    "            temp_power = self.merged_daily_data.groupby('temp_category')['daily_mean'].agg(['count', 'mean', 'std']).round(1)\n",
    "            \n",
    "            print(f\"\\n🌡️  온도별 전력 사용 패턴:\")\n",
    "            print(\"온도구간\\t일수\\t평균사용량\\t표준편차\")\n",
    "            for temp_cat in temp_power.index:\n",
    "                stats = temp_power.loc[temp_cat]\n",
    "                print(f\"{temp_cat}\\t{stats['count']}\\t{stats['mean']}\\t{stats['std']}\")\n",
    "        \n",
    "        return correlations\n",
    "    \n",
    "    def analyze_calendar_patterns(self):\n",
    "        \"\"\"달력 요인별 전력 사용 패턴 분석\"\"\"\n",
    "        if not hasattr(self, 'merged_daily_data') or self.calendar_data is None:\n",
    "            print(\"⚠️  달력 데이터가 없어 달력 패턴 분석을 건너뜁니다.\")\n",
    "            return None\n",
    "        \n",
    "        print(\"\\n=== 달력 패턴 분석 ===\")\n",
    "        \n",
    "        # 평일/주말/휴일별 패턴\n",
    "        if 'day_type' in self.merged_daily_data.columns:\n",
    "            day_type_stats = self.merged_daily_data.groupby('day_type')['daily_mean'].agg(['count', 'mean', 'std']).round(1)\n",
    "            \n",
    "            print(\"📅 일자 유형별 전력 사용 패턴:\")\n",
    "            print(\"일자유형\\t일수\\t평균사용량\\t표준편차\")\n",
    "            for day_type in day_type_stats.index:\n",
    "                stats = day_type_stats.loc[day_type]\n",
    "                print(f\"{day_type}\\t{stats['count']}\\t{stats['mean']}\\t{stats['std']}\")\n",
    "        \n",
    "        # 연휴 효과 분석\n",
    "        if 'is_consecutive_holiday' in self.merged_daily_data.columns:\n",
    "            holiday_effect = self.merged_daily_data.groupby('is_consecutive_holiday')['daily_mean'].agg(['count', 'mean']).round(1)\n",
    "            \n",
    "            print(f\"\\n🎊 연휴 효과 분석:\")\n",
    "            for is_holiday, stats in holiday_effect.iterrows():\n",
    "                holiday_label = \"연휴기간\" if is_holiday else \"일반기간\"\n",
    "                print(f\"{holiday_label}: 일수 {stats['count']}일, 평균 {stats['mean']}kW\")\n",
    "        \n",
    "        # 월별 패턴 (계절성)\n",
    "        self.merged_daily_data['month'] = self.merged_daily_data['date'].dt.month\n",
    "        monthly_stats = self.merged_daily_data.groupby('month')['daily_mean'].agg(['count', 'mean', 'std']).round(1)\n",
    "        \n",
    "        print(f\"\\n📊 월별 전력 사용 패턴:\")\n",
    "        print(\"월\\t일수\\t평균사용량\\t표준편차\")\n",
    "        for month in monthly_stats.index:\n",
    "            stats = monthly_stats.loc[month]\n",
    "            print(f\"{month}월\\t{stats['count']}\\t{stats['mean']}\\t{stats['std']}\")\n",
    "        \n",
    "        return {\n",
    "            'day_type_stats': day_type_stats if 'day_type' in self.merged_daily_data.columns else None,\n",
    "            'holiday_effect': holiday_effect if 'is_consecutive_holiday' in self.merged_daily_data.columns else None,\n",
    "            'monthly_stats': monthly_stats\n",
    "        }\n",
    "    \n",
    "    def analyze_hourly_patterns(self):\n",
    "        \"\"\"시간대별 전력 사용 패턴 분석\"\"\"\n",
    "        print(\"\\n=== 시간대별 전력 사용 패턴 분석 ===\")\n",
    "        \n",
    "        # 시간대별 평균 사용량\n",
    "        hourly_avg = self.lp_data.groupby('hour')['순방향유효전력'].agg(['mean', 'std', 'min', 'max']).round(1)\n",
    "        \n",
    "        print(\"📊 시간대별 평균 전력 사용량 (kW):\")\n",
    "        print(\"시간\\t평균\\t표준편차\\t최소\\t최대\")\n",
    "        for hour in range(24):\n",
    "            stats = hourly_avg.loc[hour]\n",
    "            print(f\"{hour:02d}시\\t{stats['mean']}\\t{stats['std']}\\t{stats['min']}\\t{stats['max']}\")\n",
    "        \n",
    "        # 피크/비피크 시간대 식별\n",
    "        peak_threshold = hourly_avg['mean'].quantile(0.8)\n",
    "        peak_hours = hourly_avg[hourly_avg['mean'] >= peak_threshold].index.tolist()\n",
    "        off_peak_hours = hourly_avg[hourly_avg['mean'] < hourly_avg['mean'].quantile(0.3)].index.tolist()\n",
    "        \n",
    "        print(f\"\\n⚡ 피크 시간대 (상위 20%): {peak_hours}시\")\n",
    "        print(f\"💤 비피크 시간대 (하위 30%): {off_peak_hours}시\")\n",
    "        \n",
    "        return {\n",
    "            'hourly_stats': hourly_avg,\n",
    "            'peak_hours': peak_hours,\n",
    "            'off_peak_hours': off_peak_hours\n",
    "        }\n",
    "    \n",
    "    def analyze_daily_patterns(self):\n",
    "        \"\"\"일별/요일별 패턴 분석\"\"\"\n",
    "        print(\"\\n=== 일별/요일별 패턴 분석 ===\")\n",
    "        \n",
    "        # 일별 총 사용량\n",
    "        daily_usage = self.lp_data.groupby(['대체고객번호', 'date'])['순방향유효전력'].sum().reset_index()\n",
    "        daily_usage['weekday'] = pd.to_datetime(daily_usage['date']).dt.weekday\n",
    "        daily_usage['is_weekend'] = daily_usage['weekday'].isin([5, 6])\n",
    "        \n",
    "        # 요일별 평균 사용량\n",
    "        weekday_avg = daily_usage.groupby('weekday')['순방향유효전력'].agg(['mean', 'std']).round(1)\n",
    "        weekday_names = ['월', '화', '수', '목', '금', '토', '일']\n",
    "        \n",
    "        print(\"📅 요일별 평균 일간 사용량 (kWh):\")\n",
    "        for i, day_name in enumerate(weekday_names):\n",
    "            stats = weekday_avg.loc[i]\n",
    "            print(f\"{day_name}요일: {stats['mean']:,.1f} ± {stats['std']:.1f}\")\n",
    "        \n",
    "        # 평일 vs 주말 비교\n",
    "        weekday_mean = daily_usage[~daily_usage['is_weekend']]['순방향유효전력'].mean()\n",
    "        weekend_mean = daily_usage[daily_usage['is_weekend']]['순방향유효전력'].mean()\n",
    "        weekend_ratio = weekend_mean / weekday_mean\n",
    "        \n",
    "        print(f\"\\n📊 평일 vs 주말 비교:\")\n",
    "        print(f\"평일 평균: {weekday_mean:,.1f} kWh\")\n",
    "        print(f\"주말 평균: {weekend_mean:,.1f} kWh\")\n",
    "        print(f\"주말/평일 비율: {weekend_ratio:.2f}\")\n",
    "        \n",
    "        return {\n",
    "            'daily_usage': daily_usage,\n",
    "            'weekday_stats': weekday_avg,\n",
    "            'weekend_ratio': weekend_ratio\n",
    "        }\n",
    "    \n",
    "    def analyze_customer_profiles(self):\n",
    "        \"\"\"고객별 사용량 프로파일 분석\"\"\"\n",
    "        print(\"\\n=== 고객별 사용량 프로파일 분석 ===\")\n",
    "        \n",
    "        # 고객별 기본 통계\n",
    "        customer_stats = self.lp_data.groupby('대체고객번호')['순방향유효전력'].agg([\n",
    "            'count', 'mean', 'std', 'min', 'max'\n",
    "        ]).round(1)\n",
    "        customer_stats['cv'] = (customer_stats['std'] / customer_stats['mean']).round(3)  # 변동계수\n",
    "        \n",
    "        print(\"👥 고객별 기본 통계 (kW):\")\n",
    "        print(\"고객번호\\t평균\\t표준편차\\t변동계수\\t최소\\t최대\")\n",
    "        for customer in customer_stats.index:\n",
    "            stats = customer_stats.loc[customer]\n",
    "            print(f\"{customer}\\t{stats['mean']}\\t{stats['std']}\\t{stats['cv']}\\t{stats['min']}\\t{stats['max']}\")\n",
    "        \n",
    "        # 사용량 규모별 분류\n",
    "        mean_usage = customer_stats['mean']\n",
    "        high_users = mean_usage[mean_usage >= mean_usage.quantile(0.8)].index.tolist()\n",
    "        low_users = mean_usage[mean_usage <= mean_usage.quantile(0.2)].index.tolist()\n",
    "        \n",
    "        print(f\"\\n📈 대용량 사용자 (상위 20%): {high_users}\")\n",
    "        print(f\"📉 소용량 사용자 (하위 20%): {low_users}\")\n",
    "        \n",
    "        # 변동성별 분류\n",
    "        high_volatility = customer_stats[customer_stats['cv'] >= customer_stats['cv'].quantile(0.8)].index.tolist()\n",
    "        low_volatility = customer_stats[customer_stats['cv'] <= customer_stats['cv'].quantile(0.2)].index.tolist()\n",
    "        \n",
    "        print(f\"\\n🌊 고변동성 고객: {high_volatility}\")\n",
    "        print(f\"📊 저변동성 고객: {low_volatility}\")\n",
    "        \n",
    "        return {\n",
    "            'customer_stats': customer_stats,\n",
    "            'usage_segments': {\n",
    "                'high_users': high_users,\n",
    "                'low_users': low_users,\n",
    "                'high_volatility': high_volatility,\n",
    "                'low_volatility': low_volatility\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def calculate_load_factors(self):\n",
    "        \"\"\"부하율 및 효율성 지표 계산\"\"\"\n",
    "        print(\"\\n=== 부하율 및 효율성 지표 계산 ===\")\n",
    "        \n",
    "        # 고객별 부하율 계산\n",
    "        customer_load_factors = {}\n",
    "        \n",
    "        for customer in self.lp_data['대체고객번호'].unique():\n",
    "            customer_data = self.lp_data[self.lp_data['대체고객번호'] == customer]\n",
    "            \n",
    "            avg_load = customer_data['순방향유효전력'].mean()\n",
    "            max_load = customer_data['순방향유효전력'].max()\n",
    "            load_factor = avg_load / max_load if max_load > 0 else 0\n",
    "            \n",
    "            # 피크 집중도 (피크 시간대 사용량 비중)\n",
    "            peak_hours = [9, 14, 18]  # 대표 피크 시간\n",
    "            peak_usage = customer_data[customer_data['hour'].isin(peak_hours)]['순방향유효전력'].mean()\n",
    "            total_avg = customer_data['순방향유효전력'].mean()\n",
    "            peak_concentration = peak_usage / total_avg if total_avg > 0 else 0\n",
    "            \n",
    "            customer_load_factors[customer] = {\n",
    "                'load_factor': round(load_factor, 3),\n",
    "                'peak_concentration': round(peak_concentration, 3),\n",
    "                'avg_load': round(avg_load, 1),\n",
    "                'max_load': round(max_load, 1)\n",
    "            }\n",
    "        \n",
    "        print(\"⚡ 고객별 부하율 및 피크 집중도:\")\n",
    "        print(\"고객번호\\t부하율\\t피크집중도\\t평균부하\\t최대부하\")\n",
    "        for customer, metrics in customer_load_factors.items():\n",
    "            print(f\"{customer}\\t{metrics['load_factor']}\\t{metrics['peak_concentration']}\\t{metrics['avg_load']}\\t{metrics['max_load']}\")\n",
    "        \n",
    "        # 전체 부하율 분포\n",
    "        load_factors = [metrics['load_factor'] for metrics in customer_load_factors.values()]\n",
    "        avg_load_factor = np.mean(load_factors)\n",
    "        \n",
    "        print(f\"\\n📊 전체 부하율 분포:\")\n",
    "        print(f\"평균 부하율: {avg_load_factor:.3f}\")\n",
    "        print(f\"부하율 범위: {min(load_factors):.3f} ~ {max(load_factors):.3f}\")\n",
    "        \n",
    "        return customer_load_factors\n",
    "    \n",
    "    def detect_usage_anomalies(self):\n",
    "        \"\"\"사용량 이상 패턴 탐지\"\"\"\n",
    "        print(\"\\n=== 사용량 이상 패턴 탐지 ===\")\n",
    "        \n",
    "        anomalies = []\n",
    "        \n",
    "        for customer in self.lp_data['대체고객번호'].unique():\n",
    "            customer_data = self.lp_data[self.lp_data['대체고객번호'] == customer].copy()\n",
    "            customer_data = customer_data.sort_values('datetime')\n",
    "            \n",
    "            # 1. 급격한 변화 탐지 (전시점 대비 200% 이상 변화)\n",
    "            customer_data['power_change'] = customer_data['순방향유효전력'].pct_change()\n",
    "            sudden_changes = customer_data[abs(customer_data['power_change']) > 2.0]\n",
    "            \n",
    "            # 2. 연속적인 0값 탐지 (2시간 이상)\n",
    "            customer_data['is_zero'] = customer_data['순방향유효전력'] == 0\n",
    "            customer_data['zero_group'] = (customer_data['is_zero'] != customer_data['is_zero'].shift()).cumsum()\n",
    "            zero_periods = customer_data[customer_data['is_zero']].groupby('zero_group').size()\n",
    "            long_zero_periods = zero_periods[zero_periods >= 8]  # 2시간 = 8개 15분 구간\n",
    "            \n",
    "            # 3. 통계적 이상치 (Z-score > 3)\n",
    "            mean_power = customer_data['순방향유효전력'].mean()\n",
    "            std_power = customer_data['순방향유효전력'].std()\n",
    "            if std_power > 0:\n",
    "                customer_data['z_score'] = abs(customer_data['순방향유효전력'] - mean_power) / std_power\n",
    "                statistical_outliers = customer_data[customer_data['z_score'] > 3]\n",
    "            else:\n",
    "                statistical_outliers = pd.DataFrame()\n",
    "            \n",
    "            # 이상치 정보 저장\n",
    "            if len(sudden_changes) > 0 or len(long_zero_periods) > 0 or len(statistical_outliers) > 0:\n",
    "                anomalies.append({\n",
    "                    'customer': customer,\n",
    "                    'sudden_changes': len(sudden_changes),\n",
    "                    'long_zero_periods': len(long_zero_periods),\n",
    "                    'statistical_outliers': len(statistical_outliers)\n",
    "                })\n",
    "        \n",
    "        print(\"🚨 이상 패턴 탐지 결과:\")\n",
    "        if anomalies:\n",
    "            print(\"고객번호\\t급격변화\\t장기0값\\t통계이상치\")\n",
    "            for anomaly in anomalies:\n",
    "                print(f\"{anomaly['customer']}\\t{anomaly['sudden_changes']}\\t{anomaly['long_zero_periods']}\\t{anomaly['statistical_outliers']}\")\n",
    "        else:\n",
    "            print(\"✅ 심각한 이상 패턴 없음\")\n",
    "        \n",
    "        return anomalies\n",
    "    \n",
    "    def generate_enhanced_pattern_summary(self):\n",
    "        \"\"\"강화된 패턴 분석 종합 요약\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📊 강화된 시계열 패턴 분석 종합 요약\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 외부 데이터 로딩\n",
    "        self.load_external_data()\n",
    "        \n",
    "        # 데이터 결합\n",
    "        merged_data = self.merge_with_external_data()\n",
    "        \n",
    "        # 기존 패턴 분석\n",
    "        hourly_stats = self.analyze_hourly_patterns()\n",
    "        daily_stats = self.analyze_daily_patterns()\n",
    "        customer_stats = self.analyze_customer_profiles()\n",
    "        load_factors = self.calculate_load_factors()\n",
    "        anomalies = self.detect_usage_anomalies()\n",
    "        \n",
    "        # 강화된 분석 (외부 데이터 활용)\n",
    "        weather_impact = self.analyze_weather_impact()\n",
    "        calendar_patterns = self.analyze_calendar_patterns()\n",
    "        \n",
    "        print(\"\\n🔍 주요 발견사항:\")\n",
    "        \n",
    "        # 1. 시간 패턴\n",
    "        peak_hours = hourly_stats['peak_hours']\n",
    "        print(f\"  • 주요 피크 시간: {peak_hours}시\")\n",
    "        \n",
    "        # 2. 요일 패턴  \n",
    "        weekend_ratio = daily_stats['weekend_ratio']\n",
    "        print(f\"  • 주말/평일 사용량 비율: {weekend_ratio:.2f}\")\n",
    "        \n",
    "        # 3. 고객 다양성\n",
    "        cv_range = customer_stats['customer_stats']['cv']\n",
    "        print(f\"  • 고객별 변동계수 범위: {cv_range.min():.3f} ~ {cv_range.max():.3f}\")\n",
    "        \n",
    "        # 4. 부하율\n",
    "        load_factor_avg = np.mean([lf['load_factor'] for lf in load_factors.values()])\n",
    "        print(f\"  • 평균 부하율: {load_factor_avg:.3f}\")\n",
    "        \n",
    "        # 5. 이상 패턴\n",
    "        anomaly_customers = len(anomalies)\n",
    "        print(f\"  • 이상 패턴 고객: {anomaly_customers}명\")\n",
    "        \n",
    "        # 6. 기상 영향 (있는 경우)\n",
    "        if weather_impact:\n",
    "            temp_corr = weather_impact.get('평균기온', {}).get('mean', 0)\n",
    "            humidity_corr = weather_impact.get('평균습도', {}).get('mean', 0)\n",
    "            print(f\"  • 기온과 전력사용량 상관관계: {temp_corr:.3f}\")\n",
    "            print(f\"  • 습도와 전력사용량 상관관계: {humidity_corr:.3f}\")\n",
    "        \n",
    "        # 7. 달력 효과 (있는 경우)\n",
    "        if calendar_patterns and calendar_patterns.get('holiday_effect') is not None:\n",
    "            holiday_effect = calendar_patterns['holiday_effect']\n",
    "            if len(holiday_effect) >= 2:\n",
    "                normal_avg = holiday_effect.loc[False, 'mean'] if False in holiday_effect.index else 0\n",
    "                holiday_avg = holiday_effect.loc[True, 'mean'] if True in holiday_effect.index else 0\n",
    "                if normal_avg > 0:\n",
    "                    holiday_ratio = holiday_avg / normal_avg\n",
    "                    print(f\"  • 연휴/일반 사용량 비율: {holiday_ratio:.3f}\")\n",
    "        \n",
    "        print(\"\\n💡 강화된 변동계수 설계를 위한 인사이트:\")\n",
    "        print(\"  1. 시간대별 가중치 필요 (피크/비피크 구분)\")\n",
    "        print(\"  2. 요일별 보정 계수 고려\") \n",
    "        print(\"  3. 고객별 기준 변동성 설정\")\n",
    "        print(\"  4. 부하율과 변동성의 상관관계 분석\")\n",
    "        print(\"  5. 기상 요인 보정 (온도, 습도, 강수량)\")\n",
    "        print(\"  6. 달력 효과 반영 (휴일, 연휴, 계절성)\")\n",
    "        print(\"  7. 다차원 변동성 지표 조합 검토\")\n",
    "        print(\"  8. 이상 패턴 필터링 메커니즘\")\n",
    "        \n",
    "        return {\n",
    "            'hourly_patterns': hourly_stats,\n",
    "            'daily_patterns': daily_stats,\n",
    "            'customer_profiles': customer_stats,\n",
    "            'load_factors': load_factors,\n",
    "            'anomalies': anomalies,\n",
    "            'weather_impact': weather_impact,\n",
    "            'calendar_patterns': calendar_patterns,\n",
    "            'merged_data': merged_data\n",
    "        }\n",
    "    \n",
    "    def generate_pattern_summary(self):\n",
    "        \"\"\"기존 패턴 분석 종합 요약 (하위 호환성)\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"📊 시계열 패턴 분석 종합 요약\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # 주요 패턴 특성\n",
    "        hourly_stats = self.analyze_hourly_patterns()\n",
    "        daily_stats = self.analyze_daily_patterns()\n",
    "        customer_stats = self.analyze_customer_profiles()\n",
    "        load_factors = self.calculate_load_factors()\n",
    "        anomalies = self.detect_usage_anomalies()\n",
    "        \n",
    "        print(\"\\n🔍 주요 발견사항:\")\n",
    "        \n",
    "        # 1. 시간 패턴\n",
    "        peak_hours = hourly_stats['peak_hours']\n",
    "        print(f\"  • 주요 피크 시간: {peak_hours}시\")\n",
    "        \n",
    "        # 2. 요일 패턴  \n",
    "        weekend_ratio = daily_stats['weekend_ratio']\n",
    "        print(f\"  • 주말/평일 사용량 비율: {weekend_ratio:.2f}\")\n",
    "        \n",
    "        # 3. 고객 다양성\n",
    "        cv_range = customer_stats['customer_stats']['cv']\n",
    "        print(f\"  • 고객별 변동계수 범위: {cv_range.min():.3f} ~ {cv_range.max():.3f}\")\n",
    "        \n",
    "        # 4. 부하율\n",
    "        load_factor_avg = np.mean([lf['load_factor'] for lf in load_factors.values()])\n",
    "        print(f\"  • 평균 부하율: {load_factor_avg:.3f}\")\n",
    "        \n",
    "        # 5. 이상 패턴\n",
    "        anomaly_customers = len(anomalies)\n",
    "        print(f\"  • 이상 패턴 고객: {anomaly_customers}명\")\n",
    "        \n",
    "        print(\"\\n💡 변동계수 설계를 위한 인사이트:\")\n",
    "        print(\"  1. 시간대별 가중치 필요 (피크/비피크 구분)\")\n",
    "        print(\"  2. 요일별 보정 계수 고려\") \n",
    "        print(\"  3. 고객별 기준 변동성 설정\")\n",
    "        print(\"  4. 부하율과 변동성의 상관관계 분석\")\n",
    "        print(\"  5. 다차원 변동성 지표 조합 검토\")\n",
    "        \n",
    "        return {\n",
    "            'hourly_patterns': hourly_stats,\n",
    "            'daily_patterns': daily_stats,\n",
    "            'customer_profiles': customer_stats,\n",
    "            'load_factors': load_factors,\n",
    "            'anomalies': anomalies\n",
    "        }\n",
    "\n",
    "# 사용 예제\n",
    "if __name__ == \"__main__\":\n",
    "    # 분석기 초기화\n",
    "    analyzer = KEPCOTimeSeriesAnalyzer()\n",
    "    \n",
    "    print(\"🔧 실제 환경에서 사용 방법 (3000호):\")\n",
    "    print(\"\"\"\n",
    "    # 실제 LP 데이터만 로딩하면 끝!\n",
    "    lp_files = ['LP데이터1.csv', 'LP데이터2.csv']\n",
    "    analyzer.load_real_lp_data(lp_files)\n",
    "    \n",
    "    # 실제 데이터로 패턴 분석\n",
    "    enhanced_summary = analyzer.generate_enhanced_pattern_summary()\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"🧪 현재는 테스트용 샘플 데이터로 시연\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 테스트용으로만 샘플 데이터 생성\n",
    "    lp_data = analyzer.load_sample_data()\n",
    "    \n",
    "    # 패턴 분석 실행\n",
    "    pattern_summary = analyzer.generate_pattern_summary()\n",
    "    \n",
    "    print(\"\\n💡 핵심 포인트:\")\n",
    "    print(\"  ✅ 실제 환경: 실제 LP 데이터 그대로 분석\")\n",
    "    print(\"  ✅ 테스트용: 샘플 데이터로 알고리즘 검증\")\n",
    "    print(\"  ✅ 3000호: 실제 데이터 있으니 프로파일 생성 불필요\")\n",
    "    print(\"  ✅ 패턴 분석: 실제 사용량에서 변동성 지표 계산\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
