{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e087110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "한국전력공사 변동계수 알고리즘 - 독립 실행\n",
      "============================================================\n",
      "⚠️ 결과 폴더를 찾을 수 없습니다.\n",
      "다음 중 하나의 폴더에 1-2단계 결과를 저장하세요:\n",
      "   - ./analysis_results\n",
      "   - ./results\n",
      "   - ./output\n",
      "✅ 기본 폴더 생성: ./analysis_results\n",
      "🔧 한국전력공사 변동계수 알고리즘 초기화\n",
      "결과 폴더: ./analysis_results\n",
      "📂 1-2단계 결과 파일 로드 중...\n",
      "⚠️ 1단계 결과 파일 없음: ./analysis_results\\analysis_results.json\n",
      "⚠️ 2단계 결과 파일 없음: ./analysis_results\\volatility_summary.csv\n",
      "🚀 변동계수 알고리즘 분석 시작\n",
      "시작 시간: 2025-07-08 15:24:31.688578\n",
      "📊 실제 데이터로 특성 생성...\n",
      "📂 원본 LP 데이터 로드...\n",
      "❌ 데이터 로드 실패: LP 데이터 파일을 찾을 수 없습니다.\n",
      "샘플 데이터로 테스트 실행...\n",
      "🧪 샘플 특성 데이터 생성...\n",
      "🚀 스태킹 모델 학습...\n",
      "❌ 분석 실패: 'KEPCOVolatilityCoefficient' object has no attribute 'fit'\n",
      "\\n💥 변동계수 분석 중 오류가 발생했습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\khmin\\AppData\\Local\\Temp\\ipykernel_28056\\3077651523.py\", line 376, in run_complete_analysis\n",
      "    training_results = self.fit(features_dict)\n",
      "                       ^^^^^^^^\n",
      "AttributeError: 'KEPCOVolatilityCoefficient' object has no attribute 'fit'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 한국전력공사 변동계수 알고리즘 - 독립 실행용\n",
    "# 1-2단계 결과 파일을 로드해서 실행\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "import warnings\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class KEPCOVolatilityCoefficient:\n",
    "    \"\"\"\n",
    "    한국전력공사 전력 사용패턴 변동계수 스태킹 알고리즘\n",
    "    1-2단계 결과 파일을 자동으로 로드해서 실행\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, results_path='./analysis_results'):\n",
    "        \"\"\"\n",
    "        초기화\n",
    "        Args:\n",
    "            results_path: 1-2단계 결과가 저장된 폴더 경로\n",
    "        \"\"\"\n",
    "        self.results_path = results_path\n",
    "        \n",
    "        # 기본 설정 (1-2단계 결과로 자동 업데이트됨)\n",
    "        self.config = {\n",
    "            'temporal_weights': {\n",
    "                'peak_hours': [9, 10, 11, 14, 15, 18, 19, 20],  \n",
    "                'peak_weight': 1.5,                               \n",
    "                'off_peak_weight': 0.8                            \n",
    "            },\n",
    "            'seasonal_adjustment': {\n",
    "                'summer_months': [6, 7, 8],      \n",
    "                'winter_months': [12, 1, 2],     \n",
    "                'summer_factor': 1.2,            \n",
    "                'winter_factor': 1.1             \n",
    "            },\n",
    "            'industry_baselines': {\n",
    "                '222': 0.25,  # 일반용(갑)‖고압A\n",
    "                '226': 0.30,  # 일반용(을) 고압A  \n",
    "                '311': 0.35,  # 산업용(갑) 저압\n",
    "                '322': 0.20,  # 산업용(갑)‖고압A\n",
    "                '726': 0.28   # 산업용(을) 고압A\n",
    "            },\n",
    "            'usage_type_factors': {\n",
    "                '02': 1.1,    # 상업용\n",
    "                '09': 0.9     # 광공업용\n",
    "            },\n",
    "            'anomaly_thresholds': {\n",
    "                'cv_extreme': 1.0,           \n",
    "                'zero_ratio_max': 0.1,       \n",
    "                'night_day_ratio_max': 0.8   \n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 모델 구성요소\n",
    "        self.level0_models = {}\n",
    "        self.level1_model = None\n",
    "        self.scalers = {}\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        # 과적합 방지 설정\n",
    "        self.cv_folds = 5\n",
    "        self.random_state = 42\n",
    "        \n",
    "        print(\"🔧 한국전력공사 변동계수 알고리즘 초기화\")\n",
    "        print(f\"결과 폴더: {self.results_path}\")\n",
    "        \n",
    "        # 🔥 핵심: 1-2단계 결과 자동 로드\n",
    "        self._load_previous_results()\n",
    "    \n",
    "    def _load_previous_results(self):\n",
    "        \"\"\"\n",
    "        1-2단계 결과 파일들을 자동으로 로드해서 설정 업데이트\n",
    "        \"\"\"\n",
    "        print(\"📂 1-2단계 결과 파일 로드 중...\")\n",
    "        \n",
    "        try:\n",
    "            # 1단계 결과 로드\n",
    "            step1_file = os.path.join(self.results_path, 'analysis_results.json')\n",
    "            if os.path.exists(step1_file):\n",
    "                with open(step1_file, 'r', encoding='utf-8') as f:\n",
    "                    step1_results = json.load(f)\n",
    "                print(\"✅ 1단계 결과 로드 완료\")\n",
    "                self._update_config_from_step1(step1_results)\n",
    "            else:\n",
    "                print(f\"⚠️ 1단계 결과 파일 없음: {step1_file}\")\n",
    "            \n",
    "            # 2단계 결과 로드\n",
    "            step2_file = os.path.join(self.results_path, 'volatility_summary.csv')\n",
    "            if os.path.exists(step2_file):\n",
    "                step2_results = pd.read_csv(step2_file)\n",
    "                print(\"✅ 2단계 결과 로드 완료\")\n",
    "                self._update_config_from_step2(step2_results)\n",
    "            else:\n",
    "                print(f\"⚠️ 2단계 결과 파일 없음: {step2_file}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 결과 파일 로드 중 오류: {e}\")\n",
    "            print(\"기본 설정으로 진행합니다.\")\n",
    "    \n",
    "    def _update_config_from_step1(self, step1_results):\n",
    "        \"\"\"1단계 결과로 설정 업데이트\"\"\"\n",
    "        print(\"🔄 1단계 결과로 설정 업데이트...\")\n",
    "        \n",
    "        # 고객 분포 정보\n",
    "        customer_summary = step1_results.get('customer_summary', {})\n",
    "        if customer_summary:\n",
    "            total_customers = customer_summary.get('total_customers', 3000)\n",
    "            print(f\"   고객 수: {total_customers:,}명\")\n",
    "            \n",
    "            # 계약종별 분포로 기준값 조정\n",
    "            contract_types = customer_summary.get('contract_types', {})\n",
    "            if contract_types:\n",
    "                print(f\"   계약종별: {len(contract_types)}개 유형\")\n",
    "                \n",
    "                # 각 계약종별 비율에 따라 기준값 미세 조정\n",
    "                total_contracts = sum(contract_types.values())\n",
    "                for contract, count in contract_types.items():\n",
    "                    if str(contract) in self.config['industry_baselines']:\n",
    "                        ratio = count / total_contracts\n",
    "                        # 비율이 높은 계약종별은 기준값을 약간 낮춤 (더 엄격하게)\n",
    "                        if ratio > 0.3:  # 30% 이상 차지하는 경우\n",
    "                            self.config['industry_baselines'][str(contract)] *= 0.95\n",
    "    \n",
    "    def _update_config_from_step2(self, step2_results):\n",
    "        \"\"\"2단계 결과로 설정 업데이트\"\"\"\n",
    "        print(\"🔄 2단계 결과로 설정 업데이트...\")\n",
    "        \n",
    "        # volatility_summary.csv에서 핵심 지표 추출\n",
    "        for _, row in step2_results.iterrows():\n",
    "            metric = row['metric']\n",
    "            value = row['value']\n",
    "            \n",
    "            if metric == 'overall_cv':\n",
    "                # 전체 변동계수를 기준으로 업종별 기준값 조정\n",
    "                baseline_adjustment = value / 0.25  # 기본 0.25 대비\n",
    "                for contract_type in self.config['industry_baselines']:\n",
    "                    self.config['industry_baselines'][contract_type] *= baseline_adjustment\n",
    "                print(f\"   전체 CV 기준 조정: {baseline_adjustment:.3f}배\")\n",
    "                \n",
    "            elif metric == 'weekday_cv' and 'weekend_cv' in step2_results['metric'].values:\n",
    "                # 주말/평일 변동성 차이\n",
    "                weekend_row = step2_results[step2_results['metric'] == 'weekend_cv']\n",
    "                if not weekend_row.empty:\n",
    "                    weekend_cv = weekend_row['value'].iloc[0]\n",
    "                    weekend_factor = weekend_cv / value if value > 0 else 1.0\n",
    "                    self.config['weekend_factor'] = weekend_factor\n",
    "                    print(f\"   주말 팩터: {weekend_factor:.3f}\")\n",
    "        \n",
    "        print(\"✅ 설정 업데이트 완료\")\n",
    "    \n",
    "    def load_actual_data_for_features(self):\n",
    "        \"\"\"\n",
    "        실제 LP 데이터를 로드해서 특성 생성\n",
    "        (1-2단계에서 전처리된 데이터 활용)\n",
    "        \"\"\"\n",
    "        print(\"📊 실제 데이터로 특성 생성...\")\n",
    "        \n",
    "        try:\n",
    "            # 🔥 여기서 실제 LP 데이터를 로드해야 함\n",
    "            # 방법 1: 1-2단계에서 전처리된 데이터가 저장되어 있다면\n",
    "            processed_data_file = os.path.join(self.results_path, 'processed_lp_data.csv')\n",
    "            \n",
    "            if os.path.exists(processed_data_file):\n",
    "                print(\"📂 전처리된 LP 데이터 로드...\")\n",
    "                lp_data = pd.read_csv(processed_data_file)\n",
    "                lp_data['LP 수신일자'] = pd.to_datetime(lp_data['LP 수신일자'])\n",
    "            else:\n",
    "                # 방법 2: 원본 LP 데이터를 다시 로드 (1-2단계와 동일한 방식)\n",
    "                print(\"📂 원본 LP 데이터 로드...\")\n",
    "                lp_data = self._load_original_lp_data()\n",
    "            \n",
    "            # 고객 데이터도 로드\n",
    "            customer_file = os.path.join(os.path.dirname(self.results_path), '제13회 산업부 공모전 대상고객.xlsx')\n",
    "            if os.path.exists(customer_file):\n",
    "                customer_data = pd.read_excel(customer_file)\n",
    "            else:\n",
    "                customer_data = None\n",
    "                print(\"⚠️ 고객 데이터 파일 없음\")\n",
    "            \n",
    "            # 특성 생성\n",
    "            features_dict = self.create_features(lp_data, customer_data)\n",
    "            \n",
    "            print(f\"✅ 특성 생성 완료: {len(features_dict)}명\")\n",
    "            return features_dict\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 데이터 로드 실패: {e}\")\n",
    "            print(\"샘플 데이터로 테스트 실행...\")\n",
    "            return self._create_sample_features()\n",
    "    \n",
    "    def _load_original_lp_data(self):\n",
    "        \"\"\"원본 LP 데이터 로드 (1-2단계와 동일)\"\"\"\n",
    "        import glob\n",
    "        \n",
    "        base_path = os.path.dirname(self.results_path)\n",
    "        lp_files = glob.glob(os.path.join(base_path, 'processed_LPData_*.csv'))\n",
    "        \n",
    "        if not lp_files:\n",
    "            raise FileNotFoundError(\"LP 데이터 파일을 찾을 수 없습니다.\")\n",
    "        \n",
    "        dataframes = []\n",
    "        for file_path in sorted(lp_files):\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # 컬럼명 표준화\n",
    "            if 'LP수신일자' in df.columns:\n",
    "                df = df.rename(columns={'LP수신일자': 'LP 수신일자'})\n",
    "            if '순방향유효전력' in df.columns:\n",
    "                df = df.rename(columns={'순방향유효전력': '순방향 유효전력'})\n",
    "            \n",
    "            dataframes.append(df)\n",
    "        \n",
    "        lp_data = pd.concat(dataframes, ignore_index=True)\n",
    "        lp_data['LP 수신일자'] = pd.to_datetime(lp_data['LP 수신일자'])\n",
    "        \n",
    "        return lp_data\n",
    "    \n",
    "    def _create_sample_features(self):\n",
    "        \"\"\"샘플 특성 데이터 생성 (테스트용)\"\"\"\n",
    "        print(\"🧪 샘플 특성 데이터 생성...\")\n",
    "        \n",
    "        sample_features = {}\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        for i in range(100):  # 100명 샘플\n",
    "            customer_id = f'SAMPLE_{i:04d}'\n",
    "            \n",
    "            sample_features[customer_id] = {\n",
    "                'basic': {\n",
    "                    'cv_basic': np.random.normal(0.25, 0.1),\n",
    "                    'range_volatility': np.random.normal(0.8, 0.3),\n",
    "                    'iqr_volatility': np.random.normal(0.6, 0.2),\n",
    "                    'skewness': np.random.normal(0.5, 0.3),\n",
    "                    'kurtosis': np.random.normal(0.2, 0.5),\n",
    "                    'mean_power': np.random.normal(50, 20),\n",
    "                    'load_factor': np.random.normal(0.6, 0.2)\n",
    "                },\n",
    "                'temporal': {\n",
    "                    'peak_cv': np.random.normal(0.3, 0.1),\n",
    "                    'off_peak_cv': np.random.normal(0.2, 0.1),\n",
    "                    'peak_mean': np.random.normal(60, 25),\n",
    "                    'off_peak_mean': np.random.normal(40, 15),\n",
    "                    'peak_off_peak_ratio': np.random.normal(1.5, 0.3),\n",
    "                    'temporal_cv_diff': np.random.normal(0.1, 0.05),\n",
    "                    'weekday_weekend_cv_ratio': np.random.normal(1.2, 0.3)\n",
    "                },\n",
    "                'seasonal': {\n",
    "                    'summer_cv': np.random.normal(0.35, 0.15),\n",
    "                    'winter_cv': np.random.normal(0.3, 0.12),\n",
    "                    'summer_mean': np.random.normal(65, 30),\n",
    "                    'winter_mean': np.random.normal(55, 25),\n",
    "                    'seasonal_cv_diff': np.random.normal(0.05, 0.03),\n",
    "                    'seasonal_stability': np.random.normal(0.1, 0.05)\n",
    "                },\n",
    "                'pattern': {\n",
    "                    'daily_cv_stability': np.random.normal(0.05, 0.02),\n",
    "                    'daily_cv_mean': np.random.normal(0.25, 0.1),\n",
    "                    'autocorrelation': np.random.normal(0.7, 0.2),\n",
    "                    'trend_volatility': np.random.normal(0.1, 0.05)\n",
    "                },\n",
    "                'anomaly': {\n",
    "                    'zero_ratio': np.random.beta(1, 10),\n",
    "                    'sudden_change_ratio': np.random.beta(1, 20),\n",
    "                    'night_day_ratio': np.random.normal(0.4, 0.2),\n",
    "                    'outlier_ratio': np.random.beta(1, 30)\n",
    "                },\n",
    "                'customer': {\n",
    "                    'baseline_cv': 0.25,\n",
    "                    'usage_factor': np.random.choice([0.9, 1.1]),\n",
    "                    'contract_power_log': np.random.normal(6.0, 1.0)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        return sample_features\n",
    "    \n",
    "    # 나머지 메서드들은 이전 변동계수 알고리즘과 동일\n",
    "    # (create_features, fit, predict, classify_volatility_grade 등)\n",
    "    \n",
    "    def create_features(self, lp_data, customer_data=None):\n",
    "        \"\"\"실제 LP 데이터로 특성 생성\"\"\"\n",
    "        print(\"🔄 실제 데이터 특성 생성 중...\")\n",
    "        \n",
    "        features_dict = {}\n",
    "        customers = lp_data['대체고객번호'].unique()\n",
    "        \n",
    "        # 메모리 고려해서 최대 1000명으로 제한\n",
    "        if len(customers) > 1000:\n",
    "            customers = customers[:1000]\n",
    "            print(f\"   메모리 효율성을 위해 {len(customers)}명으로 제한\")\n",
    "        \n",
    "        for i, customer in enumerate(customers):\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"   진행: {i+1}/{len(customers)} ({(i+1)/len(customers)*100:.1f}%)\")\n",
    "            \n",
    "            customer_lp = lp_data[lp_data['대체고객번호'] == customer].copy()\n",
    "            \n",
    "            if len(customer_lp) < 96:  # 최소 1일 데이터 필요\n",
    "                continue\n",
    "            \n",
    "            # 시간 관련 파생 변수\n",
    "            customer_lp['시간'] = customer_lp['LP 수신일자'].dt.hour\n",
    "            customer_lp['요일'] = customer_lp['LP 수신일자'].dt.weekday\n",
    "            customer_lp['월'] = customer_lp['LP 수신일자'].dt.month\n",
    "            customer_lp['주말여부'] = customer_lp['요일'].isin([5, 6])\n",
    "            \n",
    "            power_series = customer_lp['순방향 유효전력']\n",
    "            \n",
    "            # 1. 기본 변동성 특성\n",
    "            basic_features = self._calculate_basic_volatility(power_series)\n",
    "            \n",
    "            # 2. 시간대별 변동성 특성\n",
    "            temporal_features = self._calculate_temporal_volatility(customer_lp)\n",
    "            \n",
    "            # 3. 계절성 변동성 특성  \n",
    "            seasonal_features = self._calculate_seasonal_volatility(customer_lp)\n",
    "            \n",
    "            # 4. 패턴 안정성 특성\n",
    "            pattern_features = self._calculate_pattern_stability(customer_lp)\n",
    "            \n",
    "            # 5. 이상 패턴 특성\n",
    "            anomaly_features = self._calculate_anomaly_features(customer_lp)\n",
    "            \n",
    "            # 6. 고객 특성\n",
    "            customer_features = {}\n",
    "            if customer_data is not None:\n",
    "                customer_info = customer_data[customer_data['고객번호'] == customer]\n",
    "                if not customer_info.empty:\n",
    "                    customer_features = self._get_customer_features(customer_info.iloc[0])\n",
    "                else:\n",
    "                    customer_features = {'baseline_cv': 0.25, 'usage_factor': 1.0, 'contract_power_log': 6.0}\n",
    "            else:\n",
    "                customer_features = {'baseline_cv': 0.25, 'usage_factor': 1.0, 'contract_power_log': 6.0}\n",
    "            \n",
    "            features_dict[customer] = {\n",
    "                'basic': basic_features,\n",
    "                'temporal': temporal_features,\n",
    "                'seasonal': seasonal_features,\n",
    "                'pattern': pattern_features,\n",
    "                'anomaly': anomaly_features,\n",
    "                'customer': customer_features\n",
    "            }\n",
    "        \n",
    "        print(f\"✅ 특성 생성 완료: {len(features_dict)}명\")\n",
    "        return features_dict\n",
    "    \n",
    "    # 이하 _calculate_* 메서드들은 이전 코드와 동일하므로 생략\n",
    "    # (실제 사용시에는 전체 메서드 포함)\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"전체 변동계수 분석 실행\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        print(\"🚀 변동계수 알고리즘 분석 시작\")\n",
    "        print(f\"시작 시간: {start_time}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. 특성 데이터 준비\n",
    "            features_dict = self.load_actual_data_for_features()\n",
    "            \n",
    "            if not features_dict:\n",
    "                print(\"❌ 특성 데이터 준비 실패\")\n",
    "                return False\n",
    "            \n",
    "            # 2. 모델 학습\n",
    "            print(\"🚀 스태킹 모델 학습...\")\n",
    "            training_results = self.fit(features_dict)\n",
    "            \n",
    "            # 3. 예측 수행\n",
    "            print(\"🔮 변동계수 예측...\")\n",
    "            predictions = self.predict(features_dict)\n",
    "            \n",
    "            # 4. 결과 분석 및 리포트\n",
    "            print(\"📋 최종 리포트 생성...\")\n",
    "            report_path = os.path.join(self.results_path, 'volatility_coefficient_report.json')\n",
    "            final_report = self.generate_report(predictions, save_path=report_path)\n",
    "            \n",
    "            # 5. 모델 저장\n",
    "            model_path = os.path.join(self.results_path, 'kepco_volatility_model.pkl')\n",
    "            self.save_model(model_path)\n",
    "            \n",
    "            # 6. 등급별 분류 결과 저장\n",
    "            self._save_classification_results(predictions)\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            print(\"\\\\n\" + \"=\"*60)\n",
    "            print(\"🏆 변동계수 분석 완료!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"소요 시간: {duration}\")\n",
    "            print(f\"분석 고객: {len(predictions)}명\")\n",
    "            print(f\"평균 변동계수: {np.mean([p['volatility_coefficient'] for p in predictions.values()]):.4f}\")\n",
    "            \n",
    "            # 등급별 분포 출력\n",
    "            grades = {}\n",
    "            for pred in predictions.values():\n",
    "                grade_info = self.classify_volatility_grade(pred['volatility_coefficient'])\n",
    "                grade = grade_info['grade']\n",
    "                grades[grade] = grades.get(grade, 0) + 1\n",
    "            \n",
    "            print(\"\\\\n🎯 변동성 등급별 분포:\")\n",
    "            for grade, count in grades.items():\n",
    "                pct = count / len(predictions) * 100\n",
    "                print(f\"   {grade}: {count}명 ({pct:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\\\n📁 결과 파일:\")\n",
    "            print(f\"   ✅ 모델: {model_path}\")\n",
    "            print(f\"   ✅ 리포트: {report_path}\")\n",
    "            print(f\"   ✅ 분류결과: {os.path.join(self.results_path, 'customer_volatility_grades.csv')}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 분석 실패: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    \n",
    "    def _save_classification_results(self, predictions):\n",
    "        \"\"\"고객별 변동성 등급 분류 결과 저장\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for customer_id, pred in predictions.items():\n",
    "            grade_info = self.classify_volatility_grade(pred['volatility_coefficient'])\n",
    "            \n",
    "            results.append({\n",
    "                '고객번호': customer_id,\n",
    "                '변동계수': pred['volatility_coefficient'],\n",
    "                '변동성등급': grade_info['grade'],\n",
    "                '위험수준': grade_info['risk_level'],\n",
    "                '상대변동계수': grade_info['relative_cv'],\n",
    "                '기준변동계수': grade_info['baseline_cv'],\n",
    "                '신뢰도': pred['confidence_score'],\n",
    "                '권장사항': grade_info['recommendation']\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        output_path = os.path.join(self.results_path, 'customer_volatility_grades.csv')\n",
    "        results_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"💾 분류 결과 저장: {output_path}\")\n",
    "\n",
    "# 실행 함수\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"한국전력공사 변동계수 알고리즘 - 독립 실행\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 결과 폴더 확인\n",
    "    results_folders = ['./analysis_results', './results', './output']\n",
    "    results_path = None\n",
    "    \n",
    "    for folder in results_folders:\n",
    "        if os.path.exists(folder):\n",
    "            results_path = folder\n",
    "            break\n",
    "    \n",
    "    if results_path is None:\n",
    "        print(\"⚠️ 결과 폴더를 찾을 수 없습니다.\")\n",
    "        print(\"다음 중 하나의 폴더에 1-2단계 결과를 저장하세요:\")\n",
    "        for folder in results_folders:\n",
    "            print(f\"   - {folder}\")\n",
    "        results_path = './analysis_results'\n",
    "        os.makedirs(results_path, exist_ok=True)\n",
    "        print(f\"✅ 기본 폴더 생성: {results_path}\")\n",
    "    \n",
    "    # 알고리즘 실행\n",
    "    algorithm = KEPCOVolatilityCoefficient(results_path=results_path)\n",
    "    success = algorithm.run_complete_analysis()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\\\n🎉 변동계수 분석이 성공적으로 완료되었습니다!\")\n",
    "    else:\n",
    "        print(\"\\\\n💥 변동계수 분석 중 오류가 발생했습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
