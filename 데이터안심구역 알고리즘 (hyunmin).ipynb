{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 한국전력공사 변동계수 알고리즘 - 완전한 버전\n",
    "# 누락된 메서드들을 모두 포함한 실행 가능한 코드\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class KEPCOVolatilityCoefficient:\n",
    "    \"\"\"\n",
    "    한국전력공사 전력 사용패턴 변동계수 스태킹 알고리즘\n",
    "    완전한 구현 버전\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, results_path='./analysis_results'):\n",
    "        \"\"\"\n",
    "        초기화\n",
    "        Args:\n",
    "            results_path: 1-2단계 결과가 저장된 폴더 경로\n",
    "        \"\"\"\n",
    "        self.results_path = results_path\n",
    "        \n",
    "        # 기본 설정\n",
    "        self.config = {\n",
    "            'temporal_weights': {\n",
    "                'peak_hours': [9, 10, 11, 14, 15, 18, 19, 20],  \n",
    "                'peak_weight': 1.5,                               \n",
    "                'off_peak_weight': 0.8                            \n",
    "            },\n",
    "            'seasonal_adjustment': {\n",
    "                'summer_months': [6, 7, 8],      \n",
    "                'winter_months': [12, 1, 2],     \n",
    "                'summer_factor': 1.2,            \n",
    "                'winter_factor': 1.1             \n",
    "            },\n",
    "            'industry_baselines': {\n",
    "                '222': 0.25,  # 일반용(갑)‖고압A\n",
    "                '226': 0.30,  # 일반용(을) 고압A  \n",
    "                '311': 0.35,  # 산업용(갑) 저압\n",
    "                '322': 0.20,  # 산업용(갑)‖고압A\n",
    "                '726': 0.28   # 산업용(을) 고압A\n",
    "            },\n",
    "            'usage_type_factors': {\n",
    "                '02': 1.1,    # 상업용\n",
    "                '09': 0.9     # 광공업용\n",
    "            },\n",
    "            'anomaly_thresholds': {\n",
    "                'cv_extreme': 1.0,           \n",
    "                'zero_ratio_max': 0.1,       \n",
    "                'night_day_ratio_max': 0.8   \n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 모델 구성요소\n",
    "        self.level0_models = {}\n",
    "        self.level1_model = None\n",
    "        self.scalers = {}\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        # 과적합 방지 설정\n",
    "        self.cv_folds = 5\n",
    "        self.random_state = 42\n",
    "        \n",
    "        print(\"🔧 한국전력공사 변동계수 알고리즘 초기화\")\n",
    "        print(f\"결과 폴더: {self.results_path}\")\n",
    "        \n",
    "        # 스태킹 모델 초기화\n",
    "        self._initialize_stacking_models()\n",
    "        \n",
    "        # 1-2단계 결과 자동 로드\n",
    "        self._load_previous_results()\n",
    "    \n",
    "    def _initialize_stacking_models(self):\n",
    "        \"\"\"스태킹 모델 초기화\"\"\"\n",
    "        # Level-0 모델들 (다양한 기법으로 변동성 측정)\n",
    "        self.level0_models = {\n",
    "            'rf_temporal': RandomForestRegressor(\n",
    "                n_estimators=100, \n",
    "                max_depth=10, \n",
    "                random_state=self.random_state\n",
    "            ),\n",
    "            'gbm_seasonal': GradientBoostingRegressor(\n",
    "                n_estimators=100, \n",
    "                max_depth=6, \n",
    "                random_state=self.random_state\n",
    "            ),\n",
    "            'ridge_basic': Ridge(alpha=1.0),\n",
    "            'elastic_pattern': ElasticNet(alpha=0.5, l1_ratio=0.5, random_state=self.random_state)\n",
    "        }\n",
    "        \n",
    "        # Level-1 메타모델\n",
    "        self.level1_model = Ridge(alpha=0.1)\n",
    "        \n",
    "        # 스케일러\n",
    "        self.scalers = {\n",
    "            'basic': StandardScaler(),\n",
    "            'temporal': RobustScaler(),\n",
    "            'seasonal': StandardScaler(),\n",
    "            'pattern': RobustScaler(),\n",
    "            'anomaly': StandardScaler()\n",
    "        }\n",
    "    \n",
    "    def _load_previous_results(self):\n",
    "        \"\"\"1-2단계 결과 파일들을 자동으로 로드해서 설정 업데이트\"\"\"\n",
    "        print(\"📂 1-2단계 결과 파일 로드 중...\")\n",
    "        \n",
    "        try:\n",
    "            # 1단계 결과 로드\n",
    "            step1_file = os.path.join(self.results_path, 'analysis_results.json')\n",
    "            if os.path.exists(step1_file):\n",
    "                with open(step1_file, 'r', encoding='utf-8') as f:\n",
    "                    step1_results = json.load(f)\n",
    "                print(\"✅ 1단계 결과 로드 완료\")\n",
    "                self._update_config_from_step1(step1_results)\n",
    "            else:\n",
    "                print(f\"⚠️ 1단계 결과 파일 없음: {step1_file}\")\n",
    "            \n",
    "            # 2단계 결과 로드\n",
    "            step2_file = os.path.join(self.results_path, 'volatility_summary.csv')\n",
    "            if os.path.exists(step2_file):\n",
    "                step2_results = pd.read_csv(step2_file)\n",
    "                print(\"✅ 2단계 결과 로드 완료\")\n",
    "                self._update_config_from_step2(step2_results)\n",
    "            else:\n",
    "                print(f\"⚠️ 2단계 결과 파일 없음: {step2_file}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 결과 파일 로드 중 오류: {e}\")\n",
    "            print(\"기본 설정으로 진행합니다.\")\n",
    "    \n",
    "    def _update_config_from_step1(self, step1_results):\n",
    "        \"\"\"1단계 결과로 설정 업데이트\"\"\"\n",
    "        print(\"🔄 1단계 결과로 설정 업데이트...\")\n",
    "        \n",
    "        customer_summary = step1_results.get('customer_summary', {})\n",
    "        if customer_summary:\n",
    "            total_customers = customer_summary.get('total_customers', 3000)\n",
    "            print(f\"   고객 수: {total_customers:,}명\")\n",
    "            \n",
    "            contract_types = customer_summary.get('contract_types', {})\n",
    "            if contract_types:\n",
    "                print(f\"   계약종별: {len(contract_types)}개 유형\")\n",
    "                \n",
    "                total_contracts = sum(contract_types.values())\n",
    "                for contract, count in contract_types.items():\n",
    "                    if str(contract) in self.config['industry_baselines']:\n",
    "                        ratio = count / total_contracts\n",
    "                        if ratio > 0.3:  \n",
    "                            self.config['industry_baselines'][str(contract)] *= 0.95\n",
    "    \n",
    "    def _update_config_from_step2(self, step2_results):\n",
    "        \"\"\"2단계 결과로 설정 업데이트\"\"\"\n",
    "        print(\"🔄 2단계 결과로 설정 업데이트...\")\n",
    "        \n",
    "        for _, row in step2_results.iterrows():\n",
    "            metric = row['metric']\n",
    "            value = row['value']\n",
    "            \n",
    "            if metric == 'overall_cv':\n",
    "                baseline_adjustment = value / 0.25  \n",
    "                for contract_type in self.config['industry_baselines']:\n",
    "                    self.config['industry_baselines'][contract_type] *= baseline_adjustment\n",
    "                print(f\"   전체 CV 기준 조정: {baseline_adjustment:.3f}배\")\n",
    "                \n",
    "            elif metric == 'weekday_cv' and 'weekend_cv' in step2_results['metric'].values:\n",
    "                weekend_row = step2_results[step2_results['metric'] == 'weekend_cv']\n",
    "                if not weekend_row.empty:\n",
    "                    weekend_cv = weekend_row['value'].iloc[0]\n",
    "                    weekend_factor = weekend_cv / value if value > 0 else 1.0\n",
    "                    self.config['weekend_factor'] = weekend_factor\n",
    "                    print(f\"   주말 팩터: {weekend_factor:.3f}\")\n",
    "        \n",
    "        print(\"✅ 설정 업데이트 완료\")\n",
    "    \n",
    "    def load_actual_data_for_features(self):\n",
    "        \"\"\"실제 LP 데이터를 로드해서 특성 생성\"\"\"\n",
    "        print(\"📊 실제 데이터로 특성 생성...\")\n",
    "        \n",
    "        try:\n",
    "            # 전처리된 데이터가 있는지 확인\n",
    "            processed_data_file = os.path.join(self.results_path, 'processed_lp_data.csv')\n",
    "            \n",
    "            if os.path.exists(processed_data_file):\n",
    "                print(\"📂 전처리된 LP 데이터 로드...\")\n",
    "                lp_data = pd.read_csv(processed_data_file)\n",
    "                lp_data['LP 수신일자'] = pd.to_datetime(lp_data['LP 수신일자'])\n",
    "            else:\n",
    "                # 원본 LP 데이터 로드\n",
    "                print(\"📂 원본 LP 데이터 로드...\")\n",
    "                lp_data = self._load_original_lp_data()\n",
    "            \n",
    "            # 고객 데이터 로드\n",
    "            customer_file = os.path.join(os.path.dirname(self.results_path), '제13회 산업부 공모전 대상고객.xlsx')\n",
    "            if os.path.exists(customer_file):\n",
    "                customer_data = pd.read_excel(customer_file)\n",
    "            else:\n",
    "                customer_data = None\n",
    "                print(\"⚠️ 고객 데이터 파일 없음\")\n",
    "            \n",
    "            # 특성 생성\n",
    "            features_dict = self.create_features(lp_data, customer_data)\n",
    "            \n",
    "            print(f\"✅ 특성 생성 완료: {len(features_dict)}명\")\n",
    "            return features_dict\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 데이터 로드 실패: {e}\")\n",
    "            print(\"샘플 데이터로 테스트 실행...\")\n",
    "            return self._create_sample_features()\n",
    "    \n",
    "    def _load_original_lp_data(self):\n",
    "        \"\"\"원본 LP 데이터 로드\"\"\"\n",
    "        import glob\n",
    "        \n",
    "        base_path = os.path.dirname(self.results_path)\n",
    "        lp_files = glob.glob(os.path.join(base_path, 'processed_LPData_*.csv'))\n",
    "        \n",
    "        if not lp_files:\n",
    "            raise FileNotFoundError(\"LP 데이터 파일을 찾을 수 없습니다.\")\n",
    "        \n",
    "        dataframes = []\n",
    "        for file_path in sorted(lp_files):\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # 컬럼명 표준화\n",
    "            column_mapping = {\n",
    "                'LP수신일자': 'LP 수신일자',\n",
    "                '순방향유효전력': '순방향 유효전력',\n",
    "                '대체고객번호': '대체고객번호'\n",
    "            }\n",
    "            \n",
    "            for old_col, new_col in column_mapping.items():\n",
    "                if old_col in df.columns:\n",
    "                    df = df.rename(columns={old_col: new_col})\n",
    "            \n",
    "            dataframes.append(df)\n",
    "        \n",
    "        lp_data = pd.concat(dataframes, ignore_index=True)\n",
    "        lp_data['LP 수신일자'] = pd.to_datetime(lp_data['LP 수신일자'])\n",
    "        \n",
    "        return lp_data\n",
    "    \n",
    "    def _create_sample_features(self):\n",
    "        \"\"\"샘플 특성 데이터 생성 (테스트용)\"\"\"\n",
    "        print(\"🧪 샘플 특성 데이터 생성...\")\n",
    "        \n",
    "        sample_features = {}\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        for i in range(100):  \n",
    "            customer_id = f'SAMPLE_{i:04d}'\n",
    "            \n",
    "            sample_features[customer_id] = {\n",
    "                'basic': {\n",
    "                    'cv_basic': np.random.normal(0.25, 0.1),\n",
    "                    'range_volatility': np.random.normal(0.8, 0.3),\n",
    "                    'iqr_volatility': np.random.normal(0.6, 0.2),\n",
    "                    'skewness': np.random.normal(0.5, 0.3),\n",
    "                    'kurtosis': np.random.normal(0.2, 0.5),\n",
    "                    'mean_power': np.random.normal(50, 20),\n",
    "                    'load_factor': np.random.normal(0.6, 0.2)\n",
    "                },\n",
    "                'temporal': {\n",
    "                    'peak_cv': np.random.normal(0.3, 0.1),\n",
    "                    'off_peak_cv': np.random.normal(0.2, 0.1),\n",
    "                    'peak_mean': np.random.normal(60, 25),\n",
    "                    'off_peak_mean': np.random.normal(40, 15),\n",
    "                    'peak_off_peak_ratio': np.random.normal(1.5, 0.3),\n",
    "                    'temporal_cv_diff': np.random.normal(0.1, 0.05),\n",
    "                    'weekday_weekend_cv_ratio': np.random.normal(1.2, 0.3)\n",
    "                },\n",
    "                'seasonal': {\n",
    "                    'summer_cv': np.random.normal(0.35, 0.15),\n",
    "                    'winter_cv': np.random.normal(0.3, 0.12),\n",
    "                    'summer_mean': np.random.normal(65, 30),\n",
    "                    'winter_mean': np.random.normal(55, 25),\n",
    "                    'seasonal_cv_diff': np.random.normal(0.05, 0.03),\n",
    "                    'seasonal_stability': np.random.normal(0.1, 0.05)\n",
    "                },\n",
    "                'pattern': {\n",
    "                    'daily_cv_stability': np.random.normal(0.05, 0.02),\n",
    "                    'daily_cv_mean': np.random.normal(0.25, 0.1),\n",
    "                    'autocorrelation': np.random.normal(0.7, 0.2),\n",
    "                    'trend_volatility': np.random.normal(0.1, 0.05)\n",
    "                },\n",
    "                'anomaly': {\n",
    "                    'zero_ratio': np.random.beta(1, 10),\n",
    "                    'sudden_change_ratio': np.random.beta(1, 20),\n",
    "                    'night_day_ratio': np.random.normal(0.4, 0.2),\n",
    "                    'outlier_ratio': np.random.beta(1, 30)\n",
    "                },\n",
    "                'customer': {\n",
    "                    'baseline_cv': 0.25,\n",
    "                    'usage_factor': np.random.choice([0.9, 1.1]),\n",
    "                    'contract_power_log': np.random.normal(6.0, 1.0)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        return sample_features\n",
    "    \n",
    "    def create_features(self, lp_data, customer_data=None):\n",
    "        \"\"\"실제 LP 데이터로 특성 생성\"\"\"\n",
    "        print(\"🔄 실제 데이터 특성 생성 중...\")\n",
    "        \n",
    "        features_dict = {}\n",
    "        customers = lp_data['대체고객번호'].unique()\n",
    "        \n",
    "        # 메모리 고려해서 최대 1000명으로 제한\n",
    "        if len(customers) > 1000:\n",
    "            customers = customers[:1000]\n",
    "            print(f\"   메모리 효율성을 위해 {len(customers)}명으로 제한\")\n",
    "        \n",
    "        for i, customer in enumerate(customers):\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"   진행: {i+1}/{len(customers)} ({(i+1)/len(customers)*100:.1f}%)\")\n",
    "            \n",
    "            # 컬럼명 확인 및 표준화\n",
    "            power_col = None\n",
    "            for col in ['순방향 유효전력', '순방향유효전력']:\n",
    "                if col in lp_data.columns:\n",
    "                    power_col = col\n",
    "                    break\n",
    "            \n",
    "            if power_col is None:\n",
    "                print(\"⚠️ 전력 데이터 컬럼을 찾을 수 없습니다.\")\n",
    "                continue\n",
    "            \n",
    "            customer_lp = lp_data[lp_data['대체고객번호'] == customer].copy()\n",
    "            \n",
    "            if len(customer_lp) < 96:  # 최소 1일 데이터 필요\n",
    "                continue\n",
    "            \n",
    "            # 시간 관련 파생 변수\n",
    "            customer_lp['시간'] = customer_lp['LP 수신일자'].dt.hour\n",
    "            customer_lp['요일'] = customer_lp['LP 수신일자'].dt.weekday\n",
    "            customer_lp['월'] = customer_lp['LP 수신일자'].dt.month\n",
    "            customer_lp['주말여부'] = customer_lp['요일'].isin([5, 6])\n",
    "            \n",
    "            power_series = customer_lp[power_col]\n",
    "            \n",
    "            # 1. 기본 변동성 특성\n",
    "            basic_features = self._calculate_basic_volatility(power_series)\n",
    "            \n",
    "            # 2. 시간대별 변동성 특성\n",
    "            temporal_features = self._calculate_temporal_volatility(customer_lp, power_col)\n",
    "            \n",
    "            # 3. 계절성 변동성 특성  \n",
    "            seasonal_features = self._calculate_seasonal_volatility(customer_lp, power_col)\n",
    "            \n",
    "            # 4. 패턴 안정성 특성\n",
    "            pattern_features = self._calculate_pattern_stability(customer_lp, power_col)\n",
    "            \n",
    "            # 5. 이상 패턴 특성\n",
    "            anomaly_features = self._calculate_anomaly_features(customer_lp, power_col)\n",
    "            \n",
    "            # 6. 고객 특성\n",
    "            customer_features = {}\n",
    "            if customer_data is not None:\n",
    "                customer_info = customer_data[customer_data['고객번호'] == customer]\n",
    "                if not customer_info.empty:\n",
    "                    customer_features = self._get_customer_features(customer_info.iloc[0])\n",
    "                else:\n",
    "                    customer_features = {'baseline_cv': 0.25, 'usage_factor': 1.0, 'contract_power_log': 6.0}\n",
    "            else:\n",
    "                customer_features = {'baseline_cv': 0.25, 'usage_factor': 1.0, 'contract_power_log': 6.0}\n",
    "            \n",
    "            features_dict[customer] = {\n",
    "                'basic': basic_features,\n",
    "                'temporal': temporal_features,\n",
    "                'seasonal': seasonal_features,\n",
    "                'pattern': pattern_features,\n",
    "                'anomaly': anomaly_features,\n",
    "                'customer': customer_features\n",
    "            }\n",
    "        \n",
    "        print(f\"✅ 특성 생성 완료: {len(features_dict)}명\")\n",
    "        return features_dict\n",
    "    \n",
    "    def _calculate_basic_volatility(self, power_series):\n",
    "        \"\"\"기본 변동성 특성 계산\"\"\"\n",
    "        if len(power_series) == 0 or power_series.mean() == 0:\n",
    "            return {\n",
    "                'cv_basic': 0, 'range_volatility': 0, 'iqr_volatility': 0,\n",
    "                'skewness': 0, 'kurtosis': 0, 'mean_power': 0, 'load_factor': 0\n",
    "            }\n",
    "        \n",
    "        mean_power = power_series.mean()\n",
    "        std_power = power_series.std()\n",
    "        \n",
    "        # 변동계수\n",
    "        cv_basic = std_power / mean_power if mean_power > 0 else 0\n",
    "        \n",
    "        # 범위 변동성\n",
    "        range_volatility = (power_series.max() - power_series.min()) / mean_power if mean_power > 0 else 0\n",
    "        \n",
    "        # IQR 변동성\n",
    "        q75, q25 = np.percentile(power_series, [75, 25])\n",
    "        median_power = np.median(power_series)\n",
    "        iqr_volatility = (q75 - q25) / median_power if median_power > 0 else 0\n",
    "        \n",
    "        # 왜도와 첨도\n",
    "        skewness = stats.skew(power_series)\n",
    "        kurtosis = stats.kurtosis(power_series)\n",
    "        \n",
    "        # 부하율 (평균/최대)\n",
    "        load_factor = mean_power / power_series.max() if power_series.max() > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'cv_basic': cv_basic,\n",
    "            'range_volatility': range_volatility,\n",
    "            'iqr_volatility': iqr_volatility,\n",
    "            'skewness': skewness,\n",
    "            'kurtosis': kurtosis,\n",
    "            'mean_power': mean_power,\n",
    "            'load_factor': load_factor\n",
    "        }\n",
    "    \n",
    "    def _calculate_temporal_volatility(self, customer_lp, power_col):\n",
    "        \"\"\"시간대별 변동성 특성 계산\"\"\"\n",
    "        # 피크/오프피크 구분\n",
    "        peak_mask = customer_lp['시간'].isin(self.config['temporal_weights']['peak_hours'])\n",
    "        \n",
    "        peak_data = customer_lp[peak_mask][power_col]\n",
    "        off_peak_data = customer_lp[~peak_mask][power_col]\n",
    "        \n",
    "        # 각각의 변동계수 계산\n",
    "        peak_cv = peak_data.std() / peak_data.mean() if len(peak_data) > 0 and peak_data.mean() > 0 else 0\n",
    "        off_peak_cv = off_peak_data.std() / off_peak_data.mean() if len(off_peak_data) > 0 and off_peak_data.mean() > 0 else 0\n",
    "        \n",
    "        # 평일/주말 구분\n",
    "        weekday_data = customer_lp[~customer_lp['주말여부']][power_col]\n",
    "        weekend_data = customer_lp[customer_lp['주말여부']][power_col]\n",
    "        \n",
    "        weekday_cv = weekday_data.std() / weekday_data.mean() if len(weekday_data) > 0 and weekday_data.mean() > 0 else 0\n",
    "        weekend_cv = weekend_data.std() / weekend_data.mean() if len(weekend_data) > 0 and weekend_data.mean() > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'peak_cv': peak_cv,\n",
    "            'off_peak_cv': off_peak_cv,\n",
    "            'peak_mean': peak_data.mean() if len(peak_data) > 0 else 0,\n",
    "            'off_peak_mean': off_peak_data.mean() if len(off_peak_data) > 0 else 0,\n",
    "            'peak_off_peak_ratio': (peak_data.mean() / off_peak_data.mean()) if len(off_peak_data) > 0 and off_peak_data.mean() > 0 else 1,\n",
    "            'temporal_cv_diff': abs(peak_cv - off_peak_cv),\n",
    "            'weekday_weekend_cv_ratio': (weekday_cv / weekend_cv) if weekend_cv > 0 else 1\n",
    "        }\n",
    "    \n",
    "    def _calculate_seasonal_volatility(self, customer_lp, power_col):\n",
    "        \"\"\"계절성 변동성 특성 계산\"\"\"\n",
    "        # 여름/겨울/기타 구분\n",
    "        summer_mask = customer_lp['월'].isin(self.config['seasonal_adjustment']['summer_months'])\n",
    "        winter_mask = customer_lp['월'].isin(self.config['seasonal_adjustment']['winter_months'])\n",
    "        \n",
    "        summer_data = customer_lp[summer_mask][power_col]\n",
    "        winter_data = customer_lp[winter_mask][power_col]\n",
    "        other_data = customer_lp[~(summer_mask | winter_mask)][power_col]\n",
    "        \n",
    "        summer_cv = summer_data.std() / summer_data.mean() if len(summer_data) > 0 and summer_data.mean() > 0 else 0\n",
    "        winter_cv = winter_data.std() / winter_data.mean() if len(winter_data) > 0 and winter_data.mean() > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'summer_cv': summer_cv,\n",
    "            'winter_cv': winter_cv,\n",
    "            'summer_mean': summer_data.mean() if len(summer_data) > 0 else 0,\n",
    "            'winter_mean': winter_data.mean() if len(winter_data) > 0 else 0,\n",
    "            'seasonal_cv_diff': abs(summer_cv - winter_cv),\n",
    "            'seasonal_stability': 1 - (abs(summer_cv - winter_cv) / max(summer_cv, winter_cv)) if max(summer_cv, winter_cv) > 0 else 1\n",
    "        }\n",
    "    \n",
    "    def _calculate_pattern_stability(self, customer_lp, power_col):\n",
    "        \"\"\"패턴 안정성 특성 계산\"\"\"\n",
    "        power_series = customer_lp[power_col]\n",
    "        \n",
    "        # 일별 변동계수 계산\n",
    "        customer_lp['날짜'] = customer_lp['LP 수신일자'].dt.date\n",
    "        daily_cvs = []\n",
    "        \n",
    "        for date in customer_lp['날짜'].unique():\n",
    "            daily_data = customer_lp[customer_lp['날짜'] == date][power_col]\n",
    "            if len(daily_data) > 1 and daily_data.mean() > 0:\n",
    "                daily_cv = daily_data.std() / daily_data.mean()\n",
    "                daily_cvs.append(daily_cv)\n",
    "        \n",
    "        daily_cv_stability = np.std(daily_cvs) if len(daily_cvs) > 1 else 0\n",
    "        daily_cv_mean = np.mean(daily_cvs) if len(daily_cvs) > 0 else 0\n",
    "        \n",
    "        # 자기상관\n",
    "        if len(power_series) > 1:\n",
    "            autocorr = power_series.autocorr(lag=1)\n",
    "            autocorr = autocorr if not np.isnan(autocorr) else 0\n",
    "        else:\n",
    "            autocorr = 0\n",
    "        \n",
    "        # 추세 변동성\n",
    "        if len(power_series) > 2:\n",
    "            trend = np.polyfit(range(len(power_series)), power_series, 1)[0]\n",
    "            detrended = power_series - (trend * np.arange(len(power_series)))\n",
    "            trend_volatility = detrended.std() / power_series.mean() if power_series.mean() > 0 else 0\n",
    "        else:\n",
    "            trend_volatility = 0\n",
    "        \n",
    "        return {\n",
    "            'daily_cv_stability': daily_cv_stability,\n",
    "            'daily_cv_mean': daily_cv_mean,\n",
    "            'autocorrelation': autocorr,\n",
    "            'trend_volatility': trend_volatility\n",
    "        }\n",
    "    \n",
    "    def _calculate_anomaly_features(self, customer_lp, power_col):\n",
    "        \"\"\"이상 패턴 특성 계산\"\"\"\n",
    "        power_series = customer_lp[power_col]\n",
    "        \n",
    "        # 0값 비율\n",
    "        zero_ratio = (power_series == 0).sum() / len(power_series)\n",
    "        \n",
    "        # 급격한 변화 비율\n",
    "        if len(power_series) > 1:\n",
    "            changes = np.abs(power_series.diff())\n",
    "            sudden_changes = changes > (changes.mean() + 2 * changes.std())\n",
    "            sudden_change_ratio = sudden_changes.sum() / len(power_series)\n",
    "        else:\n",
    "            sudden_change_ratio = 0\n",
    "        \n",
    "        # 야간/주간 비율\n",
    "        night_mask = customer_lp['시간'].isin([22, 23, 0, 1, 2, 3, 4, 5])\n",
    "        day_mask = customer_lp['시간'].isin([6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21])\n",
    "        \n",
    "        night_mean = customer_lp[night_mask][power_col].mean() if night_mask.sum() > 0 else 0\n",
    "        day_mean = customer_lp[day_mask][power_col].mean() if day_mask.sum() > 0 else 0\n",
    "        \n",
    "        night_day_ratio = night_mean / day_mean if day_mean > 0 else 0\n",
    "        \n",
    "        # 이상치 비율 (IQR 방법)\n",
    "        q75, q25 = np.percentile(power_series, [75, 25])\n",
    "        iqr = q75 - q25\n",
    "        outlier_mask = (power_series < q25 - 1.5*iqr) | (power_series > q75 + 1.5*iqr)\n",
    "        outlier_ratio = outlier_mask.sum() / len(power_series)\n",
    "        \n",
    "        return {\n",
    "            'zero_ratio': zero_ratio,\n",
    "            'sudden_change_ratio': sudden_change_ratio,\n",
    "            'night_day_ratio': night_day_ratio,\n",
    "            'outlier_ratio': outlier_ratio\n",
    "        }\n",
    "    \n",
    "    def _get_customer_features(self, customer_info):\n",
    "        \"\"\"고객 정보에서 특성 추출\"\"\"\n",
    "        # 계약종별에 따른 기준 변동계수\n",
    "        contract_type = str(customer_info.get('계약종별', '322'))\n",
    "        baseline_cv = self.config['industry_baselines'].get(contract_type, 0.25)\n",
    "        \n",
    "        # 용도별 팩터\n",
    "        usage_type = str(customer_info.get('용도별', '09'))\n",
    "        usage_factor = self.config['usage_type_factors'].get(usage_type, 1.0)\n",
    "        \n",
    "        # 계약전력 (로그 변환)\n",
    "        contract_power = customer_info.get('계약전력', 100)\n",
    "        contract_power_log = np.log10(max(contract_power, 1))\n",
    "        \n",
    "        return {\n",
    "            'baseline_cv': baseline_cv,\n",
    "            'usage_factor': usage_factor,\n",
    "            'contract_power_log': contract_power_log\n",
    "        }\n",
    "    \n",
    "    def _prepare_feature_matrix(self, features_dict):\n",
    "        \"\"\"특성 딕셔너리를 모델 학습용 행렬로 변환\"\"\"\n",
    "        feature_matrices = {}\n",
    "        customer_ids = list(features_dict.keys())\n",
    "        \n",
    "        # 각 카테고리별 특성 행렬 생성\n",
    "        for category in ['basic', 'temporal', 'seasonal', 'pattern', 'anomaly', 'customer']:\n",
    "            category_features = []\n",
    "            \n",
    "            for customer_id in customer_ids:\n",
    "                customer_features = features_dict[customer_id][category]\n",
    "                feature_vector = list(customer_features.values())\n",
    "                category_features.append(feature_vector)\n",
    "            \n",
    "            feature_matrices[category] = np.array(category_features)\n",
    "            \n",
    "            # NaN 처리\n",
    "            feature_matrices[category] = np.nan_to_num(feature_matrices[category], 0)\n",
    "        \n",
    "        return feature_matrices, customer_ids\n",
    "    \n",
    "    def fit(self, features_dict):\n",
    "        \"\"\"스태킹 모델 학습\"\"\"\n",
    "        print(\"🚀 스태킹 모델 학습 시작...\")\n",
    "        \n",
    "        # 특성 행렬 준비\n",
    "        feature_matrices, customer_ids = self._prepare_feature_matrix(features_dict)\n",
    "        \n",
    "        # 타겟 변수 생성 (기본 변동계수를 기준으로)\n",
    "        y_target = feature_matrices['basic'][:, 0]  # cv_basic\n",
    "        \n",
    "        print(f\"학습 데이터: {len(customer_ids)}명\")\n",
    "        print(f\"타겟 변수 범위: {y_target.min():.3f} ~ {y_target.max():.3f}\")\n",
    "        \n",
    "        # Level-0 모델 학습 및 예측\n",
    "        level0_predictions = {}\n",
    "        \n",
    "        for category, model_name in [\n",
    "            ('temporal', 'rf_temporal'),\n",
    "            ('seasonal', 'gbm_seasonal'), \n",
    "            ('basic', 'ridge_basic'),\n",
    "            ('pattern', 'elastic_pattern')\n",
    "        ]:\n",
    "            print(f\"  Level-0 모델 학습: {model_name} ({category})\")\n",
    "            \n",
    "            X = feature_matrices[category]\n",
    "            \n",
    "            # 스케일링\n",
    "            if category in self.scalers:\n",
    "                X_scaled = self.scalers[category].fit_transform(X)\n",
    "            else:\n",
    "                X_scaled = X\n",
    "            \n",
    "            # 교차검증을 통한 Level-0 예측 생성\n",
    "            cv = TimeSeriesSplit(n_splits=self.cv_folds)\n",
    "            predictions = np.zeros(len(y_target))\n",
    "            \n",
    "            for train_idx, val_idx in cv.split(X_scaled):\n",
    "                X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "                y_train, y_val = y_target[train_idx], y_target[val_idx]\n",
    "                \n",
    "                # 모델 학습\n",
    "                model = self.level0_models[model_name]\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                # 검증 세트 예측\n",
    "                val_pred = model.predict(X_val)\n",
    "                predictions[val_idx] = val_pred\n",
    "            \n",
    "            level0_predictions[model_name] = predictions\n",
    "            \n",
    "            # 전체 데이터로 최종 모델 재학습\n",
    "            self.level0_models[model_name].fit(X_scaled, y_target)\n",
    "        \n",
    "        # Level-1 메타 특성 구성\n",
    "        meta_features = np.column_stack([\n",
    "            level0_predictions['rf_temporal'],\n",
    "            level0_predictions['gbm_seasonal'],\n",
    "            level0_predictions['ridge_basic'],\n",
    "            level0_predictions['elastic_pattern'],\n",
    "            feature_matrices['anomaly'].mean(axis=1),  # 이상 패턴 요약\n",
    "            feature_matrices['customer'][:, 0]         # baseline_cv\n",
    "        ])\n",
    "        \n",
    "        # Level-1 모델 학습\n",
    "        print(\"  Level-1 메타모델 학습...\")\n",
    "        self.level1_model.fit(meta_features, y_target)\n",
    "        \n",
    "        # 성능 평가\n",
    "        final_predictions = self.level1_model.predict(meta_features)\n",
    "        mae = mean_absolute_error(y_target, final_predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(y_target, final_predictions))\n",
    "        r2 = r2_score(y_target, final_predictions)\n",
    "        \n",
    "        print(f\"✅ 학습 완료 - MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        \n",
    "        return {\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'level0_predictions': level0_predictions,\n",
    "            'meta_features_shape': meta_features.shape\n",
    "        }\n",
    "    \n",
    "    def predict(self, features_dict):\n",
    "        \"\"\"변동계수 예측\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"모델이 학습되지 않았습니다. fit() 메서드를 먼저 실행하세요.\")\n",
    "        \n",
    "        print(\"🔮 변동계수 예측 중...\")\n",
    "        \n",
    "        # 특성 행렬 준비\n",
    "        feature_matrices, customer_ids = self._prepare_feature_matrix(features_dict)\n",
    "        \n",
    "        # Level-0 예측\n",
    "        level0_predictions = {}\n",
    "        \n",
    "        for category, model_name in [\n",
    "            ('temporal', 'rf_temporal'),\n",
    "            ('seasonal', 'gbm_seasonal'),\n",
    "            ('basic', 'ridge_basic'),\n",
    "            ('pattern', 'elastic_pattern')\n",
    "        ]:\n",
    "            X = feature_matrices[category]\n",
    "            \n",
    "            # 스케일링 (학습시 사용한 스케일러 적용)\n",
    "            if category in self.scalers:\n",
    "                X_scaled = self.scalers[category].transform(X)\n",
    "            else:\n",
    "                X_scaled = X\n",
    "            \n",
    "            # 예측\n",
    "            predictions = self.level0_models[model_name].predict(X_scaled)\n",
    "            level0_predictions[model_name] = predictions\n",
    "        \n",
    "        # Level-1 메타 특성 구성\n",
    "        meta_features = np.column_stack([\n",
    "            level0_predictions['rf_temporal'],\n",
    "            level0_predictions['gbm_seasonal'],\n",
    "            level0_predictions['ridge_basic'],\n",
    "            level0_predictions['elastic_pattern'],\n",
    "            feature_matrices['anomaly'].mean(axis=1),\n",
    "            feature_matrices['customer'][:, 0]\n",
    "        ])\n",
    "        \n",
    "        # 최종 예측\n",
    "        final_predictions = self.level1_model.predict(meta_features)\n",
    "        \n",
    "        # 예측 결과 딕셔너리 구성\n",
    "        predictions_dict = {}\n",
    "        for i, customer_id in enumerate(customer_ids):\n",
    "            # 신뢰도 계산 (Level-0 모델들의 예측 일치도)\n",
    "            level0_values = [\n",
    "                level0_predictions['rf_temporal'][i],\n",
    "                level0_predictions['gbm_seasonal'][i],\n",
    "                level0_predictions['ridge_basic'][i],\n",
    "                level0_predictions['elastic_pattern'][i]\n",
    "            ]\n",
    "            confidence = 1 - (np.std(level0_values) / max(np.mean(level0_values), 0.01))\n",
    "            confidence = max(0, min(1, confidence))  # 0-1 범위로 제한\n",
    "            \n",
    "            predictions_dict[customer_id] = {\n",
    "                'volatility_coefficient': max(0, final_predictions[i]),  # 음수 방지\n",
    "                'confidence_score': confidence,\n",
    "                'level0_predictions': {\n",
    "                    'temporal': level0_predictions['rf_temporal'][i],\n",
    "                    'seasonal': level0_predictions['gbm_seasonal'][i],\n",
    "                    'basic': level0_predictions['ridge_basic'][i],\n",
    "                    'pattern': level0_predictions['elastic_pattern'][i]\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        print(f\"✅ 예측 완료: {len(predictions_dict)}명\")\n",
    "        return predictions_dict\n",
    "    \n",
    "    def classify_volatility_grade(self, volatility_coefficient, customer_features=None):\n",
    "        \"\"\"변동성 등급 분류\"\"\"\n",
    "        # 기본 기준값\n",
    "        baseline_cv = 0.25\n",
    "        \n",
    "        # 고객별 기준값 조정\n",
    "        if customer_features and 'customer' in customer_features:\n",
    "            baseline_cv = customer_features['customer'].get('baseline_cv', 0.25)\n",
    "        \n",
    "        # 상대 변동계수 계산\n",
    "        relative_cv = volatility_coefficient / baseline_cv\n",
    "        \n",
    "        # 등급 분류\n",
    "        if relative_cv <= 0.8:\n",
    "            grade = \"매우 안정\"\n",
    "            risk_level = \"낮음\"\n",
    "            recommendation = \"현재 안정적인 전력 사용 패턴을 유지하세요.\"\n",
    "        elif relative_cv <= 1.2:\n",
    "            grade = \"안정\"\n",
    "            risk_level = \"낮음\"\n",
    "            recommendation = \"양호한 전력 사용 패턴입니다.\"\n",
    "        elif relative_cv <= 1.8:\n",
    "            grade = \"보통\"\n",
    "            risk_level = \"중간\"\n",
    "            recommendation = \"전력 사용 패턴 최적화를 고려해보세요.\"\n",
    "        elif relative_cv <= 2.5:\n",
    "            grade = \"불안정\"\n",
    "            risk_level = \"높음\"\n",
    "            recommendation = \"전력 사용 패턴 개선이 필요합니다.\"\n",
    "        else:\n",
    "            grade = \"매우 불안정\"\n",
    "            risk_level = \"매우 높음\"\n",
    "            recommendation = \"즉시 전력 사용 패턴 점검 및 개선이 필요합니다.\"\n",
    "        \n",
    "        return {\n",
    "            'grade': grade,\n",
    "            'risk_level': risk_level,\n",
    "            'relative_cv': relative_cv,\n",
    "            'baseline_cv': baseline_cv,\n",
    "            'recommendation': recommendation\n",
    "        }\n",
    "    \n",
    "    def generate_report(self, predictions, save_path=None):\n",
    "        \"\"\"종합 리포트 생성\"\"\"\n",
    "        print(\"📋 종합 리포트 생성 중...\")\n",
    "        \n",
    "        # 기본 통계\n",
    "        cv_values = [pred['volatility_coefficient'] for pred in predictions.values()]\n",
    "        confidence_scores = [pred['confidence_score'] for pred in predictions.values()]\n",
    "        \n",
    "        # 등급별 분포\n",
    "        grade_distribution = {}\n",
    "        for customer_id, pred in predictions.items():\n",
    "            grade_info = self.classify_volatility_grade(pred['volatility_coefficient'])\n",
    "            grade = grade_info['grade']\n",
    "            grade_distribution[grade] = grade_distribution.get(grade, 0) + 1\n",
    "        \n",
    "        # 리포트 구성\n",
    "        report = {\n",
    "            'analysis_summary': {\n",
    "                'total_customers': len(predictions),\n",
    "                'analysis_date': datetime.now().isoformat(),\n",
    "                'model_type': 'Stacking Ensemble'\n",
    "            },\n",
    "            'volatility_statistics': {\n",
    "                'mean_cv': np.mean(cv_values),\n",
    "                'std_cv': np.std(cv_values),\n",
    "                'min_cv': np.min(cv_values),\n",
    "                'max_cv': np.max(cv_values),\n",
    "                'median_cv': np.median(cv_values),\n",
    "                'percentiles': {\n",
    "                    'p25': np.percentile(cv_values, 25),\n",
    "                    'p75': np.percentile(cv_values, 75),\n",
    "                    'p90': np.percentile(cv_values, 90),\n",
    "                    'p95': np.percentile(cv_values, 95)\n",
    "                }\n",
    "            },\n",
    "            'confidence_statistics': {\n",
    "                'mean_confidence': np.mean(confidence_scores),\n",
    "                'min_confidence': np.min(confidence_scores),\n",
    "                'max_confidence': np.max(confidence_scores)\n",
    "            },\n",
    "            'grade_distribution': grade_distribution,\n",
    "            'high_risk_customers': [],\n",
    "            'recommendations': {\n",
    "                'immediate_attention': [],\n",
    "                'monitoring_required': [],\n",
    "                'stable_customers': []\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 고위험 고객 식별\n",
    "        for customer_id, pred in predictions.items():\n",
    "            cv = pred['volatility_coefficient']\n",
    "            grade_info = self.classify_volatility_grade(cv)\n",
    "            \n",
    "            if grade_info['risk_level'] in ['높음', '매우 높음']:\n",
    "                report['high_risk_customers'].append({\n",
    "                    'customer_id': customer_id,\n",
    "                    'volatility_coefficient': cv,\n",
    "                    'grade': grade_info['grade'],\n",
    "                    'risk_level': grade_info['risk_level'],\n",
    "                    'confidence': pred['confidence_score']\n",
    "                })\n",
    "            \n",
    "            # 권장사항 분류\n",
    "            if grade_info['risk_level'] == '매우 높음':\n",
    "                report['recommendations']['immediate_attention'].append(customer_id)\n",
    "            elif grade_info['risk_level'] in ['높음', '중간']:\n",
    "                report['recommendations']['monitoring_required'].append(customer_id)\n",
    "            else:\n",
    "                report['recommendations']['stable_customers'].append(customer_id)\n",
    "        \n",
    "        # 파일 저장\n",
    "        if save_path:\n",
    "            with open(save_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(report, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"💾 리포트 저장: {save_path}\")\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def save_model(self, file_path):\n",
    "        \"\"\"모델 저장\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            print(\"⚠️ 학습되지 않은 모델은 저장할 수 없습니다.\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            model_data = {\n",
    "                'level0_models': self.level0_models,\n",
    "                'level1_model': self.level1_model,\n",
    "                'scalers': self.scalers,\n",
    "                'config': self.config,\n",
    "                'is_fitted': self.is_fitted\n",
    "            }\n",
    "            \n",
    "            joblib.dump(model_data, file_path)\n",
    "            print(f\"💾 모델 저장 완료: {file_path}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 모델 저장 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def load_model(self, file_path):\n",
    "        \"\"\"모델 로드\"\"\"\n",
    "        try:\n",
    "            model_data = joblib.load(file_path)\n",
    "            \n",
    "            self.level0_models = model_data['level0_models']\n",
    "            self.level1_model = model_data['level1_model']\n",
    "            self.scalers = model_data['scalers']\n",
    "            self.config = model_data['config']\n",
    "            self.is_fitted = model_data['is_fitted']\n",
    "            \n",
    "            print(f\"✅ 모델 로드 완료: {file_path}\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 모델 로드 실패: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"전체 변동계수 분석 실행\"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        print(\"🚀 변동계수 알고리즘 분석 시작\")\n",
    "        print(f\"시작 시간: {start_time}\")\n",
    "        \n",
    "        try:\n",
    "            # 1. 특성 데이터 준비\n",
    "            features_dict = self.load_actual_data_for_features()\n",
    "            \n",
    "            if not features_dict:\n",
    "                print(\"❌ 특성 데이터 준비 실패\")\n",
    "                return False\n",
    "            \n",
    "            # 2. 모델 학습\n",
    "            print(\"🚀 스태킹 모델 학습...\")\n",
    "            training_results = self.fit(features_dict)\n",
    "            \n",
    "            # 3. 예측 수행\n",
    "            print(\"🔮 변동계수 예측...\")\n",
    "            predictions = self.predict(features_dict)\n",
    "            \n",
    "            # 4. 결과 분석 및 리포트\n",
    "            print(\"📋 최종 리포트 생성...\")\n",
    "            report_path = os.path.join(self.results_path, 'volatility_coefficient_report.json')\n",
    "            final_report = self.generate_report(predictions, save_path=report_path)\n",
    "            \n",
    "            # 5. 모델 저장\n",
    "            model_path = os.path.join(self.results_path, 'kepco_volatility_model.pkl')\n",
    "            self.save_model(model_path)\n",
    "            \n",
    "            # 6. 등급별 분류 결과 저장\n",
    "            self._save_classification_results(predictions)\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(\"🏆 변동계수 분석 완료!\")\n",
    "            print(\"=\"*60)\n",
    "            print(f\"소요 시간: {duration}\")\n",
    "            print(f\"분석 고객: {len(predictions)}명\")\n",
    "            print(f\"평균 변동계수: {np.mean([p['volatility_coefficient'] for p in predictions.values()]):.4f}\")\n",
    "            \n",
    "            # 등급별 분포 출력\n",
    "            grades = {}\n",
    "            for pred in predictions.values():\n",
    "                grade_info = self.classify_volatility_grade(pred['volatility_coefficient'])\n",
    "                grade = grade_info['grade']\n",
    "                grades[grade] = grades.get(grade, 0) + 1\n",
    "            \n",
    "            print(\"\\n🎯 변동성 등급별 분포:\")\n",
    "            for grade, count in grades.items():\n",
    "                pct = count / len(predictions) * 100\n",
    "                print(f\"   {grade}: {count}명 ({pct:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\n📁 결과 파일:\")\n",
    "            print(f\"   ✅ 모델: {model_path}\")\n",
    "            print(f\"   ✅ 리포트: {report_path}\")\n",
    "            print(f\"   ✅ 분류결과: {os.path.join(self.results_path, 'customer_volatility_grades.csv')}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 분석 실패: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "    \n",
    "    def _save_classification_results(self, predictions):\n",
    "        \"\"\"고객별 변동성 등급 분류 결과 저장\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for customer_id, pred in predictions.items():\n",
    "            grade_info = self.classify_volatility_grade(pred['volatility_coefficient'])\n",
    "            \n",
    "            results.append({\n",
    "                '고객번호': customer_id,\n",
    "                '변동계수': pred['volatility_coefficient'],\n",
    "                '변동성등급': grade_info['grade'],\n",
    "                '위험수준': grade_info['risk_level'],\n",
    "                '상대변동계수': grade_info['relative_cv'],\n",
    "                '기준변동계수': grade_info['baseline_cv'],\n",
    "                '신뢰도': pred['confidence_score'],\n",
    "                '권장사항': grade_info['recommendation']\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        output_path = os.path.join(self.results_path, 'customer_volatility_grades.csv')\n",
    "        results_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"💾 분류 결과 저장: {output_path}\")\n",
    "\n",
    "# 실행 함수\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"한국전력공사 변동계수 알고리즘 - 완전한 버전\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 결과 폴더 확인\n",
    "    results_folders = ['./analysis_results', './results', './output']\n",
    "    results_path = None\n",
    "    \n",
    "    for folder in results_folders:\n",
    "        if os.path.exists(folder):\n",
    "            results_path = folder\n",
    "            break\n",
    "    \n",
    "    if results_path is None:\n",
    "        print(\"⚠️ 결과 폴더를 찾을 수 없습니다.\")\n",
    "        print(\"다음 중 하나의 폴더에 1-2단계 결과를 저장하세요:\")\n",
    "        for folder in results_folders:\n",
    "            print(f\"   - {folder}\")\n",
    "        results_path = './analysis_results'\n",
    "        os.makedirs(results_path, exist_ok=True)\n",
    "        print(f\"✅ 기본 폴더 생성: {results_path}\")\n",
    "    \n",
    "    # 알고리즘 실행\n",
    "    algorithm = KEPCOVolatilityCoefficient(results_path=results_path)\n",
    "    success = algorithm.run_complete_analysis()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n🎉 변동계수 분석이 성공적으로 완료되었습니다!\")\n",
    "    else:\n",
    "        print(\"\\n💥 변동계수 분석 중 오류가 발생했습니다.\")\n",
    "    \n",
    "    return algorithm\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
