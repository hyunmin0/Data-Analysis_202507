"""
í•œêµ­ì „ë ¥ê³µì‚¬ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” - NaN ë¬¸ì œ í•´ê²° ë²„ì „
RÂ² = nan ë¬¸ì œì™€ ë°ì´í„° ë¶„ì‚° ì´ìŠˆ ìˆ˜ì •
"""

import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.model_selection import cross_val_score, TimeSeriesSplit, KFold
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import joblib
import warnings
warnings.filterwarnings('ignore')

class KEPCOStackingEnsembleFixed:
    """
    ğŸ—ï¸ í•œêµ­ì „ë ¥ê³µì‚¬ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì‹œìŠ¤í…œ (NaN ë¬¸ì œ í•´ê²°)
    """
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.level0_models = {}
        self.level1_meta_model = None
        self.scaler = None
        self.performance_metrics = {}
        self.feature_importance = {}
        
        print("ğŸ—ï¸ í•œêµ­ì „ë ¥ê³µì‚¬ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì‹œìŠ¤í…œ (NaN ë¬¸ì œ í•´ê²°)")
        print()
    
    def build_level0_models(self):
        """Level-0 ê¸°ë³¸ ì˜ˆì¸¡ê¸°ë“¤ êµ¬ì¶•"""
        print("ğŸ”¨ Level-0 ê¸°ë³¸ ì˜ˆì¸¡ê¸°ë“¤ êµ¬ì¶• ì¤‘...")
        
        # 1. Random Forest
        self.level0_models['rf_model'] = {
            'model': RandomForestRegressor(
                n_estimators=50,
                max_depth=5,
                min_samples_split=5,
                min_samples_leaf=3,
                random_state=self.random_state,
                n_jobs=-1
            ),
            'specialty': 'Random Forest ì˜ˆì¸¡ê¸°'
        }
        
        # 2. Gradient Boosting
        self.level0_models['gb_model'] = {
            'model': GradientBoostingRegressor(
                n_estimators=50,
                learning_rate=0.2,
                max_depth=4,
                min_samples_split=10,
                random_state=self.random_state
            ),
            'specialty': 'Gradient Boosting ì˜ˆì¸¡ê¸°'
        }
        
        # 3. Ridge Regression
        self.level0_models['ridge_model'] = {
            'model': Ridge(
                alpha=1.0,
                random_state=self.random_state
            ),
            'specialty': 'Ridge íšŒê·€ ì˜ˆì¸¡ê¸°'
        }
        
        print(f"âœ… Level-0 ëª¨ë¸ {len(self.level0_models)}ê°œ êµ¬ì¶• ì™„ë£Œ")
        return self.level0_models
    
    def create_realistic_training_data(self, n_samples=30):
        """í˜„ì‹¤ì ì´ê³  ë‹¤ì–‘ì„± ìˆëŠ” í›ˆë ¨ ë°ì´í„° ìƒì„±"""
        print(f"ğŸ“Š í˜„ì‹¤ì ì¸ í›ˆë ¨ ë°ì´í„° ìƒì„± ì¤‘... ({n_samples}ê°œ ìƒ˜í”Œ)")
        
        np.random.seed(42)
        
        # ê³ ê°ë³„ ë‹¤ì–‘í•œ íŠ¹ì„± ìƒì„±
        features_list = []
        targets_list = []
        
        for i in range(n_samples):
            # ê³ ê° íƒ€ì… ê²°ì • (ì œì¡°ì—…, ìƒì—…, ì„œë¹„ìŠ¤ì—…)
            customer_type = np.random.choice(['manufacturing', 'commercial', 'service'])
            
            if customer_type == 'manufacturing':
                # ì œì¡°ì—…: ë†’ì€ ì‚¬ìš©ëŸ‰, ë‚®ì€ ë³€ë™ì„±
                base_power = np.random.uniform(300, 800)
                volatility = np.random.uniform(0.1, 0.3)
                efficiency = np.random.uniform(0.7, 0.9)
                digital_score = np.random.uniform(0.3, 0.7)
            elif customer_type == 'commercial':
                # ìƒì—…ì‹œì„¤: ì¤‘ê°„ ì‚¬ìš©ëŸ‰, ì¤‘ê°„ ë³€ë™ì„±
                base_power = np.random.uniform(150, 400)
                volatility = np.random.uniform(0.3, 0.6)
                efficiency = np.random.uniform(0.5, 0.8)
                digital_score = np.random.uniform(0.4, 0.8)
            else:  # service
                # ì„œë¹„ìŠ¤ì—…: ë‚®ì€ ì‚¬ìš©ëŸ‰, ë†’ì€ ë³€ë™ì„±
                base_power = np.random.uniform(50, 200)
                volatility = np.random.uniform(0.5, 0.9)
                efficiency = np.random.uniform(0.4, 0.7)
                digital_score = np.random.uniform(0.6, 0.9)
            
            # ì‹œê°„ íŒ¨í„´ íŠ¹ì„±
            peak_ratio = np.random.uniform(1.2, 2.5)  # í”¼í¬/í‰ê·  ë¹„ìœ¨
            night_ratio = np.random.uniform(0.1, 0.5)  # ì•¼ê°„/ì£¼ê°„ ë¹„ìœ¨
            weekend_ratio = np.random.uniform(0.3, 0.8)  # ì£¼ë§/í‰ì¼ ë¹„ìœ¨
            
            # ê²½ì˜ íŠ¹ì„±
            growth_trend = np.random.uniform(-0.2, 0.3)  # ì„±ì¥ íŠ¸ë Œë“œ
            stability_score = np.random.uniform(0.2, 0.9)  # ì•ˆì •ì„± ì ìˆ˜
            
            # íŠ¹ì„± ë²¡í„° êµ¬ì„±
            features = {
                'avg_power': base_power,
                'volatility': volatility,
                'efficiency': efficiency,
                'digital_score': digital_score,
                'peak_ratio': peak_ratio,
                'night_ratio': night_ratio,
                'weekend_ratio': weekend_ratio,
                'growth_trend': growth_trend,
                'stability_score': stability_score,
                'customer_type_mfg': 1 if customer_type == 'manufacturing' else 0,
                'customer_type_com': 1 if customer_type == 'commercial' else 0,
                'customer_type_svc': 1 if customer_type == 'service' else 0
            }
            
            # íƒ€ê²Ÿ ìƒì„± (ë¹„ì¦ˆë‹ˆìŠ¤ ë³€í™” í™•ë¥ )
            # ë³µí•©ì ì¸ ìš”ì¸ì„ ê³ ë ¤
            change_prob = (
                volatility * 0.4 +  # ë³€ë™ì„±ì´ ë†’ì„ìˆ˜ë¡ ë³€í™” ê°€ëŠ¥ì„± ì¦ê°€
                (1 - stability_score) * 0.3 +  # ë¶ˆì•ˆì •í• ìˆ˜ë¡ ë³€í™” ê°€ëŠ¥ì„± ì¦ê°€
                abs(growth_trend) * 0.2 +  # ê¸‰ê²©í•œ ì„±ì¥/ì‡ í‡´ì‹œ ë³€í™” ê°€ëŠ¥ì„± ì¦ê°€
                digital_score * 0.1  # ë””ì§€í„¸í™” ìˆ˜ì¤€ì´ ë†’ì„ìˆ˜ë¡ ë³€í™” ë¯¼ê°
            )
            
            # ë…¸ì´ì¦ˆ ì¶”ê°€ ë° ì •ê·œí™”
            change_prob += np.random.normal(0, 0.1)
            change_prob = np.clip(change_prob, 0.0, 1.0)
            
            features_list.append(features)
            targets_list.append(change_prob)
        
        X = pd.DataFrame(features_list)
        y = np.array(targets_list)
        
        # ë°ì´í„° í’ˆì§ˆ í™•ì¸
        print(f"âœ… ë°ì´í„° ìƒì„± ì™„ë£Œ:")
        print(f"   íŠ¹ì„± ìˆ˜: {len(X.columns)}")
        print(f"   íƒ€ê²Ÿ ë¶„í¬: í‰ê· ={y.mean():.3f}, í‘œì¤€í¸ì°¨={y.std():.3f}")
        print(f"   íƒ€ê²Ÿ ë²”ìœ„: {y.min():.3f} ~ {y.max():.3f}")
        
        # NaN ì²´í¬
        if X.isnull().any().any():
            print("âš ï¸ íŠ¹ì„±ì— NaN ê°’ ë°œê²¬")
        if np.isnan(y).any():
            print("âš ï¸ íƒ€ê²Ÿì— NaN ê°’ ë°œê²¬")
        
        return X, y
    
    def safe_cross_val_score(self, model, X, y, cv, scoring='r2'):
        """ì•ˆì „í•œ êµì°¨ê²€ì¦ ì ìˆ˜ ê³„ì‚°"""
        try:
            scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)
            
            # NaN ê°’ ì²˜ë¦¬
            valid_scores = scores[~np.isnan(scores)]
            
            if len(valid_scores) == 0:
                return np.array([0.0])  # ëª¨ë“  ì ìˆ˜ê°€ NaNì¸ ê²½ìš°
            
            return valid_scores
        
        except Exception as e:
            print(f"      êµì°¨ê²€ì¦ ì‹¤íŒ¨: {e}")
            return np.array([0.0])
    
    def train_level0_models(self, X, y):
        """Level-0 ëª¨ë¸ë“¤ í›ˆë ¨ (NaN ì•ˆì „ ì²˜ë¦¬)"""
        print("ğŸ“ Level-0 ëª¨ë¸ë“¤ í›ˆë ¨ ì‹œì‘...")
        
        n_samples = len(X)
        print(f"   ë°ì´í„° í¬ê¸°: {n_samples}ê°œ ìƒ˜í”Œ")
        
        # ë°ì´í„° ì •ê·œí™”
        self.scaler = StandardScaler()
        X_scaled = self.scaler.fit_transform(X)
        
        # êµì°¨ê²€ì¦ ì„¤ì •
        cv_splits = min(5, max(3, n_samples // 5))
        cv = KFold(n_splits=cv_splits, shuffle=True, random_state=self.random_state)
        
        print(f"   êµì°¨ê²€ì¦ í´ë“œ ìˆ˜: {cv_splits}")
        
        level0_predictions = np.zeros((len(X), len(self.level0_models)))
        
        for i, (model_name, model_config) in enumerate(self.level0_models.items()):
            print(f"   í›ˆë ¨ ì¤‘: {model_name}")
            
            model = model_config['model']
            
            try:
                # êµì°¨ê²€ì¦ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€
                cv_scores = self.safe_cross_val_score(model, X_scaled, y, cv=cv, scoring='r2')
                
                mean_score = cv_scores.mean()
                std_score = cv_scores.std()
                
                print(f"      CV RÂ² ì ìˆ˜: {mean_score:.4f} (Â±{std_score*2:.4f})")
                
                # ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ í›ˆë ¨
                model.fit(X_scaled, y)
                
                # Level-1ì„ ìœ„í•œ ì˜ˆì¸¡ê°’ ìƒì„±
                fold_predictions = np.zeros(len(X))
                
                for train_idx, val_idx in cv.split(X_scaled, y):
                    fold_model = type(model)(**model.get_params())
                    fold_model.fit(X_scaled[train_idx], y[train_idx])
                    fold_predictions[val_idx] = fold_model.predict(X_scaled[val_idx])
                
                level0_predictions[:, i] = fold_predictions
                
                # ì„±ëŠ¥ ê¸°ë¡
                self.performance_metrics[model_name] = {
                    'cv_r2_mean': mean_score,
                    'cv_r2_std': std_score,
                    'specialty': model_config['specialty']
                }
                
                # íŠ¹ì„± ì¤‘ìš”ë„
                if hasattr(model, 'feature_importances_'):
                    self.feature_importance[model_name] = {
                        'importance': model.feature_importances_,
                        'features': X.columns.tolist()
                    }
                    
            except Exception as e:
                print(f"      âŒ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
                level0_predictions[:, i] = np.mean(y)
                
                self.performance_metrics[model_name] = {
                    'cv_r2_mean': 0.0,
                    'cv_r2_std': 0.0,
                    'specialty': model_config['specialty'],
                    'error': str(e)
                }
        
        print("âœ… Level-0 ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        return level0_predictions
    
    def build_level1_meta_model(self, level0_predictions, y):
        """Level-1 ë©”íƒ€ëª¨ë¸ êµ¬ì¶•"""
        print("ğŸ§  Level-1 ë©”íƒ€ëª¨ë¸ êµ¬ì¶• ì¤‘...")
        
        # ê°„ë‹¨í•œ ë©”íƒ€ëª¨ë¸ë“¤
        meta_candidates = {
            'ridge': Ridge(alpha=1.0, random_state=self.random_state),
            'simple_average': None
        }
        
        best_score = -np.inf
        best_meta_model = None
        best_meta_name = None
        
        cv_splits = min(3, len(level0_predictions) - 1)
        kfold = KFold(n_splits=cv_splits, shuffle=True, random_state=self.random_state)
        
        print("   ë©”íƒ€ëª¨ë¸ í›„ë³´ í‰ê°€:")
        
        for name, model in meta_candidates.items():
            try:
                if name == 'simple_average':
                    # ë‹¨ìˆœ í‰ê· 
                    avg_predictions = np.mean(level0_predictions, axis=1)
                    score = r2_score(y, avg_predictions)
                    if np.isnan(score):
                        score = 0.0
                else:
                    # ëª¨ë¸ ê¸°ë°˜
                    scores = self.safe_cross_val_score(model, level0_predictions, y, cv=kfold, scoring='r2')
                    score = scores.mean()
                
                print(f"      {name}: RÂ² = {score:.4f}")
                
                if score > best_score:
                    best_score = score
                    best_meta_model = model
                    best_meta_name = name
                    
            except Exception as e:
                print(f"      {name}: í‰ê°€ ì‹¤íŒ¨ - {e}")
        
        # ìµœì  ë©”íƒ€ëª¨ë¸ ì„¤ì •
        if best_meta_model is not None:
            best_meta_model.fit(level0_predictions, y)
            self.level1_meta_model = best_meta_model
        else:
            self.level1_meta_model = 'simple_average'
            best_meta_name = 'simple_average'
        
        print(f"âœ… ìµœì  ë©”íƒ€ëª¨ë¸ ì„ íƒ: {best_meta_name} (RÂ² = {best_score:.4f})")
        
        self.performance_metrics['meta_model'] = {
            'model_type': best_meta_name,
            'cv_r2_mean': best_score
        }
        
        return True
    
    def fit(self, X, y):
        """ì „ì²´ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” í›ˆë ¨"""
        print("ğŸ‹ï¸ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì „ì²´ í›ˆë ¨ ì‹œì‘")
        print("=" * 60)
        
        # 1. Level-0 ëª¨ë¸ë“¤ êµ¬ì¶•
        self.build_level0_models()
        
        # 2. Level-0 ëª¨ë¸ë“¤ í›ˆë ¨
        level0_predictions = self.train_level0_models(X, y)
        
        # 3. Level-1 ë©”íƒ€ëª¨ë¸ êµ¬ì¶•
        meta_success = self.build_level1_meta_model(level0_predictions, y)
        
        if meta_success:
            print("\nğŸ‰ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” í›ˆë ¨ ì™„ë£Œ!")
            self._print_performance_summary()
            return True
        else:
            print("\nâŒ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” í›ˆë ¨ ì‹¤íŒ¨")
            return False
    
    def predict(self, X):
        """ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì˜ˆì¸¡"""
        if self.level1_meta_model is None:
            raise ValueError("ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ì •ê·œí™”
        X_scaled = self.scaler.transform(X)
        
        # Level-0 ì˜ˆì¸¡
        level0_preds = np.zeros((len(X), len(self.level0_models)))
        
        for i, (model_name, model_config) in enumerate(self.level0_models.items()):
            model = model_config['model']
            try:
                level0_preds[:, i] = model.predict(X_scaled)
            except:
                level0_preds[:, i] = 0.5  # ì‹¤íŒ¨ì‹œ ì¤‘ê°„ê°’
        
        # Level-1 ìµœì¢… ì˜ˆì¸¡
        if self.level1_meta_model == 'simple_average':
            final_predictions = np.mean(level0_preds, axis=1)
        else:
            final_predictions = self.level1_meta_model.predict(level0_preds)
        
        return final_predictions
    
    def _print_performance_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        print("\nğŸ“Š ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ì„±ëŠ¥ ìš”ì•½")
        print("-" * 40)
        
        print("Level-0 ëª¨ë¸ ì„±ëŠ¥:")
        for model_name, metrics in self.performance_metrics.items():
            if model_name != 'meta_model':
                r2_score = metrics.get('cv_r2_mean', 0)
                if 'error' in metrics:
                    print(f"  {model_name}: í›ˆë ¨ ì‹¤íŒ¨")
                else:
                    print(f"  {model_name}: RÂ² = {r2_score:.4f}")
        
        if 'meta_model' in self.performance_metrics:
            meta_metrics = self.performance_metrics['meta_model']
            print(f"\nLevel-1 ë©”íƒ€ëª¨ë¸:")
            print(f"  íƒ€ì…: {meta_metrics['model_type']}")
            print(f"  ì„±ëŠ¥: RÂ² = {meta_metrics['cv_r2_mean']:.4f}")

def main_fixed_demo():
    """NaN ë¬¸ì œ í•´ê²°ëœ ë°ëª¨"""
    print("ğŸš€ NaN ë¬¸ì œ í•´ê²°ëœ ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ë°ëª¨")
    print("=" * 50)
    
    # 1. ì•™ìƒë¸” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    ensemble = KEPCOStackingEnsembleFixed()
    
    # 2. í˜„ì‹¤ì ì¸ ë°ì´í„° ìƒì„±
    X, y = ensemble.create_realistic_training_data(n_samples=25)
    
    # 3. ëª¨ë¸ í›ˆë ¨
    success = ensemble.fit(X, y)
    
    if success:
        # 4. ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
        predictions = ensemble.predict(X)
        
        # 5. ì„±ëŠ¥ í‰ê°€
        mae = mean_absolute_error(y, predictions)
        mse = mean_squared_error(y, predictions)
        r2 = r2_score(y, predictions)
        
        print(f"\nğŸ“Š ì „ì²´ ì„±ëŠ¥ í‰ê°€:")
        print(f"  MAE: {mae:.4f}")
        print(f"  MSE: {mse:.4f}")
        print(f"  RÂ²:  {r2:.4f}")
        
        # 6. ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ
        print(f"\nğŸ”® ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:")
        for i in range(min(5, len(predictions))):
            print(f"  ê³ ê° {i+1}: ì‹¤ì œ={y[i]:.3f}, ì˜ˆì¸¡={predictions[i]:.3f}")
        
        print("\nğŸ‰ ë°ëª¨ ì™„ë£Œ! NaN ë¬¸ì œ í•´ê²°ë¨")
        return ensemble
    else:
        print("\nâŒ ë°ëª¨ ì‹¤íŒ¨")
        return None

if __name__ == "__main__":
    main_fixed_demo()