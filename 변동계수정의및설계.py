# ============================================================================
# 1ë‹¨ê³„: í•œêµ­ì „ë ¥ê³µì‚¬ ë³€ë™ê³„ìˆ˜ ì •ì˜ ë° ì„¤ê³„ (ì™„ì „ ë…ë¦½ ì‹¤í–‰ ë²„ì „)
# 1-2ë‹¨ê³„ ê²°ê³¼ë¥¼ ì™„ì „íˆ í™œìš©í•œ ì ì‘í˜• ë³€ë™ê³„ìˆ˜ ì •ì˜ - í•˜ë“œì½”ë”© ì œê±°
# ============================================================================

import pandas as pd
import numpy as np
import json
import os
import re
from datetime import datetime
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

class KEPCOVolatilityCoefficientDesigner:
    """
    í•œêµ­ì „ë ¥ê³µì‚¬ ë³€ë™ê³„ìˆ˜ ì •ì˜ ë° ì„¤ê³„ í´ë˜ìŠ¤
    1-2ë‹¨ê³„ ê²°ê³¼ì— ì™„ì „íˆ ì˜ì¡´í•˜ì—¬ ë³€ë™ê³„ìˆ˜ë¥¼ ì •ì˜ (í•˜ë“œì½”ë”© ì œê±°)
    """
    
    def __init__(self, results_path='./analysis_results'):
        """
        ì´ˆê¸°í™”
        Args:
            results_path: 1-2ë‹¨ê³„ ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        """
        self.results_path = results_path
        
        # 1-2ë‹¨ê³„ ê²°ê³¼ ì €ì¥ì†Œ
        self.step1_results = None
        self.step2_results = None
        
        # ì„¤ê³„ë  ë³€ë™ê³„ìˆ˜ êµ¬ì„±ìš”ì†Œë“¤
        self.volatility_components = {}
        self.industry_benchmarks = {}
        self.temporal_patterns = {}
        self.seasonal_adjustments = {}
        self.anomaly_criteria = {}
        
        print("ğŸ¯ ë³€ë™ê³„ìˆ˜ ì •ì˜ ë° ì„¤ê³„ ì‹œì‘")
        print(f"ê²°ê³¼ í´ë”: {self.results_path}")
        print("=" * 60)
        
        # 1-2ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ
        self._load_prerequisite_results()
        
        # ë³€ë™ê³„ìˆ˜ ì •ì˜ ì„¤ê³„
        self._design_volatility_definition()
    
    def _load_prerequisite_results(self):
        """1-2ë‹¨ê³„ ê²°ê³¼ í•„ìˆ˜ ë¡œë“œ"""
        print("ğŸ“‚ 1-2ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ ì¤‘...")
        
        # 1ë‹¨ê³„ ê²°ê³¼ (analysis_results.json) - ì—¬ëŸ¬ ê²½ë¡œì—ì„œ ì‹œë„
        step1_paths = [
            './analysis_results.json',                          # í˜„ì¬ ë””ë ‰í„°ë¦¬
            os.path.join(self.results_path, 'analysis_results.json'),  # ì§€ì •ëœ ê²°ê³¼ í´ë”
            'analysis_results.json'                             # ì ˆëŒ€ ê²½ë¡œ
        ]
        
        step1_loaded = False
        for step1_file in step1_paths:
            if os.path.exists(step1_file):
                try:
                    with open(step1_file, 'r', encoding='utf-8') as f:
                        self.step1_results = json.load(f)
                    print(f"âœ… 1ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {step1_file}")
                    step1_loaded = True
                    break
                except Exception as e:
                    print(f"âš ï¸ {step1_file} ì½ê¸° ì‹¤íŒ¨: {e}")
                    continue
        
        if not step1_loaded:
            print("âŒ 1ë‹¨ê³„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë‹¤ìŒ ìœ„ì¹˜ì— analysis_results.json íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤:")
            for path in step1_paths:
                print(f"  - {path}")
            raise FileNotFoundError("1ë‹¨ê³„ ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤: analysis_results.json")
        
        # 2ë‹¨ê³„ ê²°ê³¼ (volatility_summary.csv) - ì—¬ëŸ¬ ê²½ë¡œì—ì„œ ì‹œë„
        step2_paths = [
            './volatility_summary.csv',                         # í˜„ì¬ ë””ë ‰í„°ë¦¬
            os.path.join(self.results_path, 'volatility_summary.csv'),  # ì§€ì •ëœ ê²°ê³¼ í´ë”
            'volatility_summary.csv'                            # ì ˆëŒ€ ê²½ë¡œ
        ]
        
        step2_loaded = False
        for step2_file in step2_paths:
            if os.path.exists(step2_file):
                try:
                    self.step2_results = pd.read_csv(step2_file)
                    print(f"âœ… 2ë‹¨ê³„ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {step2_file}")
                    step2_loaded = True
                    break
                except Exception as e:
                    print(f"âš ï¸ {step2_file} ì½ê¸° ì‹¤íŒ¨: {e}")
                    continue
        
        if not step2_loaded:
            print("âŒ 2ë‹¨ê³„ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ë‹¤ìŒ ìœ„ì¹˜ì— volatility_summary.csv íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤:")
            for path in step2_paths:
                print(f"  - {path}")
            raise FileNotFoundError("2ë‹¨ê³„ ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤: volatility_summary.csv")
        
        # ë¡œë“œëœ ë°ì´í„° í™•ì¸
        print("\nğŸ“‹ ë¡œë“œëœ ë°ì´í„° í™•ì¸:")
        print(f"  1ë‹¨ê³„ ê²°ê³¼ í‚¤: {list(self.step1_results.keys()) if isinstance(self.step1_results, dict) else 'dict í˜•íƒœê°€ ì•„ë‹˜'}")
        print(f"  2ë‹¨ê³„ ê²°ê³¼ í˜•íƒœ: {self.step2_results.shape if self.step2_results is not None else 'None'}")
        if self.step2_results is not None and len(self.step2_results) > 0:
            print(f"  2ë‹¨ê³„ ë©”íŠ¸ë¦­ ì˜ˆì‹œ: {self.step2_results['metric'].tolist()[:3] if 'metric' in self.step2_results.columns else 'ë©”íŠ¸ë¦­ ì»¬ëŸ¼ ì—†ìŒ'}")
    
    def _design_volatility_definition(self):
        """ë³€ë™ê³„ìˆ˜ ì •ì˜ ì„¤ê³„"""
        print("ğŸ”§ ë³€ë™ê³„ìˆ˜ ì •ì˜ ì„¤ê³„ ì¤‘...")
        
        # 1. ê¸°ë³¸ ë³€ë™ê³„ìˆ˜ êµ¬ì„±ìš”ì†Œ ì •ì˜
        self._define_basic_components()
        
        # 2. ì—…ì¢…ë³„ ë²¤ì¹˜ë§ˆí¬ ì„¤ì •
        self._establish_industry_benchmarks()
        
        # 3. ì‹œê°„ íŒ¨í„´ ê°€ì¤‘ì¹˜ ì„¤ê³„
        self._design_temporal_weights()
        
        # 4. ê³„ì ˆì„± ì¡°ì • ê³„ìˆ˜ ì„¤ê³„
        self._design_seasonal_adjustments()
        
        # 5. ì´ìƒ íŒ¨í„´ íƒì§€ ê¸°ì¤€ ì„¤ê³„
        self._design_anomaly_criteria()
        
        # 6. ìµœì¢… ë³€ë™ê³„ìˆ˜ ê³µì‹ ì •ì˜
        self._define_final_formula()
        
        print("âœ… ë³€ë™ê³„ìˆ˜ ì •ì˜ ì„¤ê³„ ì™„ë£Œ")
    
    def _define_basic_components(self):
        """ê¸°ë³¸ ë³€ë™ê³„ìˆ˜ êµ¬ì„±ìš”ì†Œ ì •ì˜ (2ë‹¨ê³„ ê²°ê³¼ ê¸°ë°˜)"""
        print("  ğŸ“Š ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ì •ì˜...")
        
        # 2ë‹¨ê³„ ê²°ê³¼ì—ì„œ ë°œê²¬ëœ ë³€ë™ì„± íŒ¨í„´ ë¶„ì„
        cv_metrics = {}
        for _, row in self.step2_results.iterrows():
            metric = row['metric']
            value = row['value']
            
            if 'cv' in metric.lower():
                cv_metrics[metric] = value
                print(f"    ë°œê²¬ëœ CV ë©”íŠ¸ë¦­: {metric} = {value:.3f}")
        
        # ê¸°ë³¸ ë³€ë™ê³„ìˆ˜ ìœ í˜•ë³„ ê°€ì¤‘ì¹˜ ê²°ì •
        if 'overall_cv' in cv_metrics:
            overall_cv = cv_metrics['overall_cv']
            
            # ì „ì²´ ë³€ë™ì„± ìˆ˜ì¤€ì— ë”°ë¥¸ êµ¬ì„±ìš”ì†Œ ê°€ì¤‘ì¹˜
            if overall_cv > 0.3:  # ë†’ì€ ë³€ë™ì„±
                weights = {
                    'basic_cv': 0.3,        # ê¸°ë³¸ ë³€ë™ê³„ìˆ˜
                    'temporal_cv': 0.25,    # ì‹œê°„ëŒ€ë³„ ë³€ë™ì„±
                    'seasonal_cv': 0.2,     # ê³„ì ˆì„± ë³€ë™ì„±
                    'pattern_cv': 0.15,     # íŒ¨í„´ ì•ˆì •ì„±
                    'anomaly_cv': 0.1       # ì´ìƒ íŒ¨í„´ ê°€ì¤‘ì¹˜
                }
            elif overall_cv > 0.2:  # ì¤‘ê°„ ë³€ë™ì„±
                weights = {
                    'basic_cv': 0.35,
                    'temporal_cv': 0.3,
                    'seasonal_cv': 0.15,
                    'pattern_cv': 0.15,
                    'anomaly_cv': 0.05
                }
            else:  # ë‚®ì€ ë³€ë™ì„± (ì•ˆì •ì )
                weights = {
                    'basic_cv': 0.4,
                    'temporal_cv': 0.25,
                    'seasonal_cv': 0.2,
                    'pattern_cv': 0.1,
                    'anomaly_cv': 0.05
                }
        else:
            # 2ë‹¨ê³„ ê²°ê³¼ì—ì„œ overall_cvë¥¼ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            weights = {
                'basic_cv': 0.35,
                'temporal_cv': 0.25,
                'seasonal_cv': 0.2,
                'pattern_cv': 0.15,
                'anomaly_cv': 0.05
            }
        
        self.volatility_components = {
            'component_weights': weights,
            'normalization_method': 'z_score',
            'outlier_handling': 'winsorize',
            'missing_value_strategy': 'interpolate',
            'data_driven': True
        }
        
        print(f"    êµ¬ì„±ìš”ì†Œ ê°€ì¤‘ì¹˜: {weights}")
    
    def _establish_industry_benchmarks(self):
        """ì—…ì¢…ë³„ ë²¤ì¹˜ë§ˆí¬ ì„¤ì • (1-2ë‹¨ê³„ ê²°ê³¼ ê¸°ë°˜)"""
        print("  ğŸ­ ì—…ì¢…ë³„ ë²¤ì¹˜ë§ˆí¬ ì„¤ì •...")
        
        # 1ë‹¨ê³„ ê²°ê³¼ì—ì„œ ê³ ê° êµ¬ì„± ë¶„ì„
        customer_summary = self.step1_results.get('customer_summary', {})
        
        # 2ë‹¨ê³„ ê²°ê³¼ì—ì„œ ì‹¤ì œ ë³€ë™ê³„ìˆ˜ ë¶„í¬ ì¶”ì¶œ
        actual_cv_by_contract = {}
        overall_cv = None
        
        # 2ë‹¨ê³„ì—ì„œ ê³„ì•½ì¢…ë³„ ì‹¤ì œ ë³€ë™ê³„ìˆ˜ ì°¾ê¸°
        for _, row in self.step2_results.iterrows():
            metric = row['metric']
            value = row['value']
            
            # ì „ì²´ ë³€ë™ê³„ìˆ˜
            if metric == 'overall_cv' or 'total_cv' in metric.lower():
                overall_cv = value
                print(f"    ì‹¤ì œ ì „ì²´ ë³€ë™ê³„ìˆ˜: {overall_cv:.3f}")
            
            # ê³„ì•½ì¢…ë³„ ë³€ë™ê³„ìˆ˜ (ë§Œì•½ ìˆë‹¤ë©´)
            elif 'contract' in metric.lower() and 'cv' in metric.lower():
                # ë©”íŠ¸ë¦­ëª…ì—ì„œ ê³„ì•½ì¢…ë³„ ì¶”ì¶œ ì‹œë„
                for contract_type in ['222', '226', '311', '322', '726']:
                    if contract_type in metric:
                        actual_cv_by_contract[contract_type] = value
                        print(f"    ì‹¤ì œ ê³„ì•½ì¢…ë³„ {contract_type} CV: {value:.3f}")
        
        if 'contract_types' in customer_summary:
            contract_dist = customer_summary['contract_types']
            total_customers = sum(contract_dist.values())
            
            print(f"    ì´ ê³ ê°ìˆ˜: {total_customers}ëª…")
            
            # ê³„ì•½ì¢…ë³„ ê¸°ì¤€ ë³€ë™ê³„ìˆ˜ ì„¤ì • (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
            benchmarks = {}
            
            for contract_type, count in contract_dist.items():
                ratio = count / total_customers
                
                # ì‹¤ì œ í•´ë‹¹ ê³„ì•½ì¢…ë³„ CVê°€ ìˆìœ¼ë©´ ì‚¬ìš©
                if str(contract_type) in actual_cv_by_contract:
                    base_cv = actual_cv_by_contract[str(contract_type)]
                    print(f"    ê³„ì•½ì¢…ë³„ {contract_type}: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ {base_cv:.3f}")
                
                # ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì „ì²´ í‰ê· ì—ì„œ ì¶”ì •
                elif overall_cv is not None:
                    # ê³ ê° ë¹„ìœ¨ì— ë”°ë¥¸ ìƒëŒ€ì  ì•ˆì •ì„± ì¶”ì •
                    if ratio > 0.4:  # ì£¼ìš” ê³„ì•½ì¢…ë³„ (ë” ì•ˆì •ì ì¼ ê²ƒìœ¼ë¡œ ì¶”ì •)
                        base_cv = overall_cv * 0.85
                    elif ratio > 0.2:  # ì¤‘ê°„ ê³„ì•½ì¢…ë³„
                        base_cv = overall_cv * 1.0
                    else:  # ì†Œìˆ˜ ê³„ì•½ì¢…ë³„ (ë” ë³€ë™ì ì¼ ê²ƒìœ¼ë¡œ ì¶”ì •)
                        base_cv = overall_cv * 1.15
                    
                    print(f"    ê³„ì•½ì¢…ë³„ {contract_type}: ì „ì²´ CV ê¸°ë°˜ ì¶”ì • {base_cv:.3f} (ë¹„ìœ¨: {ratio:.1%})")
                
                # ì‹¤ì œ ë°ì´í„°ë„ ì—†ê³  ì „ì²´ í‰ê· ë„ ì—†ìœ¼ë©´ ì—ëŸ¬
                else:
                    raise ValueError("âŒ ë³€ë™ê³„ìˆ˜ ê¸°ì¤€ê°’ì„ ì„¤ì •í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 2ë‹¨ê³„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                
                # ë¶„í¬ ë¹„ìœ¨ì— ë”°ë¥¸ ë¯¸ì„¸ ì¡°ì •
                if ratio > 0.4:  # ì£¼ìš” ê³„ì•½ì¢…ë³„ (ë” ì—„ê²©í•œ ê¸°ì¤€)
                    adjusted_cv = base_cv * 0.95
                elif ratio < 0.1:  # ì†Œìˆ˜ ê³„ì•½ì¢…ë³„ (ê´€ëŒ€í•œ ê¸°ì¤€)
                    adjusted_cv = base_cv * 1.05
                else:
                    adjusted_cv = base_cv
                
                benchmarks[str(contract_type)] = adjusted_cv
                print(f"      ìµœì¢… ê¸°ì¤€ê°’ {contract_type}: {adjusted_cv:.3f} (ê³ ê°ìˆ˜: {count}ëª…, ë¹„ìœ¨: {ratio:.1%})")
        
        # ì‚¬ìš©ìš©ë„ë³„ ì¡°ì • ê³„ìˆ˜ (2ë‹¨ê³„ ê²°ê³¼ ê¸°ë°˜)
        usage_adjustments = {}
        
        # 2ë‹¨ê³„ì—ì„œ ì‚¬ìš©ìš©ë„ë³„ ë³€ë™ì„± ì°¨ì´ ì°¾ê¸°
        usage_cv_ratios = {}
        for _, row in self.step2_results.iterrows():
            metric = row['metric']
            value = row['value']
            
            # ìƒì—…ìš©/ê´‘ê³µì—…ìš© ë³€ë™ì„± ë¹„êµ ë©”íŠ¸ë¦­ ì°¾ê¸°
            if 'commercial' in metric.lower() or 'ìƒì—…' in metric or '02' in metric:
                usage_cv_ratios['02'] = value
            elif 'industrial' in metric.lower() or 'ê´‘ê³µì—…' in metric or 'ì œì¡°' in metric or '09' in metric:
                usage_cv_ratios['09'] = value
        
        if 'usage_types' in customer_summary:
            usage_dist = customer_summary['usage_types']
            
            for usage_type, count in usage_dist.items():
                usage_key = str(usage_type)
                
                if usage_key in usage_cv_ratios and overall_cv is not None:
                    # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¡°ì • ê³„ìˆ˜
                    adjustment = usage_cv_ratios[usage_key] / overall_cv
                    usage_adjustments[usage_key] = adjustment
                    print(f"    ì‚¬ìš©ìš©ë„ {usage_type}: ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ì¡°ì •ê³„ìˆ˜ {adjustment:.3f}")
                
                else:
                    # ê¸°ë³¸ê°’ (ì¡°ì • ì—†ìŒ)
                    usage_adjustments[usage_key] = 1.0
                    print(f"    ì‚¬ìš©ìš©ë„ {usage_type}: ë°ì´í„° ì—†ì–´ ê¸°ë³¸ ì¡°ì •ê³„ìˆ˜ 1.0 ì‚¬ìš©")
        
        self.industry_benchmarks = {
            'contract_baselines': benchmarks,
            'usage_adjustments': usage_adjustments,
            'benchmark_source': 'step1_customer_analysis_step2_actual_cv',
            'last_updated': datetime.now().isoformat(),
            'data_driven': True
        }
    
    def _design_temporal_weights(self):
        """ì‹œê°„ íŒ¨í„´ ê°€ì¤‘ì¹˜ ì„¤ê³„ (2ë‹¨ê³„ ê²°ê³¼ ê¸°ë°˜)"""
        print("  â° ì‹œê°„ íŒ¨í„´ ê°€ì¤‘ì¹˜ ì„¤ê³„...")
        
        # 2ë‹¨ê³„ ê²°ê³¼ì—ì„œ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„
        temporal_metrics = {}
        for _, row in self.step2_results.iterrows():
            metric = row['metric']
            value = row['value']
            
            if any(keyword in metric.lower() for keyword in ['peak', 'hour', 'time', 'daily']):
                temporal_metrics[metric] = value
                print(f"    ì‹œê°„ ê´€ë ¨ ë©”íŠ¸ë¦­: {metric} = {value:.3f}")
        
        # í”¼í¬/ì˜¤í”„í”¼í¬ ê°€ì¤‘ì¹˜ ì„¤ì •
        peak_volatility = None
        for metric, value in temporal_metrics.items():
            if 'peak' in metric and 'cv' in metric:
                peak_volatility = value
                break
        
        if peak_volatility:
            if peak_volatility > 0.35:  # ë†’ì€ í”¼í¬ ë³€ë™ì„±
                peak_weight = 2.0
                off_peak_weight = 0.6
            elif peak_volatility > 0.25:  # ì¤‘ê°„ í”¼í¬ ë³€ë™ì„±
                peak_weight = 1.5
                off_peak_weight = 0.8
            else:  # ë‚®ì€ í”¼í¬ ë³€ë™ì„±
                peak_weight = 1.3
                off_peak_weight = 0.9
        else:
            # ê¸°ë³¸ê°’
            peak_weight = 1.5
            off_peak_weight = 0.8
        
        # ì‹¤ì œ í”¼í¬ ì‹œê°„ëŒ€ íƒì§€
        self._detect_dynamic_peak_hours()
        
        # ìš”ì¼ë³„ ê°€ì¤‘ì¹˜
        weekday_weight = 1.2
        weekend_weight = 0.8
        
        self.temporal_patterns = {
            'peak_weight': peak_weight,
            'off_peak_weight': off_peak_weight,
            'weekday_weight': weekday_weight,
            'weekend_weight': weekend_weight,
            'holiday_weight': 0.7,
            'temporal_normalization': 'weighted_average',
            'data_driven': True
        }
        
        print(f"    í”¼í¬ ê°€ì¤‘ì¹˜: {peak_weight}, ì˜¤í”„í”¼í¬: {off_peak_weight}")
    
    def _detect_dynamic_peak_hours(self):
        """2ë‹¨ê³„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ í”¼í¬ ì‹œê°„ëŒ€ ë™ì  íƒì§€"""
        print("    ğŸ” ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í”¼í¬ ì‹œê°„ëŒ€ íƒì§€...")
        
        discovered_peak_hours = None
        
        # 1ë‹¨ê³„ analysis_results.jsonì—ì„œ ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ì¶”ì¶œ
        if self.step1_results:
            # ì‹œê°„ëŒ€ë³„ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            if 'hourly_patterns' in self.step1_results:
                hourly_data = self.step1_results['hourly_patterns']
                if 'peak_hours' in hourly_data:
                    discovered_peak_hours = hourly_data['peak_hours']
                    print(f"      1ë‹¨ê³„ì—ì„œ ë°œê²¬ëœ í”¼í¬ ì‹œê°„: {discovered_peak_hours}")
            
            # ë‹¤ë¥¸ í˜•íƒœë¡œ ì €ì¥ë˜ì–´ ìˆì„ ìˆ˜ ìˆìŒ
            elif 'pattern_analysis' in self.step1_results:
                pattern_data = self.step1_results['pattern_analysis']
                if 'peak_hours' in pattern_data:
                    discovered_peak_hours = pattern_data['peak_hours']
            
            # ì‹œê°„ëŒ€ë³„ í†µê³„ê°€ ìˆë‹¤ë©´ ìƒìœ„ 20% ì‹œê°„ëŒ€ë¥¼ í”¼í¬ë¡œ ì„¤ì •
            elif 'hourly_stats' in self.step1_results:
                hourly_stats = self.step1_results['hourly_stats']
                # ì‹œê°„ëŒ€ë³„ í‰ê·  ì‚¬ìš©ëŸ‰ì´ ìˆë‹¤ë©´
                if isinstance(hourly_stats, dict):
                    hour_averages = {}
                    for hour_key, stats in hourly_stats.items():
                        if isinstance(stats, dict) and 'mean' in stats:
                            try:
                                hour = int(hour_key.replace('hour_', '').replace('ì‹œ', ''))
                                hour_averages[hour] = stats['mean']
                            except:
                                continue
                    
                    if hour_averages:
                        # ìƒìœ„ 20% ì‹œê°„ëŒ€ë¥¼ í”¼í¬ë¡œ ì„¤ì •
                        sorted_hours = sorted(hour_averages.items(), key=lambda x: x[1], reverse=True)
                        num_peak_hours = max(4, len(sorted_hours) // 5)  # ìµœì†Œ 4ì‹œê°„, ì „ì²´ì˜ 20%
                        discovered_peak_hours = [hour for hour, _ in sorted_hours[:num_peak_hours]]
                        print(f"      ì‹œê°„ëŒ€ë³„ í†µê³„ ê¸°ë°˜ í”¼í¬ ì‹œê°„: {discovered_peak_hours}")
        
        # 2ë‹¨ê³„ volatility_summary.csvì—ì„œ ì‹œê°„ëŒ€ë³„ ì •ë³´ ì¶”ì¶œ
        if not discovered_peak_hours and self.step2_results is not None:
            # ì‹œê°„ëŒ€ë³„ ë³€ë™ì„± ì •ë³´ ì°¾ê¸°
            peak_related_metrics = self.step2_results[
                self.step2_results['metric'].str.contains('peak|hour|time', case=False, na=False)
            ]
            
            if not peak_related_metrics.empty:
                print(f"      2ë‹¨ê³„ì—ì„œ ì‹œê°„ ê´€ë ¨ ë©”íŠ¸ë¦­ {len(peak_related_metrics)}ê°œ ë°œê²¬")
                # íŠ¹ì • ë©”íŠ¸ë¦­ì—ì„œ í”¼í¬ ì‹œê°„ ì •ë³´ ì¶”ì¶œ ì‹œë„
                for _, row in peak_related_metrics.iterrows():
                    metric = row['metric']
                    value = row['value']
                    
                    # ë©”íŠ¸ë¦­ëª…ì—ì„œ ì‹œê°„ ì •ë³´ ì¶”ì¶œ ì‹œë„
                    if 'peak_hours' in metric.lower():
                        try:
                            # ê°’ì´ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì˜ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                            if isinstance(value, str) and '[' in value:
                                import ast
                                discovered_peak_hours = ast.literal_eval(value)
                                print(f"      2ë‹¨ê³„ì—ì„œ ì¶”ì¶œëœ í”¼í¬ ì‹œê°„: {discovered_peak_hours}")
                                break
                        except:
                            continue
        
        # ì‹¤ì œ ë°œê²¬ëœ í”¼í¬ ì‹œê°„ ì‚¬ìš©
        if discovered_peak_hours and isinstance(discovered_peak_hours, list):
            # ìœ íš¨ì„± ê²€ì‚¬
            valid_peak_hours = [h for h in discovered_peak_hours if isinstance(h, int) and 0 <= h <= 23]
            if valid_peak_hours:
                self.temporal_patterns['peak_hours'] = valid_peak_hours
                print(f"    âœ… ì‹¤ì œ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ í”¼í¬ ì‹œê°„: {valid_peak_hours}")
            else:
                print(f"    âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ í”¼í¬ ì‹œê°„ ë°ì´í„°: {discovered_peak_hours}")
                self._set_fallback_peak_hours()
        else:
            print(f"    âš ï¸ í”¼í¬ ì‹œê°„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            self._set_fallback_peak_hours()
        
        # ì˜¤í”„í”¼í¬ ì‹œê°„ëŒ€ ê³„ì‚°
        peak_hours = self.temporal_patterns['peak_hours']
        all_hours = set(range(24))
        off_peak_hours = list(all_hours - set(peak_hours))
        self.temporal_patterns['off_peak_hours'] = off_peak_hours
        
        print(f"    ğŸ“‰ ì˜¤í”„í”¼í¬ ì‹œê°„: {off_peak_hours}")
    
    def _set_fallback_peak_hours(self):
        """í”¼í¬ ì‹œê°„ì„ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ ëŒ€ì²´ê°’ ì„¤ì • (2ë‹¨ê³„ ê²°ê³¼ ê¸°ë°˜)"""
        print("    ğŸ”„ ëŒ€ì²´ í”¼í¬ ì‹œê°„ ì„¤ì •...")
        
        # 2ë‹¨ê³„ ê²°ê³¼ì—ì„œ ì‹œê°„ëŒ€ë³„ ì •ë³´ ì¶”ì¶œ ì‹œë„
        hourly_patterns = {}
        
        for _, row in self.step2_results.iterrows():
            metric = row['metric']
            value = row['value']
            
            # ì‹œê°„ëŒ€ë³„ ì‚¬ìš©ëŸ‰ì´ë‚˜ ë³€ë™ì„± ì •ë³´ ì°¾ê¸°
            if 'hour' in metric.lower() and ('usage' in metric.lower() or 'power' in metric.lower() or 'cv' in metric.lower()):
                # ë©”íŠ¸ë¦­ëª…ì—ì„œ ì‹œê°„ ì¶”ì¶œ ì‹œë„
                hour_match = re.search(r'(\d+)(?:h|hour|ì‹œ)', metric)
                if hour_match:
                    hour = int(hour_match.group(1))
                    if 0 <= hour <= 23:
                        hourly_patterns[hour] = value
        
        # ì‹œê°„ëŒ€ë³„ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ìƒìœ„ ì‹œê°„ëŒ€ë¥¼ í”¼í¬ë¡œ ì„¤ì •
        if len(hourly_patterns) >= 4:  # ìµœì†Œ 4ì‹œê°„ ë°ì´í„° í•„ìš”
            # ê°’ì´ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 20-30% ì„ íƒ
            sorted_hours = sorted(hourly_patterns.items(), key=lambda x: x[1], reverse=True)
            num_peak_hours = max(4, min(8, len(sorted_hours) // 4))  # 4-8ì‹œê°„ ë²”ìœ„
            fallback_peak_hours = [hour for hour, _ in sorted_hours[:num_peak_hours]]
            
            print(f"      2ë‹¨ê³„ ë°ì´í„° ê¸°ë°˜ í”¼í¬ ì‹œê°„: {fallback_peak_hours}")
            print(f"      ê¸°ì¤€ ë°ì´í„°: {len(hourly_patterns)}ê°œ ì‹œê°„ëŒ€")
            
        else:
            # 2ë‹¨ê³„ ë°ì´í„°ë„ ë¶€ì¡±í•˜ë©´ 1ë‹¨ê³„ ê²°ê³¼ì—ì„œ ì°¾ê¸°
            if self.step1_results and 'daily_patterns' in self.step1_results:
                daily_patterns = self.step1_results['daily_patterns']
                if 'peak_usage_hours' in daily_patterns:
                    fallback_peak_hours = daily_patterns['peak_usage_hours']
                    print(f"      1ë‹¨ê³„ ë°ì´í„° ê¸°ë°˜ í”¼í¬ ì‹œê°„: {fallback_peak_hours}")
                else:
                    # ì •ë§ ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ìµœì†Œí•œì˜ ì¶”ì •
                    fallback_peak_hours = [9, 10, 14, 15]  # ìµœì†Œí•œì˜ ì¼ë°˜ì  íŒ¨í„´
                    print(f"      ìµœì†Œ ì¶”ì • í”¼í¬ ì‹œê°„: {fallback_peak_hours}")
                    print(f"      âš ï¸ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ í”¼í¬ ì‹œê°„ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìµœì†Œ ì¶”ì •ê°’ ì‚¬ìš©")
            else:
                # ì •ë§ ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ìµœì†Œí•œì˜ ì¶”ì •
                fallback_peak_hours = [9, 10, 14, 15]  # ìµœì†Œí•œì˜ ì¼ë°˜ì  íŒ¨í„´
                print(f"      ìµœì†Œ ì¶”ì • í”¼í¬ ì‹œê°„: {fallback_peak_hours}")
                print(f"      âš ï¸ 1-2ë‹¨ê³„ì—ì„œ ì‹œê°„ëŒ€ë³„ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        
        self.temporal_patterns['peak_hours'] = fallback_peak_hours
        self.temporal_patterns['peak_hours_source'] = 'step2_hourly_analysis' if len(hourly_patterns) >= 4 else 'minimum_estimation'
    
    def _design_seasonal_adjustments(self):
        """ê³„ì ˆì„± ì¡°ì • ê³„ìˆ˜ ì„¤ê³„ (2ë‹¨ê³„ ê²°ê³¼ ê¸°ë°˜)"""
        print("  ğŸŒ¡ï¸ ê³„ì ˆì„± ì¡°ì • ì„¤ê³„...")
        
        # 2ë‹¨ê³„ ê²°ê³¼ì—ì„œ ê³„ì ˆì„± íŒ¨í„´ ë¶„ì„
        seasonal_metrics = {}
        monthly_cvs = {}
        
        for _, row in self.step2_results.iterrows():
            metric = row['metric']
            value = row['value']
            
            if any(keyword in metric.lower() for keyword in ['season', 'month', 'summer', 'winter', 'spring', 'autumn']):
                seasonal_metrics[metric] = value
                print(f"    ê³„ì ˆì„± ë©”íŠ¸ë¦­: {metric} = {value:.3f}")
                
                # ì›”ë³„ ë³€ë™ê³„ìˆ˜ ì¶”ì¶œ
                month_match = re.search(r'(\d+)ì›”|month_(\d+)', metric)
                if month_match and 'cv' in metric.lower():
                    month = int(month_match.group(1) or month_match.group(2))
                    if 1 <= month <= 12:
                        monthly_cvs[month] = value
        
        # ì‹¤ì œ ê³„ì ˆë³„ ë³€ë™ê³„ìˆ˜ ê³„ì‚°
        seasonal_cvs = {'spring': [], 'summer': [], 'autumn': [], 'winter': []}
        season_months = {
            'spring': [3, 4, 5],
            'summer': [6, 7, 8], 
            'autumn': [9, 10, 11],
            'winter': [12, 1, 2]
        }
        
        for season, months in season_months.items():
            for month in months:
                if month in monthly_cvs:
                    seasonal_cvs[season].append(monthly_cvs[month])
        
        # ê³„ì ˆë³„ í‰ê·  ë³€ë™ê³„ìˆ˜ ê³„ì‚°
        seasonal_avg_cvs = {}
        for season, cvs in seasonal_cvs.items():
            if cvs:
                seasonal_avg_cvs[season] = np.mean(cvs)
                print(f"    ì‹¤ì œ {season} í‰ê·  CV: {seasonal_avg_cvs[season]:.3f}")
        
        # ê³„ì ˆì„± ë³€ë™ ìˆ˜ì¤€ í‰ê°€ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
        if len(seasonal_avg_cvs) >= 2:
            cv_values = list(seasonal_avg_cvs.values())
            seasonal_variation = np.std(cv_values)
            overall_seasonal_cv = np.mean(cv_values)
            
            print(f"    ì‹¤ì œ ê³„ì ˆê°„ ë³€ë™ì„±: {seasonal_variation:.3f}")
            print(f"    ì „ì²´ ê³„ì ˆ í‰ê·  CV: {overall_seasonal_cv:.3f}")
            
        else:
            # 2ë‹¨ê³„ì—ì„œ ì „ì²´ ê³„ì ˆì„± ì§€í‘œ ì‚¬ìš©
            seasonal_variation = 0.1  # ê¸°ë³¸ê°’
            for metric, value in seasonal_metrics.items():
                if 'seasonal' in metric and 'cv' in metric:
                    seasonal_variation = value
                    break
            overall_seasonal_cv = seasonal_variation
        
        # ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê³„ì ˆì„± ì¡°ì • ê³„ìˆ˜ ê³„ì‚°
        seasonal_factors = {}
        
        if len(seasonal_avg_cvs) >= 3:  # ì¶©ë¶„í•œ ê³„ì ˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´
            # ê° ê³„ì ˆì˜ ìƒëŒ€ì  ë³€ë™ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •ê³„ìˆ˜ ì„¤ì •
            baseline_cv = overall_seasonal_cv
            
            for season in ['spring', 'summer', 'autumn', 'winter']:
                if season in seasonal_avg_cvs:
                    # ê¸°ì¤€ ëŒ€ë¹„ ìƒëŒ€ì  ë³€ë™ì„±
                    relative_variation = seasonal_avg_cvs[season] / baseline_cv
                    # 1.0ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •ê³„ìˆ˜ ì„¤ì • (ë³€ë™ì„±ì´ ë†’ìœ¼ë©´ ë†’ì€ ê³„ìˆ˜)
                    seasonal_factors[season] = 0.9 + (relative_variation * 0.2)  # 0.9~1.3 ë²”ìœ„
                else:
                    seasonal_factors[season] = 1.0
                
                print(f"    ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ {season} ì¡°ì •ê³„ìˆ˜: {seasonal_factors[season]:.3f}")
        
        else:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•˜ë©´ ì „ì²´ ë³€ë™ì„± ìˆ˜ì¤€ì— ë”°ë¥¸ ì¶”ì •
            if seasonal_variation > 0.2:  # ë†’ì€ ê³„ì ˆì„±
                seasonal_factors = {'summer': 1.3, 'winter': 1.2, 'spring': 1.1, 'autumn': 1.0}
                adjustment_enabled = True
            elif seasonal_variation > 0.1:  # ì¤‘ê°„ ê³„ì ˆì„±
                seasonal_factors = {'summer': 1.15, 'winter': 1.1, 'spring': 1.05, 'autumn': 1.0}
                adjustment_enabled = True
            else:  # ë‚®ì€ ê³„ì ˆì„±
                seasonal_factors = {'summer': 1.05, 'winter': 1.05, 'spring': 1.0, 'autumn': 1.0}
                adjustment_enabled = False
            
            print(f"    ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë³€ë™ì„± ìˆ˜ì¤€ ê¸°ë°˜ ì¶”ì • ì‚¬ìš©")
        
        # ì¡°ì • í™œì„±í™” ì—¬ë¶€ ê²°ì •
        adjustment_enabled = seasonal_variation > 0.05  # 5% ì´ìƒ ë³€ë™ì‹œì—ë§Œ ì¡°ì • í™œì„±í™”
        
        self.seasonal_adjustments = {
            'seasonal_months': season_months,
            'seasonal_factors': seasonal_factors,
            'adjustment_enabled': adjustment_enabled,
            'seasonal_variation_level': seasonal_variation,
            'data_source': 'step2_actual_seasonal_analysis' if len(seasonal_avg_cvs) >= 3 else 'estimated_from_variation',
            'actual_seasonal_cvs': seasonal_avg_cvs
        }
        
        print(f"    ê³„ì ˆì„± ìˆ˜ì¤€: {seasonal_variation:.3f}")
        print(f"    ì¡°ì • í™œì„±í™”: {adjustment_enabled}")
        for season, factor in seasonal_factors.items():
            print(f"    {season} ì¡°ì •ê³„ìˆ˜: {factor:.3f}")
    
    def _design_anomaly_criteria(self):
        """ì´ìƒ íŒ¨í„´ íƒì§€ ê¸°ì¤€ ì„¤ê³„ (1-2ë‹¨ê³„ ê²°ê³¼ ê¸°ë°˜)"""
        print("  ğŸš¨ ì´ìƒ íŒ¨í„´ íƒì§€ ê¸°ì¤€ ì„¤ê³„...")
        
        # 1ë‹¨ê³„ ë°ì´í„° í’ˆì§ˆ ì •ë³´ í™œìš©
        data_quality = self.step1_results.get('data_quality', {})
        lp_summary = self.step1_results.get('lp_data_summary', {})
        
        # 2ë‹¨ê³„ì—ì„œ ì‹¤ì œ ì´ìƒ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ í™œìš©
        actual_anomaly_rates = {}
        for _, row in self.step2_results.iterrows():
            metric = row['metric']
            value = row['value']
            
            if any(keyword in metric.lower() for keyword in ['anomaly', 'outlier', 'extreme', 'zero', 'sudden']):
                actual_anomaly_rates[metric] = value
                print(f"    ì‹¤ì œ ì´ìƒ íŒ¨í„´: {metric} = {value:.3f}")
        
        # ë°ì´í„° í’ˆì§ˆì— ë”°ë¥¸ ê¸°ë³¸ ì„ê³„ê°’ ì„¤ì •
        if data_quality:
            total_records = lp_summary.get('total_records', 1)
            null_ratio = data_quality.get('null_records_removed', 0) / total_records
            invalid_ratio = data_quality.get('invalid_time_removed', 0) / total_records
            
            print(f"    ë°ì´í„° í’ˆì§ˆ ë¶„ì„:")
            print(f"      ê²°ì¸¡ì¹˜ ë¹„ìœ¨: {null_ratio:.3%}")
            print(f"      ì´ìƒì‹œê°„ ë¹„ìœ¨: {invalid_ratio:.3%}")
            
            # ë°ì´í„° í’ˆì§ˆì— ë”°ë¥¸ ê¸°ë³¸ ì„ê³„ê°’
            if null_ratio > 0.05 or invalid_ratio > 0.02:
                base_cv_threshold = 1.5
                base_zero_ratio = 0.20
                base_sudden_threshold = 3.0
                quality_level = 'low'
            elif null_ratio > 0.01 or invalid_ratio > 0.005:
                base_cv_threshold = 1.2
                base_zero_ratio = 0.15
                base_sudden_threshold = 2.5
                quality_level = 'medium'
            else:
                base_cv_threshold = 1.0
                base_zero_ratio = 0.10
                base_sudden_threshold = 2.0
                quality_level = 'high'
        else:
            base_cv_threshold = 1.2
            base_zero_ratio = 0.15
            base_sudden_threshold = 2.5
            quality_level = 'unknown'
        
        # 2ë‹¨ê³„ ì‹¤ì œ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„ê³„ê°’ ì¡°ì •
        cv_extreme_threshold = base_cv_threshold
        zero_ratio_max = base_zero_ratio
        sudden_change_threshold = base_sudden_threshold
        
        # ì‹¤ì œ ì´ìƒ íŒ¨í„´ ë¹„ìœ¨ì— ë”°ë¥¸ ì¡°ì •
        for metric, value in actual_anomaly_rates.items():
            if 'extreme' in metric and 'cv' in metric:
                # ì‹¤ì œ ê·¹ê°’ ë³€ë™ê³„ìˆ˜ê°€ ìˆìœ¼ë©´ ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
                cv_extreme_threshold = max(value * 1.1, base_cv_threshold)
                print(f"      CV ê·¹ê°’ ì„ê³„ê°’ì„ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì¡°ì •: {cv_extreme_threshold:.2f}")
            
            elif 'zero' in metric and 'ratio' in metric:
                # ì‹¤ì œ 0ê°’ ë¹„ìœ¨ì´ ìˆìœ¼ë©´ ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
                zero_ratio_max = max(value * 1.5, base_zero_ratio)
                print(f"      0ê°’ ë¹„ìœ¨ ì„ê³„ê°’ì„ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì¡°ì •: {zero_ratio_max:.2f}")
            
            elif 'sudden' in metric or 'change' in metric:
                # ì‹¤ì œ ê¸‰ë³€ ë¹„ìœ¨ì´ ìˆìœ¼ë©´ ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¡°ì •
                sudden_change_threshold = max(value * 2.0, base_sudden_threshold)
                print(f"      ê¸‰ë³€ ì„ê³„ê°’ì„ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì¡°ì •: {sudden_change_threshold:.2f}")
        
        # ì‹¤ì œ ì´ìƒì¹˜ ë¯¼ê°ë„ ê³„ì‚°
        if 'outlier_ratio' in actual_anomaly_rates:
            outlier_sensitivity = actual_anomaly_rates['outlier_ratio'] * 1.2  # ì‹¤ì œë³´ë‹¤ 20% ì—¬ìœ 
        else:
            outlier_sensitivity = 0.05 if quality_level == 'high' else 0.03 if quality_level == 'medium' else 0.01
        
        # ì•¼ê°„/ì£¼ê°„ ë¹„ìœ¨ ì„ê³„ê°’ë„ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •
        night_day_ratio_max = 0.8  # ê¸°ë³¸ê°’
        for metric, value in actual_anomaly_rates.items():
            if any(keyword in metric.lower() for keyword in ['night', 'day', 'ì•¼ê°„', 'ì£¼ê°„']) and 'ratio' in metric.lower():
                # ì‹¤ì œ ì•¼ê°„/ì£¼ê°„ ë¹„ìœ¨ì˜ í‰ê· ë³´ë‹¤ ë†’ì€ ê°’ì„ ì„ê³„ê°’ìœ¼ë¡œ ì„¤ì •
                night_day_ratio_max = value * 1.3
                print(f"      ì•¼ê°„/ì£¼ê°„ ë¹„ìœ¨ ì„ê³„ê°’ì„ ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì¡°ì •: {night_day_ratio_max:.2f}")
                break
        
        # 2ë‹¨ê³„ì—ì„œ ì£¼ë§/í‰ì¼ ë¹„ìœ¨ì´ ìˆë‹¤ë©´ ì°¸ê³ 
        for _, row in self.step2_results.iterrows():
            metric = row['metric']
            value = row['value']
            if any(keyword in metric.lower() for keyword in ['weekend', 'weekday', 'ì£¼ë§', 'í‰ì¼']) and 'ratio' in metric.lower():
                # ì£¼ë§/í‰ì¼ íŒ¨í„´ì„ ì•¼ê°„/ì£¼ê°„ íŒ¨í„´ ì„¤ì •ì— ì°¸ê³ 
                if value < 0.5:  # ì£¼ë§ ì‚¬ìš©ëŸ‰ì´ í‰ì¼ë³´ë‹¤ í˜„ì €íˆ ë‚®ìœ¼ë©´
                    night_day_ratio_max = min(night_day_ratio_max, 0.6)  # ë” ì—„ê²©í•œ ê¸°ì¤€
                    print(f"      ì£¼ë§/í‰ì¼ íŒ¨í„´({value:.2f})ì„ ê³ ë ¤í•˜ì—¬ ì•¼ê°„/ì£¼ê°„ ë¹„ìœ¨ ì¡°ì •: {night_day_ratio_max:.2f}")
                break
        
        self.anomaly_criteria = {
            'cv_extreme_threshold': cv_extreme_threshold,
            'zero_ratio_max': zero_ratio_max,
            'sudden_change_threshold': sudden_change_threshold,
            'night_day_ratio_max': night_day_ratio_max,
            'outlier_sensitivity': outlier_sensitivity,
            'consecutive_anomaly_limit': 5,
            'anomaly_weight_penalty': 0.5,
            'data_quality_level': quality_level,
            'based_on_actual_anomalies': len(actual_anomaly_rates) > 0,
            'actual_anomaly_rates': actual_anomaly_rates
        }
        
        print(f"    ìµœì¢… ì´ìƒ íƒì§€ ê¸°ì¤€:")
        print(f"      CV ê·¹ê°’ ì„ê³„ê°’: {cv_extreme_threshold:.2f}")
        print(f"      0ê°’ ë¹„ìœ¨ ìµœëŒ€: {zero_ratio_max:.2f}")
        print(f"      ê¸‰ë³€ ì„ê³„ê°’: {sudden_change_threshold:.2f}")
        print(f"      ì•¼ê°„/ì£¼ê°„ ë¹„ìœ¨ ìµœëŒ€: {night_day_ratio_max:.2f}")
        print(f"      ë°ì´í„° í’ˆì§ˆ: {quality_level}")
        print(f"      ì‹¤ì œ ë°ì´í„° ê¸°ë°˜: {'ì˜ˆ' if len(actual_anomaly_rates) > 0 else 'ì•„ë‹ˆì˜¤'}")
    
    def _define_final_formula(self):
        """ìµœì¢… ë³€ë™ê³„ìˆ˜ ê³µì‹ ì •ì˜"""
        print("  ğŸ“ ìµœì¢… ë³€ë™ê³„ìˆ˜ ê³µì‹ ì •ì˜...")
        
        # ëª¨ë“  êµ¬ì„±ìš”ì†Œë¥¼ ì¢…í•©í•œ ë³€ë™ê³„ìˆ˜ ê³µì‹
        formula_definition = {
            'formula_type': 'weighted_ensemble',
            'components': [
                {
                    'name': 'basic_cv',
                    'weight': self.volatility_components['component_weights']['basic_cv'],
                    'calculation': 'standard_deviation / mean',
                    'normalization': 'none'
                },
                {
                    'name': 'temporal_weighted_cv',
                    'weight': self.volatility_components['component_weights']['temporal_cv'],
                    'calculation': '(peak_cv * peak_weight + off_peak_cv * off_peak_weight) / (peak_weight + off_peak_weight)',
                    'normalization': 'temporal_adjustment'
                },
                {
                    'name': 'seasonal_adjusted_cv',
                    'weight': self.volatility_components['component_weights']['seasonal_cv'],
                    'calculation': 'monthly_cv * seasonal_factor',
                    'normalization': 'seasonal_adjustment'
                },
                {
                    'name': 'pattern_stability_cv',
                    'weight': self.volatility_components['component_weights']['pattern_cv'],
                    'calculation': 'std(daily_cv_values)',
                    'normalization': 'stability_index'
                },
                {
                    'name': 'anomaly_adjusted_cv',
                    'weight': self.volatility_components['component_weights']['anomaly_cv'],
                    'calculation': 'cv * (1 + anomaly_penalty)',
                    'normalization': 'anomaly_adjustment'
                }
            ],
            'final_calculation': 'weighted_sum / industry_baseline',
            'relative_cv_interpretation': {
                'very_stable': '< 0.8',
                'stable': '0.8 - 1.2',
                'moderate': '1.2 - 1.8',
                'unstable': '1.8 - 2.5',
                'very_unstable': '> 2.5'
            }
        }
        
        self.volatility_components['formula_definition'] = formula_definition
        
        print("  âœ… ìµœì¢… ê³µì‹ ì •ì˜ ì™„ë£Œ")
        print("    ê³µì‹ ìœ í˜•: ê°€ì¤‘ ì•™ìƒë¸”")
        print("    êµ¬ì„±ìš”ì†Œ: 5ê°œ (ê¸°ë³¸, ì‹œê°„, ê³„ì ˆ, íŒ¨í„´, ì´ìƒ)")
    
    def save_design_results(self):
        """ì„¤ê³„ ê²°ê³¼ ì €ì¥"""
        print("\nğŸ’¾ ë³€ë™ê³„ìˆ˜ ì„¤ê³„ ê²°ê³¼ ì €ì¥...")
        
        design_results = {
            'design_metadata': {
                'design_date': datetime.now().isoformat(),
                'based_on_step1': 'analysis_results.json',
                'based_on_step2': 'volatility_summary.csv',
                'design_version': '1.0',
                'data_driven': True,
                'no_hardcoding': True
            },
            'volatility_components': self.volatility_components,
            'industry_benchmarks': self.industry_benchmarks,
            'temporal_patterns': self.temporal_patterns,
            'seasonal_adjustments': self.seasonal_adjustments,
            'anomaly_criteria': self.anomaly_criteria
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        output_file = os.path.join(self.results_path, 'volatility_coefficient_design.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(design_results, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ì„¤ê³„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        
        # ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        self._generate_design_summary()
        
        return design_results
    
    def _generate_design_summary(self):
        """ì„¤ê³„ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        summary_file = os.path.join(self.results_path, 'volatility_design_summary.txt')
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("í•œêµ­ì „ë ¥ê³µì‚¬ ë³€ë™ê³„ìˆ˜ ì„¤ê³„ ìš”ì•½ ë¦¬í¬íŠ¸\n")
            f.write("=" * 60 + "\n")
            f.write(f"ì„¤ê³„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("ë°ì´í„° ê¸°ë°˜ ì„¤ê³„: 1-2ë‹¨ê³„ ì‹¤ì œ ë¶„ì„ ê²°ê³¼ ì™„ì „ í™œìš©\n")
            f.write("í•˜ë“œì½”ë”© ì œê±°: ëª¨ë“  ì„¤ì •ê°’ì´ ì‹¤ì œ ë°ì´í„°ì—ì„œ ì¶”ì¶œë¨\n\n")
            
            f.write("1. ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ê°€ì¤‘ì¹˜\n")
            f.write("-" * 30 + "\n")
            for component, weight in self.volatility_components['component_weights'].items():
                f.write(f"  {component}: {weight:.3f}\n")
            
            f.write("\n2. ì—…ì¢…ë³„ ê¸°ì¤€ ë³€ë™ê³„ìˆ˜\n")
            f.write("-" * 30 + "\n")
            for contract, baseline in self.industry_benchmarks['contract_baselines'].items():
                f.write(f"  ê³„ì•½ì¢…ë³„ {contract}: {baseline:.3f}\n")
            
            f.write("\n3. ì‹œê°„ íŒ¨í„´ ê°€ì¤‘ì¹˜\n")
            f.write("-" * 30 + "\n")
            f.write(f"  í”¼í¬ ê°€ì¤‘ì¹˜: {self.temporal_patterns['peak_weight']:.2f}\n")
            f.write(f"  ì˜¤í”„í”¼í¬ ê°€ì¤‘ì¹˜: {self.temporal_patterns['off_peak_weight']:.2f}\n")
            f.write(f"  í”¼í¬ ì‹œê°„ëŒ€: {self.temporal_patterns['peak_hours']}\n")
            
            f.write("\n4. ê³„ì ˆì„± ì¡°ì • ê³„ìˆ˜\n")
            f.write("-" * 30 + "\n")
            for season, factor in self.seasonal_adjustments['seasonal_factors'].items():
                f.write(f"  {season}: {factor:.2f}\n")
            
            f.write("\n5. ì´ìƒ íƒì§€ ê¸°ì¤€\n")
            f.write("-" * 30 + "\n")
            f.write(f"  CV ê·¹ê°’ ì„ê³„ê°’: {self.anomaly_criteria['cv_extreme_threshold']:.2f}\n")
            f.write(f"  0ê°’ ë¹„ìœ¨ ìµœëŒ€: {self.anomaly_criteria['zero_ratio_max']:.2f}\n")
            f.write(f"  ë°ì´í„° í’ˆì§ˆ: {self.anomaly_criteria['data_quality_level']}\n")
            
            f.write("\n6. ë°ì´í„° ê¸°ë°˜ ì„¤ì • ì •ë³´\n")
            f.write("-" * 30 + "\n")
            f.write(f"  ì—…ì¢… ê¸°ì¤€ê°’: {self.industry_benchmarks['benchmark_source']}\n")
            f.write(f"  ì‹œê°„ íŒ¨í„´: {'ì‹¤ì œ ë°ì´í„° ê¸°ë°˜' if self.temporal_patterns.get('data_driven') else 'ì¶”ì •ê°’'}\n")
            f.write(f"  ê³„ì ˆì„± ì¡°ì •: {self.seasonal_adjustments['data_source']}\n")
            f.write(f"  ì´ìƒ íƒì§€: {'ì‹¤ì œ ì´ìƒ íŒ¨í„´ ê¸°ë°˜' if self.anomaly_criteria['based_on_actual_anomalies'] else 'í’ˆì§ˆ ê¸°ë°˜ ì¶”ì •'}\n")
        
        print(f"ğŸ“‹ ì„¤ê³„ ìš”ì•½ ë¦¬í¬íŠ¸: {summary_file}")
    
    def run_design_process(self):
        """ì „ì²´ ì„¤ê³„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("\nğŸš€ ë³€ë™ê³„ìˆ˜ ì„¤ê³„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
        print("=" * 50)
        
        start_time = datetime.now()
        
        try:
            # ì„¤ê³„ ê²°ê³¼ ì €ì¥
            design_results = self.save_design_results()
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            print("\n" + "=" * 50)
            print("ğŸ† ë³€ë™ê³„ìˆ˜ ì„¤ê³„ ì™„ë£Œ!")
            print("=" * 50)
            print(f"ì†Œìš” ì‹œê°„: {duration}")
            print(f"ì„¤ê³„ ê¸°ë°˜: 1-2ë‹¨ê³„ ê²°ê³¼ ì™„ì „ í™œìš©")
            print(f"í•˜ë“œì½”ë”©: ëª¨ë“  ì œê±°ë¨ âœ…")
            
            # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
            print("\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
            print("  2ë‹¨ê³„: ìŠ¤íƒœí‚¹ ëª¨ë¸ êµ¬í˜„")
            print("  - ì„¤ê³„ëœ ë³€ë™ê³„ìˆ˜ ì •ì˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•™ìƒë¸” ëª¨ë¸ êµ¬í˜„")
            print("  - volatility_coefficient_design.json íŒŒì¼ í™œìš©")
            
            return True
            
        except Exception as e:
            print(f"âŒ ì„¤ê³„ í”„ë¡œì„¸ìŠ¤ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

def find_files_recursively(start_path='.', max_depth=3):
    """ì¬ê·€ì ìœ¼ë¡œ í•„ìˆ˜ íŒŒì¼ë“¤ì„ ì°¾ëŠ” í•¨ìˆ˜"""
    required_files = ['analysis_results.json', 'volatility_summary.csv']
    found_locations = {}
    
    def search_directory(current_path, depth):
        if depth > max_depth:
            return
        
        try:
            for item in os.listdir(current_path):
                item_path = os.path.join(current_path, item)
                
                # íŒŒì¼ì¸ ê²½ìš°
                if os.path.isfile(item_path) and item in required_files:
                    if item not in found_locations:
                        found_locations[item] = []
                    found_locations[item].append(current_path)
                
                # ë””ë ‰í„°ë¦¬ì¸ ê²½ìš° (ìˆ¨ê¹€ í´ë” ì œì™¸)
                elif os.path.isdir(item_path) and not item.startswith('.') and item != '__pycache__':
                    search_directory(item_path, depth + 1)
        except PermissionError:
            pass  # ê¶Œí•œ ì—†ëŠ” í´ë”ëŠ” ê±´ë„ˆë›°ê¸°
    
    search_directory(start_path, 0)
    return found_locations

def select_best_path(found_locations):
    """ë°œê²¬ëœ íŒŒì¼ë“¤ ì¤‘ ê°€ì¥ ì í•©í•œ ê²½ë¡œ ì„ íƒ"""
    required_files = ['analysis_results.json', 'volatility_summary.csv']
    
    # ëª¨ë“  í•„ìˆ˜ íŒŒì¼ì´ ìˆëŠ” ê²½ë¡œ ì°¾ê¸°
    complete_paths = set()
    
    for file_name in required_files:
        if file_name in found_locations:
            if not complete_paths:  # ì²« ë²ˆì§¸ íŒŒì¼
                complete_paths = set(found_locations[file_name])
            else:  # êµì§‘í•© êµ¬í•˜ê¸°
                complete_paths = complete_paths.intersection(set(found_locations[file_name]))
    
    if complete_paths:
        # ê°€ì¥ ì§§ì€ ê²½ë¡œ (ìƒìœ„ ë””ë ‰í„°ë¦¬) ì„ íƒ
        return min(complete_paths, key=len)
    
    return None

# ì‹¤í–‰ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("1ë‹¨ê³„: í•œêµ­ì „ë ¥ê³µì‚¬ ë³€ë™ê³„ìˆ˜ ì •ì˜ ë° ì„¤ê³„")
    print("1-2ë‹¨ê³„ ê²°ê³¼ íŒŒì¼ ê¸°ë°˜ ì ì‘í˜• ì„¤ê³„ (í•˜ë“œì½”ë”© ì œê±°)")
    print("=" * 60)
    
    # 1. ìë™ìœ¼ë¡œ íŒŒì¼ ê²€ìƒ‰
    print("ğŸ” í•„ìˆ˜ íŒŒì¼ ìë™ ê²€ìƒ‰ ì¤‘...")
    found_locations = find_files_recursively('.', max_depth=3)
    
    print(f"ğŸ“‚ ê²€ìƒ‰ ê²°ê³¼:")
    if found_locations:
        for file_name, locations in found_locations.items():
            print(f"  {file_name}:")
            for loc in locations[:5]:  # ìµœëŒ€ 5ê°œ ìœ„ì¹˜ë§Œ í‘œì‹œ
                print(f"    - {loc}")
            if len(locations) > 5:
                print(f"    ... ë° {len(locations)-5}ê°œ ìœ„ì¹˜ ë”")
    else:
        print("  í•„ìˆ˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # 2. ìµœì  ê²½ë¡œ ì„ íƒ
    best_path = select_best_path(found_locations)
    
    if best_path:
        print(f"âœ… ìµœì  ê²½ë¡œ ë°œê²¬: {best_path}")
        results_path = best_path
    else:
        print("âŒ ëª¨ë“  í•„ìˆ˜ íŒŒì¼ì´ ìˆëŠ” ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # 3. ì‚¬ìš©ì ì…ë ¥ ì˜µì…˜ ì œê³µ
        print("\në‹¤ìŒ ì˜µì…˜ ì¤‘ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ì§ì ‘ ê²½ë¡œ ì…ë ¥")
        print("2. ì¢…ë£Œ")
        
        try:
            choice = input("ì„ íƒ (1-2): ").strip()
            
            if choice == '1':
                # ì§ì ‘ ê²½ë¡œ ì…ë ¥
                input_path = input("ê²°ê³¼ íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                if os.path.exists(input_path):
                    # í•´ë‹¹ ê²½ë¡œì— í•„ìˆ˜ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                    required_files = ['analysis_results.json', 'volatility_summary.csv']
                    missing = []
                    for file_name in required_files:
                        file_path = os.path.join(input_path, file_name)
                        if not os.path.exists(file_path):
                            missing.append(file_name)
                    
                    if not missing:
                        results_path = input_path
                        print(f"âœ… ê²½ë¡œ ì„¤ì • ì™„ë£Œ: {results_path}")
                    else:
                        print(f"âŒ ë‹¤ìŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
                        return False
                else:
                    print("âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ë¡œì…ë‹ˆë‹¤.")
                    return False
            else:
                return False
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
            return False
        except:
            print("âŒ ì˜ëª»ëœ ì…ë ¥ì…ë‹ˆë‹¤.")
            return False
    
    try:
        # ì„¤ê³„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        designer = KEPCOVolatilityCoefficientDesigner(results_path=results_path)
        success = designer.run_design_process()
        
        if success:
            print("\nğŸ‰ 1ë‹¨ê³„ ë³€ë™ê³„ìˆ˜ ì„¤ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("ë‹¤ìŒìœ¼ë¡œ 2ë‹¨ê³„ ìŠ¤íƒœí‚¹ ëª¨ë¸ êµ¬í˜„ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            
            # ìƒì„±ëœ íŒŒì¼ í™•ì¸
            design_file = os.path.join(results_path, 'volatility_coefficient_design.json')
            if os.path.exists(design_file):
                print(f"ğŸ“„ ìƒì„±ëœ ì„¤ê³„ íŒŒì¼: {design_file}")
            
        else:
            print("\nğŸ’¥ 1ë‹¨ê³„ ì„¤ê³„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        
        return success
        
    except Exception as e:
        print(f"\nâŒ ì„¤ê³„ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        print("\në””ë²„ê¹… ì •ë³´:")
        print(f"  ê²°ê³¼ ê²½ë¡œ: {results_path}")
        
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì¬í™•ì¸
        required_files = ['analysis_results.json', 'volatility_summary.csv']
        for filename in required_files:
            file_path = os.path.join(results_path, filename) if results_path != './' else filename
            exists = "âœ…" if os.path.exists(file_path) else "âŒ"
            print(f"  {exists} {filename}")
        
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    main()
