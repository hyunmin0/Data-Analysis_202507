"""
ë°ì´í„°ì•ˆì‹¬êµ¬ì—­ HDF5 ì••ì¶• í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
LP ë°ì´í„° íŒŒì¼ 4ê°œë¡œ ì••ì¶• ì˜µì…˜ í…ŒìŠ¤íŠ¸
"""

import pandas as pd
import numpy as np
import os
import glob
import time
from datetime import datetime
import gc

class CompressionTester:
    def __init__(self, data_dir='./ì œ13íšŒ ì‚°ì—…ë¶€ ê³µëª¨ì „ ëŒ€ìƒê³ ê° LPë°ì´í„°/'):
        self.data_dir = data_dir
        self.test_results = []
        
    def find_lp_files(self, limit=4):
        """LP íŒŒì¼ ì°¾ê¸° (ìµœëŒ€ 4ê°œ)"""
        patterns = [
            'processed_LPData_*.csv',
            'LPë°ì´í„°*.csv', 
            '*LP*.csv'
        ]
        
        lp_files = []
        for pattern in patterns:
            files = glob.glob(os.path.join(self.data_dir, pattern))
            lp_files.extend(files)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        lp_files = list(set(lp_files))
        lp_files.sort()
        
        # ìµœëŒ€ 4ê°œ íŒŒì¼ë§Œ ì„ íƒ
        if len(lp_files) > limit:
            lp_files = lp_files[:limit]
            
        print(f"ğŸ” ë°œê²¬ëœ LP íŒŒì¼ ({len(lp_files)}ê°œ):")
        for i, file in enumerate(lp_files, 1):
            file_size = os.path.getsize(file) / 1024**2  # MB
            print(f"   {i}. {os.path.basename(file)} ({file_size:.1f}MB)")
            
        return lp_files
    
    def test_compression_options(self, sample_data):
        """ë‹¤ì–‘í•œ ì••ì¶• ì˜µì…˜ í…ŒìŠ¤íŠ¸"""
        
        # í…ŒìŠ¤íŠ¸í•  ì••ì¶• ì˜µì…˜ë“¤
        compression_options = [
            {'name': 'no_compression', 'complib': None, 'complevel': 0},
            {'name': 'zlib_level1', 'complib': 'zlib', 'complevel': 1},
            {'name': 'zlib_level6', 'complib': 'zlib', 'complevel': 6},
            {'name': 'zlib_level9', 'complib': 'zlib', 'complevel': 9},
            {'name': 'blosc_level5', 'complib': 'blosc', 'complevel': 5},
            {'name': 'blosc_level9', 'complib': 'blosc', 'complevel': 9},
            {'name': 'lzo_level1', 'complib': 'lzo', 'complevel': 1},
            {'name': 'bzip2_level9', 'complib': 'bzip2', 'complevel': 9},
        ]
        
        print(f"\nğŸ§ª ì••ì¶• ì˜µì…˜ í…ŒìŠ¤íŠ¸ (ìƒ˜í”Œ ë°ì´í„°: {len(sample_data):,}ê±´)")
        print("=" * 80)
        print(f"{'ì˜µì…˜ëª…':<15} | {'ìƒíƒœ':<6} | {'í¬ê¸°(MB)':<10} | {'ì••ì¶•ë¥ ':<8} | {'ì €ì¥ì‹œê°„':<8} | {'ì½ê¸°ì‹œê°„':<8}")
        print("-" * 80)
        
        baseline_size = None
        test_results = []
        
        for option in compression_options:
            try:
                test_file = f"./test_{option['name']}.h5"
                
                # ì €ì¥ ì‹œê°„ ì¸¡ì •
                start_time = time.time()
                
                if option['complib'] is None:
                    # ì••ì¶• ì—†ìŒ
                    sample_data.to_hdf(test_file, key='df', mode='w', format='table')
                else:
                    # ì••ì¶• ì ìš©
                    sample_data.to_hdf(test_file, key='df', mode='w', format='table',
                                     complib=option['complib'], 
                                     complevel=option['complevel'])
                
                save_time = time.time() - start_time
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                file_size_mb = os.path.getsize(test_file) / 1024**2
                
                # ì½ê¸° ì‹œê°„ ì¸¡ì •
                start_time = time.time()
                _ = pd.read_hdf(test_file, key='df')
                read_time = time.time() - start_time
                
                # ì••ì¶•ë¥  ê³„ì‚°
                if baseline_size is None:
                    baseline_size = file_size_mb
                    compression_ratio = "ê¸°ì¤€"
                else:
                    compression_ratio = f"{((baseline_size - file_size_mb) / baseline_size * 100):5.1f}%"
                
                print(f"{option['name']:<15} | {'âœ…':<6} | {file_size_mb:8.2f}  | {compression_ratio:<8} | {save_time:6.3f}s | {read_time:6.3f}s")
                
                test_results.append({
                    'name': option['name'],
                    'success': True,
                    'file_size_mb': file_size_mb,
                    'save_time': save_time,
                    'read_time': read_time,
                    'complib': option['complib'],
                    'complevel': option['complevel']
                })
                
                # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‚­ì œ
                os.remove(test_file)
                
            except Exception as e:
                print(f"{option['name']:<15} | {'âŒ':<6} | {'N/A':<10} | {'N/A':<8} | {'N/A':<8} | {str(e)[:15]}")
                
                test_results.append({
                    'name': option['name'],
                    'success': False,
                    'error': str(e),
                    'complib': option['complib'],
                    'complevel': option['complevel']
                })
        
        return test_results
    
    def process_lp_files_with_compression(self, lp_files):
        """LP íŒŒì¼ë“¤ì„ ì••ì¶•í•˜ì—¬ ì²˜ë¦¬"""
        
        print(f"\nğŸš€ LP íŒŒì¼ ì••ì¶• ì²˜ë¦¬ ì‹œì‘ ({len(lp_files)}ê°œ íŒŒì¼)")
        print("=" * 60)
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í„°ë¦¬ ìƒì„±
        os.makedirs('./compression_test_results', exist_ok=True)
        
        # ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ì••ì¶• ì˜µì…˜ í…ŒìŠ¤íŠ¸
        if lp_files:
            print(f"ğŸ“ ì²« ë²ˆì§¸ íŒŒì¼ë¡œ ì••ì¶• ì˜µì…˜ í…ŒìŠ¤íŠ¸: {os.path.basename(lp_files[0])}")
            
            # ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
            sample_df = pd.read_csv(lp_files[0])
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            if 'LPìˆ˜ì‹ ì¼ì' in sample_df.columns:
                sample_df = sample_df.rename(columns={'LPìˆ˜ì‹ ì¼ì': 'LP ìˆ˜ì‹ ì¼ì'})
            if 'ìˆœë°©í–¥ìœ íš¨ì „ë ¥' in sample_df.columns:
                sample_df = sample_df.rename(columns={'ìˆœë°©í–¥ìœ íš¨ì „ë ¥': 'ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'})
            
            # datetime ì²˜ë¦¬
            sample_df = self._process_datetime(sample_df)
            
            # ì••ì¶• ì˜µì…˜ í…ŒìŠ¤íŠ¸
            compression_results = self.test_compression_options(sample_df)
            
            # ìµœì  ì••ì¶• ì˜µì…˜ ì„ íƒ
            successful_options = [r for r in compression_results if r['success']]
            if successful_options:
                # íŒŒì¼ í¬ê¸°ê°€ ê°€ì¥ ì‘ì€ ì˜µì…˜ ì„ íƒ
                best_option = min(successful_options, key=lambda x: x['file_size_mb'])
                print(f"\nğŸ† ìµœì  ì••ì¶• ì˜µì…˜: {best_option['name']} (í¬ê¸°: {best_option['file_size_mb']:.2f}MB)")
            else:
                print("\nâŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì••ì¶• ì˜µì…˜ì´ ì—†ìŠµë‹ˆë‹¤!")
                return False
            
            del sample_df
            gc.collect()
        
        # ì „ì²´ íŒŒì¼ ì²˜ë¦¬
        print(f"\nğŸ“¦ ì „ì²´ íŒŒì¼ ì••ì¶• ì²˜ë¦¬ ì‹œì‘...")
        
        total_records = 0
        all_customers = set()
        
        # ìµœì  ì••ì¶• ì„¤ì •
        if best_option['complib'] is None:
            compression_settings = {}
        else:
            compression_settings = {
                'complib': best_option['complib'],
                'complevel': best_option['complevel']
            }
        
        hdf5_path = './compression_test_results/compressed_lp_data.h5'
        
        # ê¸°ì¡´ íŒŒì¼ ì‚­ì œ
        if os.path.exists(hdf5_path):
            os.remove(hdf5_path)
        
        start_total_time = time.time()
        
        for i, file_path in enumerate(lp_files):
            try:
                filename = os.path.basename(file_path)
                print(f"\nğŸ“„ [{i+1}/{len(lp_files)}] {filename} ì²˜ë¦¬ ì¤‘...")
                
                # íŒŒì¼ ë¡œë“œ
                df = pd.read_csv(file_path)
                original_size_mb = os.path.getsize(file_path) / 1024**2
                
                print(f"   ğŸ“Š ì›ë³¸ í¬ê¸°: {original_size_mb:.1f}MB, ë ˆì½”ë“œ: {len(df):,}ê°œ")
                
                # ë°ì´í„° ì •ì œ
                df = self._clean_data(df)
                
                if len(df) == 0:
                    print(f"   âŒ ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ")
                    continue
                
                # ì••ì¶• ì €ì¥
                save_start = time.time()
                
                if i == 0:
                    # ì²« ë²ˆì§¸ íŒŒì¼
                    if compression_settings:
                        df.to_hdf(hdf5_path, key='df', mode='w', format='table', **compression_settings)
                    else:
                        df.to_hdf(hdf5_path, key='df', mode='w', format='table')
                else:
                    # ì¶”ê°€ íŒŒì¼
                    if compression_settings:
                        df.to_hdf(hdf5_path, key='df', mode='a', format='table', append=True, **compression_settings)
                    else:
                        df.to_hdf(hdf5_path, key='df', mode='a', format='table', append=True)
                
                save_time = time.time() - save_start
                
                # í˜„ì¬ íŒŒì¼ í¬ê¸° í™•ì¸
                current_size_mb = os.path.getsize(hdf5_path) / 1024**2
                
                # í†µê³„ ìˆ˜ì§‘
                total_records += len(df)
                all_customers.update(df['ëŒ€ì²´ê³ ê°ë²ˆí˜¸'].unique())
                
                print(f"   âœ… ì €ì¥ ì™„ë£Œ: {save_time:.2f}ì´ˆ")
                print(f"   ğŸ’¾ ëˆ„ì  í¬ê¸°: {current_size_mb:.1f}MB")
                print(f"   ğŸ‘¥ ëˆ„ì  ê³ ê°: {len(all_customers)}ëª…")
                
                del df
                gc.collect()
                
            except Exception as e:
                print(f"   âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        total_time = time.time() - start_total_time
        
        # ìµœì¢… ê²°ê³¼
        if os.path.exists(hdf5_path):
            final_size_mb = os.path.getsize(hdf5_path) / 1024**2
            
            print(f"\nğŸ¯ ì••ì¶• ì²˜ë¦¬ ì™„ë£Œ!")
            print("=" * 50)
            print(f"â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {total_time:.1f}ì´ˆ")
            print(f"ğŸ“Š ì´ ë ˆì½”ë“œ: {total_records:,}ê°œ")
            print(f"ğŸ‘¥ ì´ ê³ ê°: {len(all_customers)}ëª…")
            print(f"ğŸ’¾ ìµœì¢… íŒŒì¼ í¬ê¸°: {final_size_mb:.1f}MB")
            print(f"ğŸ—œï¸ ì‚¬ìš©ëœ ì••ì¶•: {best_option['name']}")
            
            # ì›ë³¸ ëŒ€ë¹„ ì••ì¶•ë¥  ì¶”ì •
            estimated_original_mb = total_records * 0.2 / 1000  # ëŒ€ëµ ì¶”ì •
            if estimated_original_mb > 0:
                compression_ratio = (1 - final_size_mb / estimated_original_mb) * 100
                print(f"ğŸ“ˆ ì˜ˆìƒ ì••ì¶•ë¥ : {compression_ratio:.1f}%")
            
            # ì½ê¸° í…ŒìŠ¤íŠ¸
            print(f"\nğŸ“– ì••ì¶•ëœ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸...")
            read_start = time.time()
            test_sample = pd.read_hdf(hdf5_path, key='df', start=0, stop=1000)
            read_time = time.time() - read_start
            print(f"   âœ… 1000ê±´ ì½ê¸°: {read_time:.3f}ì´ˆ")
            print(f"   ğŸ“… ë°ì´í„° ë²”ìœ„: {test_sample['datetime'].min()} ~ {test_sample['datetime'].max()}")
            
            return True
        else:
            print("\nâŒ ì••ì¶• íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
            return False
    
    def _process_datetime(self, df):
        """datetime ì»¬ëŸ¼ ì²˜ë¦¬"""
        try:
            if 'LP ìˆ˜ì‹ ì¼ì' in df.columns:
                # 24:00 ì²˜ë¦¬
                df['LP ìˆ˜ì‹ ì¼ì'] = df['LP ìˆ˜ì‹ ì¼ì'].str.replace(' 24:00', ' 00:00')
                df['datetime'] = pd.to_datetime(df['LP ìˆ˜ì‹ ì¼ì'], errors='coerce')
            return df
        except Exception as e:
            print(f"   âš ï¸ datetime ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return df
    
    def _clean_data(self, df):
        """ë°ì´í„° ì •ì œ"""
        try:
            # ì»¬ëŸ¼ëª… í‘œì¤€í™”
            if 'LPìˆ˜ì‹ ì¼ì' in df.columns:
                df = df.rename(columns={'LPìˆ˜ì‹ ì¼ì': 'LP ìˆ˜ì‹ ì¼ì'})
            if 'ìˆœë°©í–¥ìœ íš¨ì „ë ¥' in df.columns:
                df = df.rename(columns={'ìˆœë°©í–¥ìœ íš¨ì „ë ¥': 'ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'})
            
            # datetime ì²˜ë¦¬
            df = self._process_datetime(df)
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_cols = ['ëŒ€ì²´ê³ ê°ë²ˆí˜¸', 'LP ìˆ˜ì‹ ì¼ì', 'ìˆœë°©í–¥ ìœ íš¨ì „ë ¥']
            if not all(col in df.columns for col in required_cols):
                return pd.DataFrame()
            
            # ê²°ì¸¡ì¹˜ ë° ì´ìƒê°’ ì œê±°
            df = df.dropna(subset=['datetime', 'ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'])
            df = df[df['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'] >= 0]
            
            return df
            
        except Exception as e:
            print(f"   âš ï¸ ë°ì´í„° ì •ì œ ì˜¤ë¥˜: {e}")
            return pd.DataFrame()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ—œï¸ ë°ì´í„°ì•ˆì‹¬êµ¬ì—­ HDF5 ì••ì¶• í…ŒìŠ¤íŠ¸ ë„êµ¬")
    print("=" * 60)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = CompressionTester()
    
    # LP íŒŒì¼ ì°¾ê¸°
    lp_files = tester.find_lp_files(limit=4)
    
    if not lp_files:
        print("âŒ LP ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print("ğŸ’¡ ë‹¤ìŒ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:")
        print("   - ./ì œ13íšŒ ì‚°ì—…ë¶€ ê³µëª¨ì „ ëŒ€ìƒê³ ê° LPë°ì´í„°/")
        print("   - processed_LPData_*.csv íŒ¨í„´ì˜ íŒŒì¼ë“¤")
        return False
    
    # ì••ì¶• í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    success = tester.process_lp_files_with_compression(lp_files)
    
    if success:
        print(f"\nâœ… ì••ì¶• í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: ./compression_test_results/compressed_lp_data.h5")
        print(f"\nğŸ’¡ ì´ì œ ì‹¤ì œ ì „ì²˜ë¦¬ ì½”ë“œì—ì„œ ë™ì¼í•œ ì••ì¶• ì„¤ì •ì„ ì‚¬ìš©í•˜ì„¸ìš”!")
    else:
        print(f"\nâŒ ì••ì¶• í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
    
    print(f"\nì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    return success

if __name__ == "__main__":
    main()