import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
import glob
import os
import gc  # â† ì¶”ê°€
import json  # â† ì¶”ê°€
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

class KEPCODataAnalyzer:
    def __init__(self):
        self.customer_data = None
        self.lp_data = None
        
        self.analysis_results = {}
        
    def load_customer_data(self, file_path='ì œ13íšŒ ì‚°ì—…ë¶€ ê³µëª¨ì „ ëŒ€ìƒê³ ê°/ì œ13íšŒ ì‚°ì—…ë¶€ ê³µëª¨ì „ ëŒ€ìƒê³ ê°.xlsx'):
        """ì‹¤ì œ ê³ ê° ê¸°ë³¸ì •ë³´ ë¡œë”© ë° ê¸°ë³¸ ë¶„ì„"""
        print("=== ê³ ê° ê¸°ë³¸ì •ë³´ ë¡œë”© ===")
        
        try:
            # ì‹¤ì œ Excel íŒŒì¼ ì½ê¸°
            self.customer_data = pd.read_excel(file_path, header=1)
            
            print(f"ì´ ê³ ê° ìˆ˜: {len(self.customer_data):,}ëª…")
            print(f"ì»¬ëŸ¼: {list(self.customer_data.columns)}")
            print("\nê¸°ë³¸ ì •ë³´:")
            print(self.customer_data.head())
            
            return self._analyze_customer_distribution()
            
        except Exception as e:
            print(f"ê³ ê° ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {e}")
            return None
    
    def _analyze_customer_distribution(self):
        """ê³ ê° ë¶„í¬ ë¶„ì„"""
        print("\n=== ê³ ê° ë¶„í¬ ë¶„ì„ ===")
        
        # ê³„ì•½ì¢…ë³„ ë¶„í¬
        contract_counts = self.customer_data['ê³„ì•½ì¢…ë³„'].value_counts()
        print("\nğŸ“Š ê³„ì•½ì¢…ë³„ ë¶„í¬:")
        for contract, count in contract_counts.items():
            pct = (count / len(self.customer_data)) * 100
            print(f"  {contract}: {count}ëª… ({pct:.1f}%)")
        
        # ì‚¬ìš©ìš©ë„ë³„ ë¶„í¬
        usage_counts = self.customer_data['ì‚¬ìš©ìš©ë„'].value_counts()
        print("\nğŸ­ ì‚¬ìš©ìš©ë„ë³„ ë¶„í¬:")
        for usage, count in usage_counts.items():
            pct = (count / len(self.customer_data)) * 100
            print(f"  {usage}: {count}ëª… ({pct:.1f}%)")
        
        # ê³„ì•½ì „ë ¥ ë¶„í¬
        print("\nâš¡ ê³„ì•½ì „ë ¥ ë¶„í¬:")
        power_stats = self.customer_data['ê³„ì•½ì „ë ¥'].describe()
        print(power_stats)
        
        return {
            'contract_distribution': contract_counts,
            'usage_distribution': usage_counts,
            'power_stats': power_stats
        }
    
    def load_lp_data(self, data_dir):
        """LP ë°ì´í„° ë¡œë”© - ë©”ëª¨ë¦¬ ìµœì í™”"""
        lp_files = []
        for root, dirs, files in os.walk(data_dir):
            for file in files:
                if file.startswith('processed_LPData_') and file.endswith('.csv'):
                    lp_files.append(os.path.join(root, file))
        
        if not lp_files:
            print("âŒ LP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        print(f"ë°œê²¬ëœ LP íŒŒì¼ ìˆ˜: {len(lp_files)}ê°œ")
        
        # â­ í•µì‹¬ ë³€ê²½: íŒŒì¼ë³„ë¡œ ì²˜ë¦¬í•˜ê³  ë°”ë¡œ HDF5ì— ì €ì¥
        os.makedirs('./analysis_results', exist_ok=True)
        total_records = 0
        all_customers = set()
        
        for i, file_path in enumerate(sorted(lp_files)):
            try:
                filename = os.path.basename(file_path)
                print(f"   [{i+1}/{len(lp_files)}] {filename} ì²˜ë¦¬ ì¤‘...")
                
                # í•œ íŒŒì¼ë§Œ ë©”ëª¨ë¦¬ì— ë¡œë“œ
                df = pd.read_csv(file_path)
                
                # ì»¬ëŸ¼ëª… í‘œì¤€í™”
                if 'LPìˆ˜ì‹ ì¼ì' in df.columns:
                    df = df.rename(columns={'LPìˆ˜ì‹ ì¼ì': 'LP ìˆ˜ì‹ ì¼ì'})
                if 'ìˆœë°©í–¥ìœ íš¨ì „ë ¥' in df.columns:
                    df = df.rename(columns={'ìˆœë°©í–¥ìœ íš¨ì „ë ¥': 'ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'})
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
                required_cols = ['ëŒ€ì²´ê³ ê°ë²ˆí˜¸', 'LP ìˆ˜ì‹ ì¼ì', 'ìˆœë°©í–¥ ìœ íš¨ì „ë ¥']
                if not all(col in df.columns for col in required_cols):
                    print(f"      âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {filename}")
                    del df
                    continue
                
                # ë°ì´í„° ì •ì œ
                df = self._process_datetime_file(df)
                df = df.dropna(subset=required_cols)
                df = df[df['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'] >= 0]
                
                if len(df) == 0:
                    print(f"      âŒ ìœ íš¨í•œ ë°ì´í„° ì—†ìŒ: {filename}")
                    del df
                    continue
                
                # íŒŒì¼ë³„ HDF5 ì €ì¥ (append ëª¨ë“œ)
                hdf5_path = './analysis_results/processed_lp_data.h5'
                try:
                    if i == 0:
                        df.to_hdf(hdf5_path, key='df', mode='w', format='table')
                    else:
                        df.to_hdf(hdf5_path, key='df', mode='a', format='table', append=True)
                except Exception as hdf_error:
                    print(f"      âš ï¸ HDF5 ì €ì¥ ì‹¤íŒ¨: {hdf_error}")
                    print(f"      ğŸ’¡ í•´ê²°ë°©ë²•: pip install tables")
                    del df
                    continue
                
                # í†µê³„ë§Œ ìˆ˜ì§‘
                total_records += len(df)
                all_customers.update(df['ëŒ€ì²´ê³ ê°ë²ˆí˜¸'].unique())
                
                print(f"      âœ… ë ˆì½”ë“œ: {len(df):,}ê°œ, ê³ ê°: {df['ëŒ€ì²´ê³ ê°ë²ˆí˜¸'].nunique()}ëª…")
                
                # ë©”ëª¨ë¦¬ì—ì„œ ì¦‰ì‹œ ì‚­ì œ
                del df
                gc.collect()
                
            except Exception as e:
                print(f"      âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        if total_records == 0:
            print("âŒ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        print(f"\nâœ… LP ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ:")
        print(f"  ì´ ë ˆì½”ë“œ: {total_records:,}")
        print(f"  ì´ ê³ ê°: {len(all_customers)}ëª…")
        print(f"  ì €ì¥ ìœ„ì¹˜: ./analysis_results/processed_lp_data.h5")
        
        # ì „ì²´ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì§€ ì•Šê³  í†µê³„ë§Œ ì €ì¥
        self.lp_summary = {
            'total_records': total_records,
            'total_customers': len(all_customers),
            'hdf5_file': './analysis_results/processed_lp_data.h5'
        }
        
        return True

    def _process_datetime_file(self, df):
        """ì „ì²´ íŒŒì¼ì˜ datetime ì²˜ë¦¬"""
        try:
            # 24:00ì„ 00:00ìœ¼ë¡œ ë³€ê²½
            original_24_mask = df['LP ìˆ˜ì‹ ì¼ì'].str.contains(' 24:00', na=False)
            df['LP ìˆ˜ì‹ ì¼ì'] = df['LP ìˆ˜ì‹ ì¼ì'].str.replace(' 24:00', ' 00:00')
            
            # datetime ë³€í™˜
            df['datetime'] = pd.to_datetime(df['LP ìˆ˜ì‹ ì¼ì'], errors='coerce')
            
            # 24:00ì´ì—ˆë˜ í–‰ë“¤ì€ ë‹¤ìŒë‚ ë¡œ ì´ë™
            if original_24_mask.any():
                df.loc[original_24_mask, 'datetime'] += pd.Timedelta(days=1)
            
            return df
        except Exception as e:
            print(f"   âš ï¸ datetime ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            df['datetime'] = pd.to_datetime(df['LP ìˆ˜ì‹ ì¼ì'], errors='coerce')
            return df
    
    def detect_outliers_streamed(self, customer_limit=3, method='iqr'):
        """HDF5 ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì´ìƒì¹˜ íƒì§€ (ìƒ˜í”Œ ê³ ê° ê¸°ì¤€)"""
        print("\n[ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜] ì´ìƒì¹˜ íƒì§€ (ìƒ˜í”Œ ê³ ê°)")
        
        # â­ ìˆ˜ì •: ì˜¬ë°”ë¥¸ HDF5 íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
        hdf_path = './analysis_results/processed_lp_data.h5'
        if not os.path.exists(hdf_path):
            print("âŒ HDF5 íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None

        try:
            # â­ ìˆ˜ì •: ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ HDF5 ì½ê¸°
            sample_data = pd.read_hdf(hdf_path, key='df', start=0, stop=10000)  # ì²« 1ë§Œê°œë§Œ ìƒ˜í”Œ
            customer_ids = sample_data['ëŒ€ì²´ê³ ê°ë²ˆí˜¸'].unique()
            print(f"ğŸ’¡ ìƒ˜í”Œ ê³ ê° ìˆ˜: {len(customer_ids)}ëª… ì¤‘ {customer_limit}ëª… ë¶„ì„")

            summary = {}

            for cid in customer_ids[:customer_limit]:
                df = sample_data[sample_data['ëŒ€ì²´ê³ ê°ë²ˆí˜¸'] == cid]

                print(f"\nğŸ“Œ ê³ ê° {cid} - ë ˆì½”ë“œ ìˆ˜: {len(df):,}")

                numeric_columns = ['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥', 'ì§€ìƒë¬´íš¨', 'ì§„ìƒë¬´íš¨', 'í”¼ìƒì „ë ¥']
                available_cols = [col for col in numeric_columns if col in df.columns]

                for col in available_cols:
                    if method == 'iqr':
                        Q1 = df[col].quantile(0.25)
                        Q3 = df[col].quantile(0.75)
                        IQR = Q3 - Q1
                        lower = Q1 - 1.5 * IQR
                        upper = Q3 + 1.5 * IQR
                        outliers = df[(df[col] < lower) | (df[col] > upper)]

                        pct = len(outliers) / len(df) * 100 if len(df) > 0 else 0
                        print(f"   - {col}: ì´ìƒì¹˜ {len(outliers)}ê±´ ({pct:.2f}%)")

                        summary[f"{cid}-{col}"] = {
                            'outlier_count': len(outliers),
                            'outlier_pct': pct,
                            'lower_bound': lower,
                            'upper_bound': upper
                        }

            self.analysis_results['outliers_streamed'] = summary
            return summary

        except Exception as e:
            print(f"âŒ ìŠ¤íŠ¸ë¦¬ë° ì´ìƒì¹˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None

    def generate_quality_report_streamed(self):
        """HDF5 ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° í’ˆì§ˆ ë¦¬í¬íŠ¸"""
        print("\nğŸ“‹ ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜ ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸")
        print("=" * 60)

        # â­ ìˆ˜ì •: ì˜¬ë°”ë¥¸ HDF5 íŒŒì¼ ê²½ë¡œ ì‚¬ìš©
        hdf_path = './analysis_results/processed_lp_data.h5'
        if not os.path.exists(hdf_path):
            print("âŒ HDF5 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        try:
            # â­ ìˆ˜ì •: ê°„ë‹¨í•œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì½ê¸°
            sample_data = pd.read_hdf(hdf_path, key='df', start=0, stop=50000)  # 5ë§Œê°œ ìƒ˜í”Œ
            
            # ë‚ ì§œ ë²”ìœ„
            start = sample_data['datetime'].min()
            end = sample_data['datetime'].max()

            # í‰ê·  ìœ íš¨ì „ë ¥ ê³„ì‚°
            mean_power = sample_data['ìˆœë°©í–¥ ìœ íš¨ì „ë ¥'].mean()

            # ìš”ì•½ ì €ì¥
            self.analysis_results['lp_summary_streamed'] = {
                'date_range': {'start': str(start), 'end': str(end)},
                'avg_power': float(mean_power),
                'sample_records': len(sample_data),
                'file': hdf_path
            }

            print(f"âœ… ìƒ˜í”Œ ë ˆì½”ë“œ: {len(sample_data):,}ê±´")
            print(f"âœ… ì¸¡ì • ê¸°ê°„: {start} ~ {end}")
            print(f"âœ… í‰ê·  ìœ íš¨ì „ë ¥: {mean_power:.2f} kW")

            # JSON ì €ì¥
            output_file = './analysis_results/analysis_results.json'
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_results, f, indent=2, ensure_ascii=False, default=str)

            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
            return True

        except Exception as e:
            print(f"âŒ í’ˆì§ˆ ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False


# ì‚¬ìš© ì˜ˆì œ (ì‹¤ì œ ë°ì´í„°ì•ˆì‹¬êµ¬ì—­ì—ì„œ ì‹¤í–‰)
if __name__ == "__main__":
    print("í•œêµ­ì „ë ¥ê³µì‚¬ ì „ë ¥ ì‚¬ìš©íŒ¨í„´ ë³€ë™ê³„ìˆ˜ ê°œë°œ í”„ë¡œì íŠ¸")
    print("ë°ì´í„°ì•ˆì‹¬êµ¬ì—­ ì „ìš© - ì‹¤ì œ ë°ì´í„° ë¶„ì„")
    print("="*60)
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = KEPCODataAnalyzer()
    
    # 1ë‹¨ê³„: ê³ ê° ê¸°ë³¸ì •ë³´ ë¶„ì„
    print("\n[1ë‹¨ê³„] ê³ ê° ê¸°ë³¸ì •ë³´ ë¡œë”© ë° ë¶„ì„")
    customer_analysis = analyzer.load_customer_data('ì œ13íšŒ ì‚°ì—…ë¶€ ê³µëª¨ì „ ëŒ€ìƒê³ ê°/ì œ13íšŒ ì‚°ì—…ë¶€ ê³µëª¨ì „ ëŒ€ìƒê³ ê°.xlsx')
    
    # 2ë‹¨ê³„: LP ë°ì´í„° ë¶„ì„
    print("\n[2ë‹¨ê³„] LP ë°ì´í„° ë¡œë”© ë° í’ˆì§ˆ ë¶„ì„")
    lp_analysis = analyzer.load_lp_data('./ì œ13íšŒ ì‚°ì—…ë¶€ ê³µëª¨ì „ ëŒ€ìƒê³ ê° LPë°ì´í„°/')
    
    # 3ë‹¨ê³„: ì´ìƒì¹˜ íƒì§€ (lp_analysis ì„±ê³µì‹œì—ë§Œ)
    print("\n[3ë‹¨ê³„] ì´ìƒì¹˜ íƒì§€ ë° ë°ì´í„° ì •ì œ")
    if lp_analysis:
        outliers = analyzer.detect_outliers_streamed(customer_limit=3)
    else:
        print("âŒ LP ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ë¡œ ì´ìƒì¹˜ íƒì§€ ê±´ë„ˆëœ€")
    
    # 4ë‹¨ê³„: ì¢…í•© ë¦¬í¬íŠ¸ (lp_analysis ì„±ê³µì‹œì—ë§Œ)
    print("\n[4ë‹¨ê³„] ë°ì´í„° í’ˆì§ˆ ì¢…í•© í‰ê°€")
    if lp_analysis:
        analyzer.generate_quality_report_streamed()
    else:
        print("âŒ LP ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ë¡œ í’ˆì§ˆ ë¦¬í¬íŠ¸ ê±´ë„ˆëœ€")
    
    print("\nğŸ¯ 1ë‹¨ê³„ ë°ì´í„° í’ˆì§ˆ ì ê²€ ì™„ë£Œ!")
    print("ë‹¤ìŒ: 2ë‹¨ê³„ ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ")